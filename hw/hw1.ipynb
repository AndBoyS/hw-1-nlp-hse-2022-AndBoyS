{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "## Harry Potter and the Action Prediction Challenge from Natural Language\n",
    "\n",
    "*deadline*: 14 ноября 2022, 23:59\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусом Harry Potter and the Action Prediction Challenge. Корпус собран из фанфиков о Гарри Поттере и состоит из двух частей: 1) сырые тексты, 2) фрагменты текстов, описывающих ситуацию, в которой произнесено заклинание.\n",
    "\n",
    "Корпус описан в статье: https://arxiv.org/pdf/1905.11037.pdf\n",
    "\n",
    "David Vilares and Carlos Gómez-Rodríguez. Harry Potter and the Action Prediction Challenge from Natural Language. 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics. To appear.\n",
    "\n",
    "Код для сбора корпуса находится в репозитории: https://github.com/aghie/hpac . Корпус можно скачать по инструкции из этого репозитория, но для экономии времени авторы задания уже скачали и подготовили данные к работе. \n",
    "\n",
    "Ссылки на собранный корпус: \n",
    "* Сырые тексты:  https://www.dropbox.com/s/23xet9kvbqna1qs/hpac_raw.zip?dl=0\n",
    "* Токенизированные тексты в нижнем регистре: https://www.dropbox.com/s/gwfgmomdbetvdye/hpac_lower_tokenized.zip?dl=0\n",
    "* train-test-dev: https://www.dropbox.com/s/3vdz0mouvex8abd/hpac_splits.zip?dl=0\n",
    "\n",
    "Части 1, 2 задания должны быть выполнены на полных текстах (сырых или предобработанных -- на ваше усмотрение), Часть 3 – на разбиение на тестовое, отладочное и обучающее множества. Тестовое множество должно быть использовано исключительно для тестирования моделей, обучающее и отладочное – для выбора модели и параметров. \n",
    "\n",
    "В статье и репозитории вы найдете идеи, которые помогут вам выполнить домашнее задание. Их стоит воспринимать как руководство к действию, и не стоит их копировать и переиспользовать. Обученные модели использовать не нужно, код для их обучения можно использовать как подсказку. \n",
    "\n",
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 3-х человек.\n",
    "2. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо ipython-тетрадке. \n",
    "3. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "4. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "5. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "6. Плагиат и любое недобросоветсное цитирование приводит к обнуление оценки. \n",
    "\n",
    "\n",
    "## Часть 1. [2 балла] Эксплоративный анализ \n",
    "1. Найдите топ-1000 слов по частоте без учета стоп-слов.\n",
    "2. Найдите топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия. \n",
    "\n",
    "[бонус] Постройте тематическую модель по корпусу HPAC.\n",
    "\n",
    "[бонус] Найдите еще что-то интересное в корпусе (что-то специфичное для фанфиков или фентези-тематики)\n",
    "\n",
    "## Часть 2. [2 балла] Модели представления слов \n",
    "Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса HPAC.\n",
    "1. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели. \n",
    "2. Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io).\n",
    "\n",
    "## Часть 3. [5 баллов] Классификация текстов\n",
    "Задача классификации формулируется так: данный фрагмент фанфика описывают какую-то ситуацию, которая предшествует произнесению заклинания. Требуется по тексту предсказать, какое именно заклинание будет произнесено. Таким образом, заклинание - это фактически метка класса. Основная мера качества – macro $F_1$.\n",
    "Обучите несколько классификаторов и сравните их между собой. Оцените качество классификаторов на частых и редких классах. Какие классы чаще всего оказываются перепутаны? Связаны ли ошибки со смыслом заклинаний?\n",
    "\n",
    "Используйте фрагменты из множества train для обучения, из множества dev для отладки, из множества test – для тестирования и получения итоговых результатов. \n",
    "\n",
    "1. [1 балл] Используйте fastText в качестве baseline-классификатора.\n",
    "2. [2 балла] Используйте сверточные  или реккурентные сети в качестве более продвинутого классификатора. Поэкспериментируйте с количеством и размерностью фильтров, используйте разные размеры окон, попробуйте использовать $k$-max pooling. \n",
    "3. [2 балла] Попробуйте расширить обучающее множество за счет аугментации данных. Если вам понадобится словарь синонимов, можно использовать WordNet (ниже вы найдете примеры).\n",
    "\n",
    "[бонус] Используйте результат max pooling'а как эмбеддинг входного текста. Визуализируйте эмбеддинги 500-1000 предложений из обучающего множества и изучите свойства получившегося пространства.\n",
    "\n",
    "[бонус] Используйте ваш любимый классификатор и любые (честные) способы повышения качества классификации и получите macro $F_1$ больше 0.5.\n",
    "\n",
    "## Часть 4. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Читали ли вы сами Гарри Поттера или фанфики о нем и помогло ли вам знание предметной области в выполнении домашнего задания?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\r\n",
      "/Users/germanarutunov/DataspellProjects/hw-1-nlp-hse-2022-AndBoyS/hw/data\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "%cd data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-07 20:59:19--  https://www.dropbox.com/s/23xet9kvbqna1qs/hpac_raw.zip\r\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18\r\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /s/raw/23xet9kvbqna1qs/hpac_raw.zip [following]\r\n",
      "--2022-11-07 20:59:23--  https://www.dropbox.com/s/raw/23xet9kvbqna1qs/hpac_raw.zip\r\n",
      "Reusing existing connection to www.dropbox.com:443.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com/cd/0/inline/BwX6_goqPJo1ECXTvh_cWpu92zklf6UlqQ6zzu9k6-c0lQFaFax-lxeRHu-R0Jy5mufEhXp3j717P-DzpLDcekkpXv6zTt7Jn3VRrE-0uX9lWrEE0mfNzpPpx9LFBiOEzs7MwKRgZ-eHacdOhTEY-b9KckcuKkYFfyXgMBfgrcwBTg/file# [following]\r\n",
      "--2022-11-07 20:59:24--  https://uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com/cd/0/inline/BwX6_goqPJo1ECXTvh_cWpu92zklf6UlqQ6zzu9k6-c0lQFaFax-lxeRHu-R0Jy5mufEhXp3j717P-DzpLDcekkpXv6zTt7Jn3VRrE-0uX9lWrEE0mfNzpPpx9LFBiOEzs7MwKRgZ-eHacdOhTEY-b9KckcuKkYFfyXgMBfgrcwBTg/file\r\n",
      "Resolving uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com (uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com)... 162.125.64.15\r\n",
      "Connecting to uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com (uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /cd/0/inline2/BwWbamQ57pATCA2QaNvrZk1FMExLPYT1Dj0dM1zACVuQ5YSEIkW_odvPGwXJ9IKE6eOlBlKfuroKno3nUlZ4wf-hTmNUefl7gEHHjpZClCKiOPudoRtY5dCRUGSdT2p6elsIV9IrmX_YuWTruVm0GrmpkpAkODsmGtgHYz6jAWYcM2rsmezf6CFoViPT9OwNz-7f6YSDaPnEBrxMQH0btSN3LZ882HmvfzO3PskG9iIYVv2Uw6kJ26vFePdI0KtsCYfCZl95iy0J9a16PkY-lalO3MnIqPlG_vQLQCXuEQeV-7aSp-W87XacZSnaK81RHiCG4oI6KZszgooMkRt2wwwn5KW4f_4IuNdX2nfxvxJuvva2zKpygniEiY8Q0PWrj_j3s2O0yeA2NVjcpZpetwbAWkIE2hCCjk1n6RY8n22W8Q/file [following]\r\n",
      "--2022-11-07 20:59:46--  https://uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com/cd/0/inline2/BwWbamQ57pATCA2QaNvrZk1FMExLPYT1Dj0dM1zACVuQ5YSEIkW_odvPGwXJ9IKE6eOlBlKfuroKno3nUlZ4wf-hTmNUefl7gEHHjpZClCKiOPudoRtY5dCRUGSdT2p6elsIV9IrmX_YuWTruVm0GrmpkpAkODsmGtgHYz6jAWYcM2rsmezf6CFoViPT9OwNz-7f6YSDaPnEBrxMQH0btSN3LZ882HmvfzO3PskG9iIYVv2Uw6kJ26vFePdI0KtsCYfCZl95iy0J9a16PkY-lalO3MnIqPlG_vQLQCXuEQeV-7aSp-W87XacZSnaK81RHiCG4oI6KZszgooMkRt2wwwn5KW4f_4IuNdX2nfxvxJuvva2zKpygniEiY8Q0PWrj_j3s2O0yeA2NVjcpZpetwbAWkIE2hCCjk1n6RY8n22W8Q/file\r\n",
      "Reusing existing connection to uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1018234025 (971M) [application/zip]\r\n",
      "Saving to: ‘hpac_raw.zip’\r\n",
      "\r\n",
      "hpac_raw.zip        100%[===================>] 971.06M  1.12MB/s    in 23m 10s \r\n",
      "\r\n",
      "2022-11-07 21:22:57 (715 KB/s) - ‘hpac_raw.zip’ saved [1018234025/1018234025]\r\n",
      "\r\n",
      "--2022-11-07 21:22:57--  https://www.dropbox.com/s/gwfgmomdbetvdye/hpac_lower_tokenized.zip\r\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18\r\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /s/raw/gwfgmomdbetvdye/hpac_lower_tokenized.zip [following]\r\n",
      "--2022-11-07 21:22:58--  https://www.dropbox.com/s/raw/gwfgmomdbetvdye/hpac_lower_tokenized.zip\r\n",
      "Reusing existing connection to www.dropbox.com:443.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com/cd/0/inline/BwWCmPm2dxyNSU-lnD9T5JpMVahm-SMWoBBJ9dWiHR0_GujfU1wORVgK9_Mun2-jFpC10JUCgZumzYePPZ3m0KwnDYWXRn5qW1qFe2bfI11rH8oARCFX6jVXFWRuzUMpaX51lg3f_8nfEtgZfv645KmRwypCoUlqfYYV1SrOFgZLug/file# [following]\r\n",
      "--2022-11-07 21:22:59--  https://uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com/cd/0/inline/BwWCmPm2dxyNSU-lnD9T5JpMVahm-SMWoBBJ9dWiHR0_GujfU1wORVgK9_Mun2-jFpC10JUCgZumzYePPZ3m0KwnDYWXRn5qW1qFe2bfI11rH8oARCFX6jVXFWRuzUMpaX51lg3f_8nfEtgZfv645KmRwypCoUlqfYYV1SrOFgZLug/file\r\n",
      "Resolving uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com (uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com)... 162.125.64.15\r\n",
      "Connecting to uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com (uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /cd/0/inline2/BwXA75GPhKHHfgshS-Q1YVUuYhneO0ndMIUNpVY4KQWtpIz-1sZuxcDrcOExRZHWTRCzAAdSH8SAlv8dvo3QA4dY7JwpCcMfEoKf2jB5Y5bdZ-oa5vIbBTMASi6aNAfBGUWPo2SsmU98I98oJwgc5dVwJaZ45Th-23WrdLDAcqSOFO6oaN70VTdgOLxEDwamdhkQ92d0yXmAY1g8G5SiTY8pYr_8SMKPWLnHUfvNOvuRxdYwsl_5FZ0pUyyeb6dj2MetLf48GLAqI62oqFJcmpel2j8WTWUosvaQyMrNIlcHksa8k0-h7jF_yC4Wl6tdsJrJs3u94S-2c9Rz-CseVq7CP-KRnNIHZJMx-9z17kf2pJnSVwnCjZyfr_jXX7s-BHVgJtL5HCXRYfgOrexS1_PTfu7-kHq08AN8em7LlJv9qw/file [following]\r\n",
      "--2022-11-07 21:23:00--  https://uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com/cd/0/inline2/BwXA75GPhKHHfgshS-Q1YVUuYhneO0ndMIUNpVY4KQWtpIz-1sZuxcDrcOExRZHWTRCzAAdSH8SAlv8dvo3QA4dY7JwpCcMfEoKf2jB5Y5bdZ-oa5vIbBTMASi6aNAfBGUWPo2SsmU98I98oJwgc5dVwJaZ45Th-23WrdLDAcqSOFO6oaN70VTdgOLxEDwamdhkQ92d0yXmAY1g8G5SiTY8pYr_8SMKPWLnHUfvNOvuRxdYwsl_5FZ0pUyyeb6dj2MetLf48GLAqI62oqFJcmpel2j8WTWUosvaQyMrNIlcHksa8k0-h7jF_yC4Wl6tdsJrJs3u94S-2c9Rz-CseVq7CP-KRnNIHZJMx-9z17kf2pJnSVwnCjZyfr_jXX7s-BHVgJtL5HCXRYfgOrexS1_PTfu7-kHq08AN8em7LlJv9qw/file\r\n",
      "Reusing existing connection to uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 996528740 (950M) [application/zip]\r\n",
      "Saving to: ‘hpac_lower_tokenized.zip’\r\n",
      "\r\n",
      "hpac_lower_tokenize  99%[==================> ] 947.75M   487KB/s    in 23m 25s \r\n",
      "\r\n",
      "2022-11-07 21:46:26 (691 KB/s) - Connection closed at byte 993787904. Retrying.\r\n",
      "\r\n",
      "--2022-11-07 21:46:27--  (try: 2)  https://uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com/cd/0/inline2/BwXA75GPhKHHfgshS-Q1YVUuYhneO0ndMIUNpVY4KQWtpIz-1sZuxcDrcOExRZHWTRCzAAdSH8SAlv8dvo3QA4dY7JwpCcMfEoKf2jB5Y5bdZ-oa5vIbBTMASi6aNAfBGUWPo2SsmU98I98oJwgc5dVwJaZ45Th-23WrdLDAcqSOFO6oaN70VTdgOLxEDwamdhkQ92d0yXmAY1g8G5SiTY8pYr_8SMKPWLnHUfvNOvuRxdYwsl_5FZ0pUyyeb6dj2MetLf48GLAqI62oqFJcmpel2j8WTWUosvaQyMrNIlcHksa8k0-h7jF_yC4Wl6tdsJrJs3u94S-2c9Rz-CseVq7CP-KRnNIHZJMx-9z17kf2pJnSVwnCjZyfr_jXX7s-BHVgJtL5HCXRYfgOrexS1_PTfu7-kHq08AN8em7LlJv9qw/file\r\n",
      "Connecting to uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com (uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 206 Partial Content\r\n",
      "Length: 996528740 (950M), 2740836 (2.6M) remaining [application/zip]\r\n",
      "Saving to: ‘hpac_lower_tokenized.zip’\r\n",
      "\r\n",
      "hpac_lower_tokenize 100%[+++++++++++++++++++>] 950.36M   903KB/s    in 3.0s    \r\n",
      "\r\n",
      "2022-11-07 21:46:32 (903 KB/s) - ‘hpac_lower_tokenized.zip’ saved [996528740/996528740]\r\n",
      "\r\n",
      "--2022-11-07 21:46:32--  https://www.dropbox.com/s/3vdz0mouvex8abd/hpac_splits.zip\r\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18\r\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /s/raw/3vdz0mouvex8abd/hpac_splits.zip [following]\r\n",
      "--2022-11-07 21:46:36--  https://www.dropbox.com/s/raw/3vdz0mouvex8abd/hpac_splits.zip\r\n",
      "Reusing existing connection to www.dropbox.com:443.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com/cd/0/inline/BwWUT3hrv_WgQPguHA7uNt5s3bOfAk6-p1mtO_0dRs9aNyjHGw919KuXeNc7oY_rrdQjhBLSv1CZpousig5U3y670N17zeWwkdzVi6KID75wd-1X-PivVVUbfxSjdJbudggTZQ5gdrVCxQlk_8BXTHSMqfwbiU4g1P5VBb08YoruCw/file# [following]\r\n",
      "--2022-11-07 21:46:36--  https://uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com/cd/0/inline/BwWUT3hrv_WgQPguHA7uNt5s3bOfAk6-p1mtO_0dRs9aNyjHGw919KuXeNc7oY_rrdQjhBLSv1CZpousig5U3y670N17zeWwkdzVi6KID75wd-1X-PivVVUbfxSjdJbudggTZQ5gdrVCxQlk_8BXTHSMqfwbiU4g1P5VBb08YoruCw/file\r\n",
      "Resolving uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com (uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com)... 162.125.64.15\r\n",
      "Connecting to uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com (uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /cd/0/inline2/BwX1RZANc7r_H2vfQ8TBZTMSoDcWrsgD8wcDxtnqWHBJdi8qajBddQD8EaA-dsfSflyoStkyM3KCYJrg1XCS67n5HttZrthzGEF2l2JbJWGbB2D-BwLPD_Jckmd8dM8hArz8tbu28EmyrKcTTF41d3JI9B3TQgOQXTd6XU_GC7j5WIxrVu2jP5Bd7Gn5H-Xs0vfmR1pc1AF6C6whb83Lw0lUWyRfzlj_yFW_mZDIaUvWWKxGqG4jWYmRqlA-yj1Gs-P61DFQjBYjwmg2eB9gUeuVpwfsZotQU5CX63-8oQLZQ1DpwVWi9sJKquwAlhQmlZSQaUwK_Twadmd7E7HY3CMeAaErL6rwpLcsNC_G_8KIB2nq3B1GT2KRY4F7wWG8LqTgqfavmE4Em6rYHtUDTSKWSioHJ8siRz6bbAi80kLwmw/file [following]\r\n",
      "--2022-11-07 21:46:44--  https://uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com/cd/0/inline2/BwX1RZANc7r_H2vfQ8TBZTMSoDcWrsgD8wcDxtnqWHBJdi8qajBddQD8EaA-dsfSflyoStkyM3KCYJrg1XCS67n5HttZrthzGEF2l2JbJWGbB2D-BwLPD_Jckmd8dM8hArz8tbu28EmyrKcTTF41d3JI9B3TQgOQXTd6XU_GC7j5WIxrVu2jP5Bd7Gn5H-Xs0vfmR1pc1AF6C6whb83Lw0lUWyRfzlj_yFW_mZDIaUvWWKxGqG4jWYmRqlA-yj1Gs-P61DFQjBYjwmg2eB9gUeuVpwfsZotQU5CX63-8oQLZQ1DpwVWi9sJKquwAlhQmlZSQaUwK_Twadmd7E7HY3CMeAaErL6rwpLcsNC_G_8KIB2nq3B1GT2KRY4F7wWG8LqTgqfavmE4Em6rYHtUDTSKWSioHJ8siRz6bbAi80kLwmw/file\r\n",
      "Reusing existing connection to uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 18284862 (17M) [application/zip]\r\n",
      "Saving to: ‘hpac_splits.zip’\r\n",
      "\r\n",
      "hpac_splits.zip     100%[===================>]  17.44M   806KB/s    in 32s     \r\n",
      "\r\n",
      "2022-11-07 21:47:16 (565 KB/s) - ‘hpac_splits.zip’ saved [18284862/18284862]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://www.dropbox.com/s/23xet9kvbqna1qs/hpac_raw.zip\n",
    "!wget -nc https://www.dropbox.com/s/gwfgmomdbetvdye/hpac_lower_tokenized.zip\n",
    "!wget -nc https://www.dropbox.com/s/3vdz0mouvex8abd/hpac_splits.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Импортируем базовые библиотеки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/germanarutunov/Projects/ftiad/venv/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.2' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/germanarutunov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/germanarutunov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/germanarutunov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/germanarutunov/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/germanarutunov/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/germanarutunov/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    "import re\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "import nltk\n",
    "\n",
    "# скачиваем модули для NLTK\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Данные\n",
    "\n",
    "Распакуем и переименуем данные для удобства"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Как папки будут называться в итоге\n",
    "raw_data_dir = Path('hpac_raw')\n",
    "tokenized_data_dir = Path('hpac_lower_tokenized')\n",
    "split_data_dir = Path('hpac_splits')\n",
    "\n",
    "if not raw_data_dir.exists():\n",
    "    !unzip hpac_raw\n",
    "if not tokenized_data_dir.exists():\n",
    "    !unzip hpac_lower_tokenized\n",
    "if not split_data_dir.exists():\n",
    "    !unzip hpac_splits\n",
    "shutil.rmtree('__MACOSX', ignore_errors=True)\n",
    "\n",
    "folder_mapping = {\n",
    "    'fanfiction_texts': raw_data_dir.name,\n",
    "    'hpac_source': tokenized_data_dir.name,\n",
    "    'hpac_corpus': split_data_dir.name,\n",
    "}\n",
    "\n",
    "for name, new_name in folder_mapping.items():\n",
    "    fp = Path(name)\n",
    "    if fp.exists():\n",
    "        fp.rename(new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36225\r\n"
     ]
    }
   ],
   "source": [
    "!ls hpac_lower_tokenized | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, test, dev файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(split_data_dir / 'hpac_training_128.tsv',\n",
    "                 names=['target', 'text'],\n",
    "                 index_col=0,\n",
    "                 sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                       target  \\\n7642954.0.676      RIDDIKULUS   \n10443333.0.5753    RIDDIKULUS   \n4703706.0.8690        STUPEFY   \n4593427.0.1815          ACCIO   \n4278446.0.2692   EXPELLIARMUS   \n\n                                                              text  \n7642954.0.676    were staring at her . she was up next to face ...  \n10443333.0.5753  that whole time . her first reaction , for whi...  \n4703706.0.8690   we watched his inglorious withdrawal together ...  \n4593427.0.1815   my wand , `` incendio . '' this wretched chill...  \n4278446.0.2692   already compared ours , they 're the same ever...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7642954.0.676</th>\n      <td>RIDDIKULUS</td>\n      <td>were staring at her . she was up next to face ...</td>\n    </tr>\n    <tr>\n      <th>10443333.0.5753</th>\n      <td>RIDDIKULUS</td>\n      <td>that whole time . her first reaction , for whi...</td>\n    </tr>\n    <tr>\n      <th>4703706.0.8690</th>\n      <td>STUPEFY</td>\n      <td>we watched his inglorious withdrawal together ...</td>\n    </tr>\n    <tr>\n      <th>4593427.0.1815</th>\n      <td>ACCIO</td>\n      <td>my wand , `` incendio . '' this wretched chill...</td>\n    </tr>\n    <tr>\n      <th>4278446.0.2692</th>\n      <td>EXPELLIARMUS</td>\n      <td>already compared ours , they 're the same ever...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "('RIDDIKULUS',\n \"were staring at her . she was up next to face the boggart in defense against the dark arts class . she was not scared , but what she was worried about was what had happened with lysander . she looked up at the boggart in front of her which had previously been a humongous spider . its eyes locked on her . before she could think of what frightened her , the spider transformed into lysander . he was dying . there were giggles coming from the male and female hufflepuff students . there was a smirk on lorcan 's face . `` lily help me '' i ca n't fail this class because of a secret love . lily lifted her wand and said , ``\")"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][0], df.iloc[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 1. [2 балла] Эксплоративный анализ\n",
    "1. Найдите топ-1000 слов по частоте без учета стоп-слов."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузим токенизированные тексты и уберем пунктуацию"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/36225 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "232b084bdb3a4f1985725daf2537dde4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/5f/tg63xq8x6jl7df71n9v3_g9c0000gn/T/ipykernel_21422/2847400149.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0mtop_nonstopwords_fp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'top_nonstopwords.pkl'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m \u001B[0mpreprocessed_texts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_text_no_punc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_data_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/5f/tg63xq8x6jl7df71n9v3_g9c0000gn/T/ipykernel_21422/2847400149.py\u001B[0m in \u001B[0;36mread_text_no_punc\u001B[0;34m(text_dir, num_texts)\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0mfps\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfps\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mnum_texts\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     return [re.sub(r\"[^\\w\\s'-]\", '', fp.read_text())\n\u001B[0m\u001B[1;32m     10\u001B[0m             for fp in tqdm(fps)]\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/5f/tg63xq8x6jl7df71n9v3_g9c0000gn/T/ipykernel_21422/2847400149.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0mfps\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfps\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mnum_texts\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     return [re.sub(r\"[^\\w\\s'-]\", '', fp.read_text())\n\u001B[0m\u001B[1;32m     10\u001B[0m             for fp in tqdm(fps)]\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/re.py\u001B[0m in \u001B[0;36msub\u001B[0;34m(pattern, repl, string, count, flags)\u001B[0m\n\u001B[1;32m    208\u001B[0m     \u001B[0ma\u001B[0m \u001B[0mcallable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mit\u001B[0m\u001B[0;31m'\u001B[0m\u001B[0ms\u001B[0m \u001B[0mpassed\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mMatch\u001B[0m \u001B[0mobject\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mmust\u001B[0m \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    209\u001B[0m     a replacement string to be used.\"\"\"\n\u001B[0;32m--> 210\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_compile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpattern\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msub\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrepl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstring\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcount\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    211\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    212\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0msubn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpattern\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrepl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstring\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcount\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Удаляем пунктуацию, не считая тире\n",
    "def read_text_no_punc(text_dir: Path, num_texts: Optional[int] = None):\n",
    "\n",
    "    fps = list(text_dir.glob('*'))\n",
    "\n",
    "    if num_texts:\n",
    "        fps = fps[:num_texts]\n",
    "\n",
    "    return [re.sub(r\"[^\\w\\s'-]\", '', fp.read_text())\n",
    "            for fp in tqdm(fps)]\n",
    "\n",
    "top_nonstopwords_fp = 'top_nonstopwords.pkl'\n",
    "preprocessed_texts = read_text_no_punc(raw_data_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%time word_counter, tokenized_texts = utils.get_word_counters_mp(preprocessed_texts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_top_words_from_counter(counter, top_n):\n",
    "    return sorted([(word, count) for word, count in counter.items()],\n",
    "                  key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "print('Топ-1000 слов по встречаемости:')\n",
    "top_nonstopwords = get_top_words_from_counter(word_counter, 1000)\n",
    "joblib.dump(top_nonstopwords, top_nonstopwords_fp)\n",
    "top_nonstopwords"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "2. Найдите топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "names_fp = Path('names.txt')\n",
    "names = names_fp.read_text().split('\\n')\n",
    "name_counters_fp = 'name_counters.pkl'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%time name_counter, name_pair_counter, prof_name_counter = utils.count_names_mp(tokenized_texts, names)\n",
    "counter_dump = (dict(name_counter), dict(name_pair_counter), dict(prof_name_counter))\n",
    "joblib.dump(counter_dump, name_counters_fp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name_counter, name_pair_counter, prof_name_counter = joblib.load(name_counters_fp)\n",
    "\n",
    "print('Топ-10 имен по встречаемости:')\n",
    "get_top_words_from_counter(name_counter, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Топ-10 пар имя + фамилия по встречаемости:')\n",
    "get_top_words_from_counter(name_pair_counter, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Топ-10 пар профессор + имя / фамилия по встречаемости:')\n",
    "get_top_words_from_counter(prof_name_counter, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "[бонус] Найдите еще что-то интересное в корпусе (что-то специфичное для фанфиков или фентези-тематики)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 2. [2 балла] Модели представления слов\n",
    "Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса HPAC."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/germanarutunov/DataspellProjects/hw-1-nlp-hse-2022-AndBoyS/hw\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "data_dir = Path('data')\n",
    "split_data_dir = data_dir / 'hpac_splits'\n",
    "\n",
    "ft_data_dir = data_dir / 'ft'\n",
    "ft_data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "ft_train_file = ft_data_dir / 'hpac_ft.train'\n",
    "ft_dev_file = ft_data_dir / 'hpac_ft.dev'\n",
    "\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "ft_model = models_dir / 'ft.ftz'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "should_train_ft = True\n",
    "should_train_split_ft = True\n",
    "should_dev_split_ft = True\n",
    "\n",
    "if ft_train_file.exists():\n",
    "    should_train_split_ft = False\n",
    "\n",
    "if ft_dev_file.exists():\n",
    "    should_dev_split_ft = False\n",
    "\n",
    "if ft_model.exists():\n",
    "    should_train_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "if should_train_split_ft:\n",
    "    train_df = pd.read_csv(split_data_dir / 'hpac_training_128.tsv',\n",
    "                           names=['target', 'text'],\n",
    "                           index_col=0,\n",
    "                           sep='\\t', header=None)\n",
    "    with open(ft_train_file, mode='a') as f:\n",
    "        for i, (target, text) in tqdm(train_df.iterrows(), desc='Processing train split for fastText'):\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "            f.write(f'__label__{target}\\t{text}\\n')\n",
    "    should_train_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "if should_dev_split_ft:\n",
    "    dev_df = pd.read_csv(split_data_dir / 'hpac_dev_128.tsv',\n",
    "                         names=['target', 'text'],\n",
    "                         index_col=0,\n",
    "                         sep='\\t', header=None)\n",
    "    with open(ft_dev_file, mode='a') as f:\n",
    "        for i, (target, text) in tqdm(dev_df.iterrows(), desc='Processing dev split for fastText'):\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "            f.write(f'__label__{target}\\t{text}\\n')\n",
    "    should_dev_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import fasttext"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "if should_train_ft:\n",
    "    model = fasttext.train_supervised(\n",
    "        input=str(ft_train_file),\n",
    "        autotuneValidationFile=str(ft_dev_file),\n",
    "        autotuneModelSize='5M',\n",
    "        autotuneDuration=1200\n",
    "    )\n",
    "    model.save_model(str(ft_model))\n",
    "    should_train_ft = False\n",
    "else:\n",
    "    model = fasttext.load_model(str(ft_model))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.1 Синонимы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.8944582343101501, 'rescue'),\n (0.888363242149353, 'ridiculously'),\n (0.8825259208679199, 'jeremiah'),\n (0.8562796115875244, 'witnessed'),\n (0.8521283864974976, 'hounding'),\n (0.8432715535163879, 'none'),\n (0.8367645740509033, 'hints'),\n (0.8300632834434509, 'weaved'),\n (0.82944256067276, 'sacred'),\n (0.8291577100753784, 'betas')]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors('wizard')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.2 Ассоциации"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.9383688569068909, 'combats'),\n (0.9187878966331482, 'mocked'),\n (0.9064145088195801, 'ooooo'),\n (0.9061028361320496, 'force'),\n (0.903786301612854, 'roared'),\n (0.9032526612281799, 'jezlyn'),\n (0.8954090476036072, 'wheezley'),\n (0.8932932019233704, 'abstract'),\n (0.8926324844360352, 'fenir'),\n (0.8868676424026489, 'caged')]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_analogies('zombie', 'monster', 'beast')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.3 Лишние слова"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Не знаю, как это тут сделать"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "top_nonstopwords = joblib.load(data_dir / 'top_nonstopwords.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "log_dir = Path('./logs/')\n",
    "log_dir.mkdir(exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "with open(log_dir / 'metadata.tsv', 'w') as f:\n",
    "    for w, _ in top_nonstopwords:\n",
    "        f.write(\"{}\\n\".format(w))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "embeddings = np.zeros((len(top_nonstopwords), model.get_dimension()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "for i, (w, _) in enumerate(top_nonstopwords):\n",
    "    embeddings[i] = model.get_word_vector(w)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 23:56:25.890421: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "embedding_var = tf.Variable(embeddings, name='fastText')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from tensorboard.plugins import projector\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(embedding=embedding_var)\n",
    "checkpoint.save(log_dir / 'embedding.ckpt')\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-774efd21e8d7a1b2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-774efd21e8d7a1b2\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 3. [5 баллов] Классификация текстов\n",
    "Задача классификации формулируется так: данный фрагмент фанфика описывают какую-то ситуацию, которая предшествует произнесению заклинания. Требуется по тексту предсказать, какое именно заклинание будет произнесено. Таким образом, заклинание - это фактически метка класса. Основная мера качества – macro $F_1$.\n",
    "Обучите несколько классификаторов и сравните их между собой. Оцените качество классификаторов на частых и редких классах. Какие классы чаще всего оказываются перепутаны? Связаны ли ошибки со смыслом заклинаний?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 fastText"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "ft_data_dir = data_dir / 'ft'\n",
    "\n",
    "ft_test_file = ft_data_dir / 'hpac_ft.test'\n",
    "\n",
    "models_dir = Path('models')\n",
    "ft_model = models_dir / 'ft.ftz'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "should_test_split_ft = True\n",
    "\n",
    "if ft_test_file.exists():\n",
    "    should_test_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "if should_test_split_ft:\n",
    "    test_df = pd.read_csv(split_data_dir / 'hpac_test_128.tsv',\n",
    "                           names=['target', 'text'],\n",
    "                           index_col=0,\n",
    "                           sep='\\t', header=None)\n",
    "    with open(ft_test_file, mode='a') as f:\n",
    "        for i, (target, text) in tqdm(test_df.iterrows(), desc='Processing test split for fastText'):\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "            f.write(f'__label__{target}\\t{text}\\n')\n",
    "    should_test_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model(str(ft_model))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "scores = model.test_label(str(ft_test_file))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 for fastText is 0.3122\n"
     ]
    }
   ],
   "source": [
    "macro_f1 = []\n",
    "\n",
    "for label, metrics in scores.items():\n",
    "    if np.isnan(metrics['f1score']):\n",
    "        continue\n",
    "    macro_f1 = metrics['f1score']\n",
    "\n",
    "macro_f1 = np.mean(macro_f1)\n",
    "print(f'Macro F1 for fastText is {macro_f1:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
