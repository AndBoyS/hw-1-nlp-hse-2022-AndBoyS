{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Команда: Герман Арутюнов, Алексей Корякин, Андрей Бахматов, Владимир Морозов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "## Harry Potter and the Action Prediction Challenge from Natural Language\n",
    "\n",
    "*deadline*: 14 ноября 2022, 23:59\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусом Harry Potter and the Action Prediction Challenge. Корпус собран из фанфиков о Гарри Поттере и состоит из двух частей: 1) сырые тексты, 2) фрагменты текстов, описывающих ситуацию, в которой произнесено заклинание.\n",
    "\n",
    "Корпус описан в статье: https://arxiv.org/pdf/1905.11037.pdf\n",
    "\n",
    "David Vilares and Carlos Gómez-Rodríguez. Harry Potter and the Action Prediction Challenge from Natural Language. 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics. To appear.\n",
    "\n",
    "Код для сбора корпуса находится в репозитории: https://github.com/aghie/hpac . Корпус можно скачать по инструкции из этого репозитория, но для экономии времени авторы задания уже скачали и подготовили данные к работе. \n",
    "\n",
    "Ссылки на собранный корпус: \n",
    "* Сырые тексты:  https://www.dropbox.com/s/23xet9kvbqna1qs/hpac_raw.zip?dl=0\n",
    "* Токенизированные тексты в нижнем регистре: https://www.dropbox.com/s/gwfgmomdbetvdye/hpac_lower_tokenized.zip?dl=0\n",
    "* train-test-dev: https://www.dropbox.com/s/3vdz0mouvex8abd/hpac_splits.zip?dl=0\n",
    "\n",
    "Части 1, 2 задания должны быть выполнены на полных текстах (сырых или предобработанных -- на ваше усмотрение), Часть 3 – на разбиение на тестовое, отладочное и обучающее множества. Тестовое множество должно быть использовано исключительно для тестирования моделей, обучающее и отладочное – для выбора модели и параметров. \n",
    "\n",
    "В статье и репозитории вы найдете идеи, которые помогут вам выполнить домашнее задание. Их стоит воспринимать как руководство к действию, и не стоит их копировать и переиспользовать. Обученные модели использовать не нужно, код для их обучения можно использовать как подсказку. \n",
    "\n",
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 3-х человек.\n",
    "2. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо ipython-тетрадке. \n",
    "3. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "4. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "5. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "6. Плагиат и любое недобросоветсное цитирование приводит к обнуление оценки. \n",
    "\n",
    "\n",
    "## Часть 1. [2 балла] Эксплоративный анализ \n",
    "1. Найдите топ-1000 слов по частоте без учета стоп-слов.\n",
    "2. Найдите топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия. \n",
    "\n",
    "[бонус] Постройте тематическую модель по корпусу HPAC.\n",
    "\n",
    "[бонус] Найдите еще что-то интересное в корпусе (что-то специфичное для фанфиков или фентези-тематики)\n",
    "\n",
    "## Часть 2. [2 балла] Модели представления слов \n",
    "Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса HPAC.\n",
    "1. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели. \n",
    "2. Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io).\n",
    "\n",
    "## Часть 3. [5 баллов] Классификация текстов\n",
    "Задача классификации формулируется так: данный фрагмент фанфика описывают какую-то ситуацию, которая предшествует произнесению заклинания. Требуется по тексту предсказать, какое именно заклинание будет произнесено. Таким образом, заклинание - это фактически метка класса. Основная мера качества – macro $F_1$.\n",
    "Обучите несколько классификаторов и сравните их между собой. Оцените качество классификаторов на частых и редких классах. Какие классы чаще всего оказываются перепутаны? Связаны ли ошибки со смыслом заклинаний?\n",
    "\n",
    "Используйте фрагменты из множества train для обучения, из множества dev для отладки, из множества test – для тестирования и получения итоговых результатов. \n",
    "\n",
    "1. [1 балл] Используйте fastText в качестве baseline-классификатора.\n",
    "2. [2 балла] Используйте сверточные  или реккурентные сети в качестве более продвинутого классификатора. Поэкспериментируйте с количеством и размерностью фильтров, используйте разные размеры окон, попробуйте использовать $k$-max pooling. \n",
    "3. [2 балла] Попробуйте расширить обучающее множество за счет аугментации данных. Если вам понадобится словарь синонимов, можно использовать WordNet (ниже вы найдете примеры).\n",
    "\n",
    "[бонус] Используйте результат max pooling'а как эмбеддинг входного текста. Визуализируйте эмбеддинги 500-1000 предложений из обучающего множества и изучите свойства получившегося пространства.\n",
    "\n",
    "[бонус] Используйте ваш любимый классификатор и любые (честные) способы повышения качества классификации и получите macro $F_1$ больше 0.5.\n",
    "\n",
    "## Часть 4. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Читали ли вы сами Гарри Поттера или фанфики о нем и помогло ли вам знание предметной области в выполнении домашнего задания?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "/home/natitov/workflow/Laboratory_andrew/temp/hw-1-nlp-hse-2022-AndBoyS/hw/data\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://www.dropbox.com/s/yp7fenfs4c8ohef/hpac_raw.zip\n",
    "!wget -nc https://www.dropbox.com/s/u0l2fkkmtmjumbx/hpac_lower_tokenized.zip\n",
    "!wget -nc https://www.dropbox.com/s/aogtja9upycdqv4/hpac_splits.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Импортируем базовые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/natitov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/natitov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/natitov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/natitov/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/natitov/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/natitov/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    "import re\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "import nltk\n",
    "# скачиваем модули для NLTK\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Данные\n",
    "\n",
    "Распакуем и переименуем данные для удобства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Как папки будут называться в итоге\n",
    "raw_data_dir = Path('hpac_raw')\n",
    "tokenized_data_dir = Path('hpac_lower_tokenized')\n",
    "split_data_dir = Path('hpac_splits')\n",
    "\n",
    "if not raw_data_dir.exists():\n",
    "    !unzip hpac_raw\n",
    "if not tokenized_data_dir.exists():\n",
    "    !unzip hpac_lower_tokenized\n",
    "if not split_data_dir.exists():\n",
    "    !unzip hpac_splits\n",
    "shutil.rmtree('__MACOSX', ignore_errors=True)\n",
    "\n",
    "folder_mapping = {\n",
    "    'fanfiction_texts': raw_data_dir.name,\n",
    "    'hpac_source': tokenized_data_dir.name,\n",
    "    'hpac_corpus': split_data_dir.name,\n",
    "}\n",
    "\n",
    "for name, new_name in folder_mapping.items():\n",
    "    fp = Path(name)\n",
    "    if fp.exists():\n",
    "        fp.rename(new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36225\n"
     ]
    }
   ],
   "source": [
    "!ls hpac_lower_tokenized | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, test, dev файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(split_data_dir / 'hpac_training_128.tsv',\n",
    "                 names=['target', 'text'],\n",
    "                 index_col=0,\n",
    "                 sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7642954.0.676</th>\n",
       "      <td>RIDDIKULUS</td>\n",
       "      <td>were staring at her . she was up next to face ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10443333.0.5753</th>\n",
       "      <td>RIDDIKULUS</td>\n",
       "      <td>that whole time . her first reaction , for whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703706.0.8690</th>\n",
       "      <td>STUPEFY</td>\n",
       "      <td>we watched his inglorious withdrawal together ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4593427.0.1815</th>\n",
       "      <td>ACCIO</td>\n",
       "      <td>my wand , `` incendio . '' this wretched chill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4278446.0.2692</th>\n",
       "      <td>EXPELLIARMUS</td>\n",
       "      <td>already compared ours , they 're the same ever...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       target  \\\n",
       "7642954.0.676      RIDDIKULUS   \n",
       "10443333.0.5753    RIDDIKULUS   \n",
       "4703706.0.8690        STUPEFY   \n",
       "4593427.0.1815          ACCIO   \n",
       "4278446.0.2692   EXPELLIARMUS   \n",
       "\n",
       "                                                              text  \n",
       "7642954.0.676    were staring at her . she was up next to face ...  \n",
       "10443333.0.5753  that whole time . her first reaction , for whi...  \n",
       "4703706.0.8690   we watched his inglorious withdrawal together ...  \n",
       "4593427.0.1815   my wand , `` incendio . '' this wretched chill...  \n",
       "4278446.0.2692   already compared ours , they 're the same ever...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RIDDIKULUS',\n",
       " \"were staring at her . she was up next to face the boggart in defense against the dark arts class . she was not scared , but what she was worried about was what had happened with lysander . she looked up at the boggart in front of her which had previously been a humongous spider . its eyes locked on her . before she could think of what frightened her , the spider transformed into lysander . he was dying . there were giggles coming from the male and female hufflepuff students . there was a smirk on lorcan 's face . `` lily help me '' i ca n't fail this class because of a secret love . lily lifted her wand and said , ``\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][0], df.iloc[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Часть 1. [2 балла] Эксплоративный анализ\n",
    "1. Найдите топ-1000 слов по частоте без учета стоп-слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Загрузим токенизированные тексты и уберем пунктуацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84082569329a49debf98766d7e9d5a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Удаляем пунктуацию, не считая тире\n",
    "def read_text_no_punc(text_dir: Path, num_texts: Optional[int] = None):\n",
    "\n",
    "    fps = list(text_dir.glob('*'))\n",
    "\n",
    "    if num_texts:\n",
    "        fps = fps[:num_texts]\n",
    "\n",
    "    return [re.sub(r\"[^\\w\\s'-]\", '', fp.read_text())\n",
    "            for fp in tqdm(fps)]\n",
    "\n",
    "top_nonstopwords_fp = 'top_nonstopwords.pkl'\n",
    "preprocessed_texts = read_text_no_punc(raw_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.4 s, sys: 20.9 s, total: 55.4 s\n",
      "Wall time: 21min 28s\n"
     ]
    }
   ],
   "source": [
    "%time word_counter, tokenized_texts = utils.get_word_counters_mp(preprocessed_texts, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-1000 слов по встречаемости:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Harry', 3947884),\n",
       " ('said', 2238744),\n",
       " ('would', 1846832),\n",
       " ('Hermione', 1811320),\n",
       " ('could', 1651666),\n",
       " ('back', 1381210),\n",
       " ('Draco', 1373178),\n",
       " ('one', 1273823),\n",
       " ('like', 1203811),\n",
       " ('know', 1163832),\n",
       " ('eyes', 1026301),\n",
       " ('time', 982652),\n",
       " ('Ron', 894159),\n",
       " ('looked', 892135),\n",
       " ('asked', 821670),\n",
       " ('get', 805996),\n",
       " ('around', 762014),\n",
       " ('see', 710803),\n",
       " ('going', 710542),\n",
       " ('think', 699465),\n",
       " ('head', 686617),\n",
       " ('even', 673076),\n",
       " ('still', 651545),\n",
       " ('face', 649180),\n",
       " ('Severus', 648923),\n",
       " ('way', 646887),\n",
       " ('Ginny', 631641),\n",
       " ('hand', 629513),\n",
       " ('Sirius', 621936),\n",
       " ('go', 618980),\n",
       " ('room', 611943),\n",
       " ('want', 603256),\n",
       " ('thought', 600507),\n",
       " ('Snape', 591253),\n",
       " ('Potter', 589814),\n",
       " ('something', 576982),\n",
       " ('away', 576145),\n",
       " ('much', 565970),\n",
       " ('right', 546634),\n",
       " ('never', 526015),\n",
       " ('two', 525447),\n",
       " ('knew', 522128),\n",
       " ('look', 519442),\n",
       " ('made', 508444),\n",
       " ('really', 484552),\n",
       " ('first', 484306),\n",
       " ('Malfoy', 476955),\n",
       " ('felt', 474470),\n",
       " ('turned', 471039),\n",
       " ('wand', 469119),\n",
       " ('Dumbledore', 466794),\n",
       " ('little', 465488),\n",
       " ('James', 462525),\n",
       " ('well', 443267),\n",
       " ('got', 441520),\n",
       " ('took', 433741),\n",
       " ('make', 429771),\n",
       " ('Remus', 428829),\n",
       " ('Lily', 414994),\n",
       " ('let', 413876),\n",
       " ('good', 409714),\n",
       " ('door', 406526),\n",
       " ('say', 401243),\n",
       " ('us', 397875),\n",
       " ('voice', 395231),\n",
       " ('Voldemort', 389298),\n",
       " ('long', 384652),\n",
       " ('told', 384290),\n",
       " ('though', 384198),\n",
       " ('need', 383189),\n",
       " ('take', 380844),\n",
       " ('last', 380065),\n",
       " ('left', 379111),\n",
       " ('sure', 378531),\n",
       " ('looking', 377927),\n",
       " ('come', 376124),\n",
       " ('tell', 368579),\n",
       " ('man', 367494),\n",
       " ('wanted', 366554),\n",
       " ('anything', 351339),\n",
       " ('nodded', 340783),\n",
       " ('came', 340032),\n",
       " ('next', 337257),\n",
       " ('moment', 334576),\n",
       " ('saw', 331356),\n",
       " ('went', 324738),\n",
       " ('hands', 321677),\n",
       " ('people', 314726),\n",
       " ('help', 313947),\n",
       " ('things', 313064),\n",
       " ('love', 312124),\n",
       " ('smiled', 311659),\n",
       " ('enough', 310343),\n",
       " ('Well', 306333),\n",
       " ('day', 305965),\n",
       " ('found', 304188),\n",
       " ('another', 303788),\n",
       " ('Oh', 302345),\n",
       " ('mind', 301563),\n",
       " ('hair', 298055),\n",
       " ('ca', 297641),\n",
       " ('bit', 293502),\n",
       " ('seemed', 293028),\n",
       " ('year', 293002),\n",
       " ('find', 292440),\n",
       " ('ever', 291315),\n",
       " ('always', 289004),\n",
       " ('Hogwarts', 287751),\n",
       " ('behind', 285857),\n",
       " ('bed', 284961),\n",
       " ('thing', 283931),\n",
       " ('started', 280471),\n",
       " ('boy', 278381),\n",
       " ('trying', 277541),\n",
       " ('feel', 277218),\n",
       " ('put', 273555),\n",
       " ('Yes', 272336),\n",
       " ('heard', 271881),\n",
       " ('night', 266032),\n",
       " ('smile', 265134),\n",
       " ('life', 264432),\n",
       " ('gave', 261710),\n",
       " ('side', 256600),\n",
       " ('might', 256140),\n",
       " ('years', 256082),\n",
       " ('Professor', 255398),\n",
       " ('nothing', 254939),\n",
       " ('Weasley', 254706),\n",
       " ('sat', 253849),\n",
       " ('began', 253221),\n",
       " ('better', 253103),\n",
       " ('walked', 250109),\n",
       " ('since', 244176),\n",
       " ('done', 244077),\n",
       " ('tried', 243966),\n",
       " ('already', 242400),\n",
       " ('stood', 242326),\n",
       " ('without', 238251),\n",
       " ('pulled', 237839),\n",
       " ('front', 237563),\n",
       " ('almost', 237219),\n",
       " ('small', 235368),\n",
       " ('friends', 234743),\n",
       " ('course', 231632),\n",
       " ('body', 230498),\n",
       " ('quickly', 230163),\n",
       " ('father', 229331),\n",
       " ('house', 227769),\n",
       " ('towards', 227335),\n",
       " ('someone', 227251),\n",
       " ('best', 224046),\n",
       " ('place', 223040),\n",
       " ('arms', 221749),\n",
       " ('keep', 221424),\n",
       " ('else', 221406),\n",
       " ('girl', 220160),\n",
       " ('Neville', 219347),\n",
       " ('table', 216821),\n",
       " ('also', 215880),\n",
       " ('work', 215592),\n",
       " ('mean', 214714),\n",
       " ('every', 214514),\n",
       " ('Albus', 213823),\n",
       " ('Lord', 211108),\n",
       " ('three', 209797),\n",
       " ('everything', 209644),\n",
       " ('family', 209059),\n",
       " ('Lucius', 208661),\n",
       " ('magic', 207577),\n",
       " ('Dark', 207128),\n",
       " ('happened', 204555),\n",
       " ('replied', 203589),\n",
       " ('old', 202758),\n",
       " ('give', 202656),\n",
       " ('mouth', 202148),\n",
       " ('everyone', 201968),\n",
       " ('together', 201605),\n",
       " ('finally', 201416),\n",
       " ('school', 200458),\n",
       " ('many', 198999),\n",
       " ('end', 198727),\n",
       " ('quite', 197829),\n",
       " ('open', 197077),\n",
       " ('Death', 196875),\n",
       " ('floor', 195649),\n",
       " ('able', 194571),\n",
       " ('world', 194092),\n",
       " ('must', 193789),\n",
       " ('leave', 192256),\n",
       " ('arm', 192066),\n",
       " ('new', 191983),\n",
       " ('words', 190746),\n",
       " ('mother', 190289),\n",
       " ('lips', 190010),\n",
       " ('dark', 189891),\n",
       " ('getting', 189591),\n",
       " ('least', 189490),\n",
       " ('name', 188129),\n",
       " ('friend', 187333),\n",
       " ('hard', 187302),\n",
       " ('Mr', 186399),\n",
       " ('seen', 185143),\n",
       " ('later', 184960),\n",
       " ('sighed', 184018),\n",
       " ('soon', 183069),\n",
       " ('yet', 182365),\n",
       " ('Luna', 181283),\n",
       " ('shook', 179412),\n",
       " ('feeling', 179263),\n",
       " ('anyone', 177914),\n",
       " ('stop', 177464),\n",
       " ('talk', 177057),\n",
       " ('spell', 175100),\n",
       " ('George', 174669),\n",
       " ('held', 174487),\n",
       " ('gone', 174357),\n",
       " ('making', 173381),\n",
       " ('used', 171364),\n",
       " ('rather', 171069),\n",
       " ('believe', 170846),\n",
       " ('opened', 170609),\n",
       " ('far', 170544),\n",
       " ('slowly', 169807),\n",
       " ('home', 169684),\n",
       " ('Granger', 168883),\n",
       " ('rest', 168391),\n",
       " ('Fred', 166746),\n",
       " ('stopped', 166734),\n",
       " ('actually', 166711),\n",
       " ('whispered', 165529),\n",
       " ('idea', 165111),\n",
       " ('hear', 164899),\n",
       " ('wo', 164685),\n",
       " ('inside', 164008),\n",
       " ('breath', 162872),\n",
       " ('second', 161975),\n",
       " ('across', 161652),\n",
       " ('slightly', 161066),\n",
       " ('light', 160616),\n",
       " ('Tom', 159918),\n",
       " ('parents', 159796),\n",
       " ('called', 159769),\n",
       " ('needed', 159674),\n",
       " ('probably', 159408),\n",
       " ('coming', 159117),\n",
       " ('laughed', 158971),\n",
       " ('watched', 157727),\n",
       " ('students', 156273),\n",
       " ('continued', 155818),\n",
       " ('taking', 155504),\n",
       " ('close', 155321),\n",
       " ('sorry', 155115),\n",
       " ('ask', 154857),\n",
       " ('care', 154611),\n",
       " ('try', 153438),\n",
       " ('feet', 153350),\n",
       " ('Slytherin', 153230),\n",
       " ('Gryffindor', 153041),\n",
       " ('use', 152911),\n",
       " ('lot', 152592),\n",
       " ('heart', 152151),\n",
       " ('sitting', 150436),\n",
       " ('suddenly', 149122),\n",
       " ('morning', 147085),\n",
       " ('fact', 147032),\n",
       " ('pain', 146828),\n",
       " ('stared', 146353),\n",
       " ('reached', 145962),\n",
       " ('past', 145444),\n",
       " ('part', 145155),\n",
       " ('book', 144182),\n",
       " ('onto', 143231),\n",
       " ('blood', 141937),\n",
       " ('shoulder', 141176),\n",
       " ('along', 140635),\n",
       " ('wrong', 140307),\n",
       " ('moved', 139763),\n",
       " ('set', 138491),\n",
       " ('alone', 138258),\n",
       " ('happy', 138084),\n",
       " ('chest', 137686),\n",
       " ('thinking', 137657),\n",
       " ('black', 136784),\n",
       " ('decided', 136670),\n",
       " ('fell', 136491),\n",
       " ('may', 135161),\n",
       " ('ran', 134704),\n",
       " ('read', 134456),\n",
       " ('talking', 134264),\n",
       " ('minutes', 133811),\n",
       " ('bad', 133409),\n",
       " ('fingers', 132759),\n",
       " ('hurt', 132525),\n",
       " ('standing', 132281),\n",
       " ('remember', 132048),\n",
       " ('McGonagall', 131871),\n",
       " ('understand', 131556),\n",
       " ('red', 131551),\n",
       " ('person', 131285),\n",
       " ('caught', 131118),\n",
       " ('woman', 130227),\n",
       " ('dead', 130065),\n",
       " ('great', 129543),\n",
       " ('hope', 129464),\n",
       " ('air', 129377),\n",
       " ('ground', 129325),\n",
       " ('days', 129239),\n",
       " ('point', 129183),\n",
       " ('young', 129180),\n",
       " ('either', 128842),\n",
       " ('Tonks', 128385),\n",
       " ('kept', 128172),\n",
       " ('Black', 128027),\n",
       " ('matter', 127787),\n",
       " ('others', 127354),\n",
       " ('taken', 126837),\n",
       " ('forward', 126199),\n",
       " ('times', 125740),\n",
       " ('closed', 125381),\n",
       " ('kill', 125257),\n",
       " ('noticed', 124982),\n",
       " ('kiss', 124805),\n",
       " ('stay', 124760),\n",
       " ('son', 123756),\n",
       " ('Ministry', 123570),\n",
       " ('wizard', 123414),\n",
       " ('deep', 123172),\n",
       " ('reason', 122340),\n",
       " ('ready', 122244),\n",
       " ('raised', 122201),\n",
       " ('Yeah', 120601),\n",
       " ('sound', 120538),\n",
       " ('story', 120450),\n",
       " ('kind', 119962),\n",
       " ('lost', 119523),\n",
       " ('full', 119076),\n",
       " ('death', 119075),\n",
       " ('tears', 118978),\n",
       " ('Blaise', 118624),\n",
       " ('whole', 117816),\n",
       " ('wall', 117732),\n",
       " ('potion', 117097),\n",
       " ('different', 116596),\n",
       " ('move', 116190),\n",
       " ('Bellatrix', 115960),\n",
       " ('sleep', 114961),\n",
       " ('followed', 114754),\n",
       " ('question', 114634),\n",
       " ('Rose', 113190),\n",
       " ('start', 113141),\n",
       " ('large', 112330),\n",
       " ('please', 112035),\n",
       " ('turn', 111232),\n",
       " ('office', 110975),\n",
       " ('chair', 110842),\n",
       " ('answered', 110821),\n",
       " ('attention', 110810),\n",
       " ('Eaters', 110505),\n",
       " ('answer', 110086),\n",
       " ('Lupin', 109490),\n",
       " ('word', 109427),\n",
       " ('Scorpius', 109204),\n",
       " ('fine', 109076),\n",
       " ('holding', 108808),\n",
       " ('quietly', 108682),\n",
       " ('hit', 108460),\n",
       " ('outside', 108359),\n",
       " ('completely', 108292),\n",
       " ('half', 107712),\n",
       " ('waiting', 107609),\n",
       " ('class', 107336),\n",
       " ('spoke', 107304),\n",
       " ('Minerva', 107153),\n",
       " ('ago', 106918),\n",
       " ('longer', 106568),\n",
       " ('robes', 106456),\n",
       " ('cold', 106120),\n",
       " ('stepped', 105816),\n",
       " ('saying', 105582),\n",
       " ('several', 104428),\n",
       " ('eye', 103850),\n",
       " ('Pansy', 103229),\n",
       " ('softly', 103073),\n",
       " ('neck', 102825),\n",
       " ('staring', 102693),\n",
       " ('surprised', 102622),\n",
       " ('leaving', 102554),\n",
       " ('watching', 102480),\n",
       " ('child', 102004),\n",
       " ('finished', 101561),\n",
       " ('brought', 101526),\n",
       " ('meant', 101516),\n",
       " ('immediately', 101453),\n",
       " ('closer', 101128),\n",
       " ('exactly', 100844),\n",
       " ('given', 100548),\n",
       " ('grabbed', 100540),\n",
       " ('Thank', 100486),\n",
       " ('simply', 99959),\n",
       " ('Maybe', 99903),\n",
       " ('nearly', 99459),\n",
       " ('grinned', 99442),\n",
       " ('green', 99281),\n",
       " ('realized', 98921),\n",
       " ('managed', 98911),\n",
       " ('maybe', 98647),\n",
       " ('Narcissa', 98081),\n",
       " ('hold', 97861),\n",
       " ('curse', 97707),\n",
       " ('top', 97176),\n",
       " ('instead', 96981),\n",
       " ('change', 96803),\n",
       " ('says', 96792),\n",
       " ('kissed', 96160),\n",
       " ('chance', 96037),\n",
       " ('magical', 95706),\n",
       " ('Mrs', 95436),\n",
       " ('silence', 95115),\n",
       " ('skin', 95069),\n",
       " ('killed', 94874),\n",
       " ('fire', 94728),\n",
       " ('show', 94692),\n",
       " ('running', 94572),\n",
       " ('wait', 94572),\n",
       " ('true', 94475),\n",
       " ('sent', 94471),\n",
       " ('week', 94284),\n",
       " ('today', 94238),\n",
       " ('children', 94188),\n",
       " ('brother', 94123),\n",
       " ('One', 94061),\n",
       " ('speak', 94020),\n",
       " ('pointed', 93508),\n",
       " ('added', 93377),\n",
       " ('call', 93372),\n",
       " ('witch', 93300),\n",
       " ('rolled', 93124),\n",
       " ('met', 92769),\n",
       " ('Please', 92580),\n",
       " ('expression', 92563),\n",
       " ('known', 92122),\n",
       " ('Even', 92105),\n",
       " ('supposed', 92056),\n",
       " ('returned', 92051),\n",
       " ('turning', 92043),\n",
       " ('muttered', 91838),\n",
       " ('Molly', 91674),\n",
       " ('looks', 91577),\n",
       " ('appeared', 91532),\n",
       " ('leaned', 91470),\n",
       " ('seeing', 91411),\n",
       " ('Let', 91052),\n",
       " ('nice', 90874),\n",
       " ('cast', 90609),\n",
       " ('four', 90138),\n",
       " ('shrugged', 89815),\n",
       " ('happen', 89775),\n",
       " ('fight', 89574),\n",
       " ('Miss', 89513),\n",
       " ('hours', 89486),\n",
       " ('war', 88665),\n",
       " ('throat', 88659),\n",
       " ('castle', 88308),\n",
       " ('boys', 88239),\n",
       " ('pushed', 87858),\n",
       " ('less', 87725),\n",
       " ('thoughts', 87709),\n",
       " ('girls', 87628),\n",
       " ('letter', 87610),\n",
       " ('worry', 87317),\n",
       " ('run', 87275),\n",
       " ('yes', 87255),\n",
       " ('giving', 87091),\n",
       " ('stairs', 86952),\n",
       " ('okay', 86873),\n",
       " ('walking', 86672),\n",
       " ('water', 86647),\n",
       " ('glanced', 86647),\n",
       " ('loved', 86560),\n",
       " ('sort', 86433),\n",
       " ('gently', 86415),\n",
       " ('possible', 86328),\n",
       " ('Hagrid', 86204),\n",
       " ('couple', 86033),\n",
       " ('seem', 85570),\n",
       " ('anyway', 85563),\n",
       " ('real', 85481),\n",
       " ('Quidditch', 85480),\n",
       " ('passed', 85470),\n",
       " ('hell', 85199),\n",
       " ('surprise', 85007),\n",
       " ('pretty', 84871),\n",
       " ('books', 84816),\n",
       " ('spells', 84810),\n",
       " ('Good', 84720),\n",
       " ('desk', 84326),\n",
       " ('Muggle', 84209),\n",
       " ('become', 84154),\n",
       " ('placed', 83814),\n",
       " ('knowing', 83632),\n",
       " ('upon', 83457),\n",
       " ('meet', 83030),\n",
       " ('toward', 83011),\n",
       " ('guess', 82947),\n",
       " ('big', 82698),\n",
       " ('sense', 82578),\n",
       " ('common', 81988),\n",
       " ('however', 81981),\n",
       " ('white', 81870),\n",
       " ('beside', 81851),\n",
       " ('Bill', 81652),\n",
       " ('fear', 81259),\n",
       " ('safe', 80648),\n",
       " ('late', 80473),\n",
       " ('stand', 80408),\n",
       " ('power', 80368),\n",
       " ('corner', 80059),\n",
       " ('snapped', 80014),\n",
       " ('walk', 79829),\n",
       " ('wondered', 79755),\n",
       " ('Great', 79741),\n",
       " ('kitchen', 79709),\n",
       " ('anymore', 79590),\n",
       " ('die', 79561),\n",
       " ('Merlin', 79483),\n",
       " ('Come', 79164),\n",
       " ('soft', 79087),\n",
       " ('knows', 79083),\n",
       " ('smiling', 78587),\n",
       " ('dinner', 78412),\n",
       " ('bloody', 78152),\n",
       " ('sit', 78022),\n",
       " ('window', 77889),\n",
       " ('changed', 77814),\n",
       " ('agreed', 77747),\n",
       " ('group', 77610),\n",
       " ('watch', 77598),\n",
       " ('shut', 77572),\n",
       " ('laugh', 77518),\n",
       " ('bring', 77410),\n",
       " ('telling', 77385),\n",
       " ('Peter', 77244),\n",
       " ('Charlie', 77037),\n",
       " ('wish', 76744),\n",
       " ('explained', 76743),\n",
       " ('dropped', 76602),\n",
       " ('case', 76410),\n",
       " ('shot', 76381),\n",
       " ('Hall', 76360),\n",
       " ('return', 76315),\n",
       " ('shoulders', 76269),\n",
       " ('quiet', 76190),\n",
       " ('chapter', 76134),\n",
       " ('baby', 75914),\n",
       " ('gaze', 75807),\n",
       " ('angry', 75722),\n",
       " ('plan', 75706),\n",
       " ('short', 75644),\n",
       " ('near', 75118),\n",
       " ('sight', 74900),\n",
       " ('free', 74823),\n",
       " ('break', 74622),\n",
       " ('sister', 74573),\n",
       " ('moving', 74165),\n",
       " ('stupid', 74123),\n",
       " ('charm', 74106),\n",
       " ('potions', 74053),\n",
       " ('barely', 73998),\n",
       " ('figure', 73918),\n",
       " ('spent', 73818),\n",
       " ('seat', 73643),\n",
       " ('five', 73618),\n",
       " ('entire', 73602),\n",
       " ('live', 73420),\n",
       " ('reading', 73366),\n",
       " ('Christmas', 73315),\n",
       " ('frowned', 73294),\n",
       " ('died', 73187),\n",
       " ('legs', 73154),\n",
       " ('shouted', 72933),\n",
       " ('cut', 72917),\n",
       " ('worried', 72913),\n",
       " ('clear', 72809),\n",
       " ('pulling', 72527),\n",
       " ('working', 72410),\n",
       " ('stomach', 72376),\n",
       " ('months', 72287),\n",
       " ('beautiful', 72275),\n",
       " ('hall', 71781),\n",
       " ('conversation', 71736),\n",
       " ('allowed', 71584),\n",
       " ('Thanks', 71431),\n",
       " ('tone', 71411),\n",
       " ('fall', 71295),\n",
       " ('remembered', 71280),\n",
       " ('straight', 71030),\n",
       " ('picked', 70921),\n",
       " ('form', 70707),\n",
       " ('blue', 70542),\n",
       " ('entered', 70411),\n",
       " ('broke', 70378),\n",
       " ('memory', 69981),\n",
       " ('living', 69971),\n",
       " ('Eater', 69969),\n",
       " ('wizards', 69900),\n",
       " ('hour', 69806),\n",
       " ('Order', 69751),\n",
       " ('fun', 69735),\n",
       " ('afraid', 69718),\n",
       " ('grin', 69621),\n",
       " ('control', 69491),\n",
       " ('cried', 69290),\n",
       " ('silent', 69053),\n",
       " ('smirked', 68959),\n",
       " ('nose', 68936),\n",
       " ('touch', 68850),\n",
       " ('became', 68401),\n",
       " ('shaking', 68121),\n",
       " ('trust', 68027),\n",
       " ('certain', 68001),\n",
       " ('filled', 67909),\n",
       " ('anger', 67831),\n",
       " ('meeting', 67796),\n",
       " ('play', 67560),\n",
       " ('whatever', 67526),\n",
       " ('important', 67469),\n",
       " ('tonight', 67453),\n",
       " ('within', 67287),\n",
       " ('weeks', 67198),\n",
       " ('step', 67170),\n",
       " ('Percy', 66925),\n",
       " ('quick', 66909),\n",
       " ('warm', 66784),\n",
       " ('threw', 66640),\n",
       " ('laughing', 66572),\n",
       " ('older', 66496),\n",
       " ('Fleur', 66444),\n",
       " ('glad', 66305),\n",
       " ('empty', 66289),\n",
       " ('cheek', 66219),\n",
       " ('expected', 66194),\n",
       " ('food', 65810),\n",
       " ('Headmaster', 65522),\n",
       " ('yelled', 65506),\n",
       " ('waited', 64947),\n",
       " ('team', 64509),\n",
       " ('problem', 64449),\n",
       " ('truth', 64449),\n",
       " ('ones', 64402),\n",
       " ('arrived', 64214),\n",
       " ('hate', 64101),\n",
       " ('liked', 63988),\n",
       " ('muggle', 63686),\n",
       " ('shock', 63605),\n",
       " ('worse', 63500),\n",
       " ('using', 63446),\n",
       " ('Teddy', 63058),\n",
       " ('Chapter', 63053),\n",
       " ('gotten', 63046),\n",
       " ('breakfast', 62901),\n",
       " ('Daphne', 62766),\n",
       " ('wife', 62669),\n",
       " ('memories', 62609),\n",
       " ('alive', 62535),\n",
       " ('However', 62458),\n",
       " ('forced', 62438),\n",
       " ('job', 62358),\n",
       " ('wrapped', 62313),\n",
       " ('information', 62144),\n",
       " ('loud', 61943),\n",
       " ('clothes', 61577),\n",
       " ('glass', 61529),\n",
       " ('worked', 61426),\n",
       " ('Madam', 61044),\n",
       " ('Riddle', 60802),\n",
       " ('ear', 60770),\n",
       " ('carefully', 60665),\n",
       " ('stone', 60589),\n",
       " ('strong', 60529),\n",
       " ('paused', 60346),\n",
       " ('perhaps', 60221),\n",
       " ('wide', 60103),\n",
       " ('minute', 60093),\n",
       " ('trouble', 60089),\n",
       " ('summer', 60074),\n",
       " ('parchment', 60004),\n",
       " ('deal', 59823),\n",
       " ('confused', 59815),\n",
       " ('perfect', 59726),\n",
       " ('lay', 59474),\n",
       " ('Hey', 59463),\n",
       " ('especially', 59350),\n",
       " ('clearly', 59293),\n",
       " ('tea', 59222),\n",
       " ('evening', 59101),\n",
       " ('middle', 58849),\n",
       " ('led', 58805),\n",
       " ('sir', 58716),\n",
       " ('strange', 58632),\n",
       " ('normal', 58550),\n",
       " ('notice', 58511),\n",
       " ('suppose', 58399),\n",
       " ('dear', 58331),\n",
       " ('broom', 58224),\n",
       " ('daughter', 58210),\n",
       " ('makes', 58175),\n",
       " ('usual', 58100),\n",
       " ('chuckled', 57984),\n",
       " ('thank', 57847),\n",
       " ('certainly', 57843),\n",
       " ('tired', 57814),\n",
       " ('piece', 57682),\n",
       " ('Auror', 57625),\n",
       " ('Okay', 57529),\n",
       " ('Arthur', 57505),\n",
       " ('alright', 57501),\n",
       " ('sounded', 57474),\n",
       " ('library', 57438),\n",
       " ('tongue', 57377),\n",
       " ('easy', 57202),\n",
       " ('Potions', 56946),\n",
       " ('helped', 56874),\n",
       " ('broken', 56762),\n",
       " ('doubt', 56713),\n",
       " ('finger', 56649),\n",
       " ('moments', 56622),\n",
       " ('means', 56620),\n",
       " ('questions', 56548),\n",
       " ('gasped', 56529),\n",
       " ('lying', 56519),\n",
       " ('seems', 56509),\n",
       " ('pale', 56484),\n",
       " ('jumped', 56404),\n",
       " ('order', 56327),\n",
       " ('pressed', 56303),\n",
       " ('hissed', 56276),\n",
       " ('familiar', 56176),\n",
       " ('twins', 56027),\n",
       " ('line', 55993),\n",
       " ('tomorrow', 55949),\n",
       " ('attack', 55946),\n",
       " ('calm', 55942),\n",
       " ('situation', 55936),\n",
       " ('lifted', 55923),\n",
       " ('glared', 55866),\n",
       " ('Bella', 55829),\n",
       " ('mine', 55733),\n",
       " ('men', 55710),\n",
       " ('Master', 55615),\n",
       " ('Mum', 55546),\n",
       " ('position', 55535),\n",
       " ('Sorry', 55336),\n",
       " ('headed', 55152),\n",
       " ('cloak', 55074),\n",
       " ('game', 54966),\n",
       " ('wonder', 54672),\n",
       " ('bright', 54576),\n",
       " ('wants', 54497),\n",
       " ('high', 54483),\n",
       " ('explain', 54134),\n",
       " ('owl', 54114),\n",
       " ('save', 54053),\n",
       " ('catch', 53989),\n",
       " ('fast', 53938),\n",
       " ('asking', 53716),\n",
       " ('often', 53702),\n",
       " ('teeth', 53699),\n",
       " ('secret', 53696),\n",
       " ('although', 53690),\n",
       " ('asleep', 53677),\n",
       " ('promise', 53659),\n",
       " ('obviously', 53638),\n",
       " ('Pomfrey', 53630),\n",
       " ('ten', 53450),\n",
       " ('Dobby', 53379),\n",
       " ('Moody', 53179),\n",
       " ('battle', 53121),\n",
       " ('wearing', 53086),\n",
       " ('Everyone', 53028),\n",
       " ('bag', 52964),\n",
       " ('Kingsley', 52947),\n",
       " ('screamed', 52778),\n",
       " ('covered', 52718),\n",
       " ('seconds', 52691),\n",
       " ('dad', 52689),\n",
       " ('early', 52501),\n",
       " ('sigh', 52416),\n",
       " ('hoped', 52296),\n",
       " ('shirt', 52229),\n",
       " ('flew', 52169),\n",
       " ('eyebrow', 51976),\n",
       " ('Al', 51940),\n",
       " ('Magic', 51891),\n",
       " ('mate', 51887),\n",
       " ('professor', 51852),\n",
       " ('direction', 51820),\n",
       " ('pull', 51799),\n",
       " ('beginning', 51567),\n",
       " ('lip', 51428),\n",
       " ('rose', 51406),\n",
       " ('ended', 51406),\n",
       " ('student', 51352),\n",
       " ('easily', 51337),\n",
       " ('edge', 51181),\n",
       " ('truly', 51146),\n",
       " ('hated', 51141),\n",
       " ('likely', 51127),\n",
       " ('playing', 51029),\n",
       " ('Perhaps', 50983),\n",
       " ('learn', 50833),\n",
       " ('wondering', 50772),\n",
       " ('letting', 50722),\n",
       " ('whether', 50654),\n",
       " ('offered', 50570),\n",
       " ('except', 50561),\n",
       " ('crying', 50481),\n",
       " ('fighting', 50466),\n",
       " ('husband', 50404),\n",
       " ('following', 50390),\n",
       " ('cheeks', 50329),\n",
       " ('starting', 50274),\n",
       " ('mum', 50219),\n",
       " ('Azkaban', 50150),\n",
       " ('write', 50128),\n",
       " ('tightly', 50102),\n",
       " ('note', 49962),\n",
       " ('future', 49949),\n",
       " ('knees', 49939),\n",
       " ('none', 49720),\n",
       " ('keeping', 49717),\n",
       " ('cry', 49699),\n",
       " ('Minister', 49637),\n",
       " ('pair', 49525),\n",
       " ('disappeared', 49439),\n",
       " ('pocket', 49242),\n",
       " ('train', 49176),\n",
       " ('Dad', 49167),\n",
       " ('eat', 49023),\n",
       " ('missed', 49002),\n",
       " ('third', 49002),\n",
       " ('powerful', 48994),\n",
       " ('choice', 48970),\n",
       " ('serious', 48952),\n",
       " ('falling', 48892),\n",
       " ('follow', 48863),\n",
       " ('hoping', 48851),\n",
       " ('aware', 48794),\n",
       " ('forget', 48791),\n",
       " ('shocked', 48737),\n",
       " ('flying', 48698),\n",
       " ('money', 48573),\n",
       " ('earlier', 48499),\n",
       " ('low', 48474),\n",
       " ('guys', 48470),\n",
       " ('expect', 48452),\n",
       " ('spot', 48421),\n",
       " ('Nothing', 48384),\n",
       " ('Right', 48317),\n",
       " ('hide', 48260),\n",
       " ('hug', 48181),\n",
       " ('Ravenclaw', 48164),\n",
       " ('elf', 48070),\n",
       " ('soul', 47871),\n",
       " ('bedroom', 47804),\n",
       " ('waved', 47757),\n",
       " ('somehow', 47594),\n",
       " ('single', 47539),\n",
       " ('send', 47494),\n",
       " ('hot', 47367),\n",
       " ('Would', 47298),\n",
       " ('ears', 47249),\n",
       " ('master', 47152),\n",
       " ('handed', 47116),\n",
       " ('age', 47090),\n",
       " ('dress', 46925),\n",
       " ('exclaimed', 46907),\n",
       " ('blinked', 46874),\n",
       " ('paper', 46703),\n",
       " ('somewhere', 46669),\n",
       " ('drink', 46639),\n",
       " ('admit', 46628),\n",
       " ('slipped', 46582),\n",
       " ('showed', 46535),\n",
       " ('laughter', 46512),\n",
       " ('forehead', 46439),\n",
       " ('corridor', 46404),\n",
       " ('feelings', 46303),\n",
       " ('continue', 46271),\n",
       " ('usually', 46130),\n",
       " ('smirk', 46099),\n",
       " ('present', 46078),\n",
       " ('murmured', 45987),\n",
       " ('shall', 45938),\n",
       " ('putting', 45878),\n",
       " ('scared', 45871),\n",
       " ('join', 45795),\n",
       " ('simple', 45766),\n",
       " ('doors', 45736),\n",
       " ('younger', 45682),\n",
       " ('thanks', 45671),\n",
       " ('causing', 45513),\n",
       " ('silver', 45376),\n",
       " ('box', 45359),\n",
       " ('House', 45252),\n",
       " ('relief', 45126),\n",
       " ('Finally', 45084),\n",
       " ('protect', 45069),\n",
       " ('Aurors', 45015),\n",
       " ('force', 44995),\n",
       " ('cup', 44918),\n",
       " ('breathing', 44892),\n",
       " ('Like', 44885),\n",
       " ('news', 44853),\n",
       " ('wizarding', 44792),\n",
       " ('writing', 44789),\n",
       " ('steps', 44747),\n",
       " ('bathroom', 44741),\n",
       " ('Seamus', 44675),\n",
       " ('glance', 44633),\n",
       " ('definitely', 44524),\n",
       " ('mad', 44412),\n",
       " ('Dean', 44378),\n",
       " ('sometimes', 44337),\n",
       " ('stayed', 44288),\n",
       " ('mirror', 44237),\n",
       " ('obvious', 44118),\n",
       " ('wands', 44095),\n",
       " ('sudden', 44062),\n",
       " ('wake', 44046),\n",
       " ('check', 43994),\n",
       " ('wards', 43954),\n",
       " ('touched', 43939),\n",
       " ('despite', 43829),\n",
       " ('sleeping', 43823),\n",
       " ('visit', 43680),\n",
       " ('Cedric', 43618),\n",
       " ('burst', 43611),\n",
       " ('needs', 43595),\n",
       " ('groaned', 43498),\n",
       " ('difficult', 43496),\n",
       " ('dangerous', 43483),\n",
       " ('kissing', 43376),\n",
       " ('busy', 43375),\n",
       " ('crowd', 43343),\n",
       " ('walls', 43332),\n",
       " ('fault', 43198),\n",
       " ('interrupted', 43162),\n",
       " ('married', 43143),\n",
       " ('final', 43117),\n",
       " ('business', 43110),\n",
       " ('Head', 43089),\n",
       " ('drew', 43037),\n",
       " ('remained', 43018),\n",
       " ('couch', 42988),\n",
       " ('learned', 42774),\n",
       " ('Slytherins', 42766),\n",
       " ('speaking', 42665),\n",
       " ('stated', 42653),\n",
       " ('stuff', 42481),\n",
       " ('lunch', 42457),\n",
       " ('ring', 42300),\n",
       " ('growled', 42295),\n",
       " ('party', 42276),\n",
       " ('enjoy', 42200),\n",
       " ('spend', 42085),\n",
       " ('Look', 42073),\n",
       " ('Ah', 42032),\n",
       " ('apart', 42000),\n",
       " ('foot', 41988),\n",
       " ('hospital', 41970),\n",
       " ('grew', 41866),\n",
       " ('realised', 41829),\n",
       " ('ahead', 41815),\n",
       " ('six', 41719),\n",
       " ('stuck', 41679),\n",
       " ('lose', 41637),\n",
       " ('match', 41608),\n",
       " ('response', 41522),\n",
       " ('caused', 41468),\n",
       " ('dream', 41459),\n",
       " ('wanting', 41436),\n",
       " ('listen', 41416),\n",
       " ('blonde', 41395),\n",
       " ('teacher', 41376),\n",
       " ('aside', 41340),\n",
       " ('Regulus', 41338),\n",
       " ('brown', 41301),\n",
       " ('relationship', 41136),\n",
       " ('joined', 41099),\n",
       " ('crossed', 41085),\n",
       " ('Umbridge', 41059),\n",
       " ('tight', 41055),\n",
       " ('evil', 40953),\n",
       " ('points', 40909),\n",
       " ('talked', 40882),\n",
       " ('silently', 40850),\n",
       " ('finish', 40846),\n",
       " ('slid', 40751),\n",
       " ('allow', 40746),\n",
       " ('odd', 40691)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_words_from_counter(counter, top_n):\n",
    "    return sorted([(word, count) for word, count in counter.items()],\n",
    "                  key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "print('Топ-1000 слов по встречаемости:')\n",
    "top_nonstopwords = get_top_words_from_counter(word_counter, 1000)\n",
    "joblib.dump(top_nonstopwords, top_nonstopwords_fp)\n",
    "top_nonstopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "2. Найдите топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Главная идея для нахождения имен: собираем с википедии все имена персонажей Гарри Поттера (https://en.wikipedia.org/wiki/List_of_Harry_Potter_characters), и ищем их в тексте. Также используется named entity recognition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "names_fp = Path('names.txt')\n",
    "names = names_fp.read_text().split('\\n')\n",
    "name_counters_fp = 'name_counters.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 42s, sys: 49 s, total: 2min 31s\n",
      "Wall time: 6h 16min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['name_counters.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time name_counter, name_pair_counter, prof_name_counter = utils.count_names_mp(tokenized_texts, names, n_jobs=5)\n",
    "counter_dump = (dict(name_counter), dict(name_pair_counter), dict(prof_name_counter))\n",
    "joblib.dump(counter_dump, name_counters_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 имен по встречаемости:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Harry', 3888723),\n",
       " ('Hermione', 1606139),\n",
       " ('Draco', 1182809),\n",
       " ('Ron', 835296),\n",
       " ('Ginny', 609445),\n",
       " ('Sirius', 606892),\n",
       " ('Snape', 475709),\n",
       " ('James', 447549),\n",
       " ('Severus', 443348),\n",
       " ('Potter', 422191)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_counter, name_pair_counter, prof_name_counter = joblib.load(name_counters_fp)\n",
    "\n",
    "print('Топ-10 имен по встречаемости:')\n",
    "get_top_words_from_counter(name_counter, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 пар имя + фамилия по встречаемости:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Harry Potter', 118080),\n",
       " ('Draco Malfoy', 46481),\n",
       " ('Hermione Granger', 28619),\n",
       " ('Sirius Black', 26643),\n",
       " ('James Potter', 26437),\n",
       " ('Severus Snape', 25686),\n",
       " ('Lucius Malfoy', 24330),\n",
       " ('Remus Lupin', 12903),\n",
       " ('Ginny Weasley', 10974),\n",
       " ('Ron Weasley', 10725)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Топ-10 пар имя + фамилия по встречаемости:')\n",
    "get_top_words_from_counter(name_pair_counter, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 пар профессор + имя / фамилия по встречаемости:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('professor Snape', 15373),\n",
       " ('professor Dumbledore', 8487),\n",
       " ('professor McGonagall', 7763),\n",
       " ('professor Lupin', 3832),\n",
       " ('professor Flitwick', 3454),\n",
       " ('professor Sprout', 2169),\n",
       " ('professor Slughorn', 2002),\n",
       " ('professor Trelawney', 1076),\n",
       " ('professor Umbridge', 1040),\n",
       " ('professor Harry', 958)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Топ-10 пар профессор + имя / фамилия по встречаемости:')\n",
    "get_top_words_from_counter(prof_name_counter, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "[бонус] Найдите еще что-то интересное в корпусе (что-то специфичное для фанфиков или фентези-тематики)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 2. [2 балла] Модели представления слов\n",
    "Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса HPAC."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/germanarutunov/DataspellProjects/hw-1-nlp-hse-2022-AndBoyS/hw\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "data_dir = Path('data')\n",
    "split_data_dir = data_dir / 'hpac_splits'\n",
    "\n",
    "ft_data_dir = data_dir / 'ft'\n",
    "ft_data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "ft_train_file = ft_data_dir / 'hpac_ft.train'\n",
    "ft_dev_file = ft_data_dir / 'hpac_ft.dev'\n",
    "\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "ft_model = models_dir / 'ft.ftz'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "should_train_ft = True\n",
    "should_train_split_ft = True\n",
    "should_dev_split_ft = True\n",
    "\n",
    "if ft_train_file.exists():\n",
    "    should_train_split_ft = False\n",
    "\n",
    "if ft_dev_file.exists():\n",
    "    should_dev_split_ft = False\n",
    "\n",
    "if ft_model.exists():\n",
    "    should_train_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "if should_train_split_ft:\n",
    "    train_df = pd.read_csv(split_data_dir / 'hpac_training_128.tsv',\n",
    "                           names=['target', 'text'],\n",
    "                           index_col=0,\n",
    "                           sep='\\t', header=None)\n",
    "    with open(ft_train_file, mode='a') as f:\n",
    "        for i, (target, text) in tqdm(train_df.iterrows(), desc='Processing train split for fastText'):\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "            f.write(f'__label__{target}\\t{text}\\n')\n",
    "    should_train_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "if should_dev_split_ft:\n",
    "    dev_df = pd.read_csv(split_data_dir / 'hpac_dev_128.tsv',\n",
    "                         names=['target', 'text'],\n",
    "                         index_col=0,\n",
    "                         sep='\\t', header=None)\n",
    "    with open(ft_dev_file, mode='a') as f:\n",
    "        for i, (target, text) in tqdm(dev_df.iterrows(), desc='Processing dev split for fastText'):\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "            f.write(f'__label__{target}\\t{text}\\n')\n",
    "    should_dev_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import fasttext"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "if should_train_ft:\n",
    "    model = fasttext.train_supervised(\n",
    "        input=str(ft_train_file),\n",
    "        autotuneValidationFile=str(ft_dev_file),\n",
    "        autotuneModelSize='5M',\n",
    "        autotuneDuration=1200\n",
    "    )\n",
    "    model.save_model(str(ft_model))\n",
    "    should_train_ft = False\n",
    "else:\n",
    "    model = fasttext.load_model(str(ft_model))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.1 Синонимы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.8944582343101501, 'rescue'),\n (0.888363242149353, 'ridiculously'),\n (0.8825259208679199, 'jeremiah'),\n (0.8562796115875244, 'witnessed'),\n (0.8521283864974976, 'hounding'),\n (0.8432715535163879, 'none'),\n (0.8367645740509033, 'hints'),\n (0.8300632834434509, 'weaved'),\n (0.82944256067276, 'sacred'),\n (0.8291577100753784, 'betas')]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors('wizard')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.2 Ассоциации"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.9383688569068909, 'combats'),\n (0.9187878966331482, 'mocked'),\n (0.9064145088195801, 'ooooo'),\n (0.9061028361320496, 'force'),\n (0.903786301612854, 'roared'),\n (0.9032526612281799, 'jezlyn'),\n (0.8954090476036072, 'wheezley'),\n (0.8932932019233704, 'abstract'),\n (0.8926324844360352, 'fenir'),\n (0.8868676424026489, 'caged')]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_analogies('zombie', 'monster', 'beast')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.3 Лишние слова"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Не знаю, как это тут сделать"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "top_nonstopwords = joblib.load(data_dir / 'top_nonstopwords.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "log_dir = Path('./logs/')\n",
    "log_dir.mkdir(exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "with open(log_dir / 'metadata.tsv', 'w') as f:\n",
    "    for w, _ in top_nonstopwords:\n",
    "        f.write(\"{}\\n\".format(w))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "embeddings = np.zeros((len(top_nonstopwords), model.get_dimension()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "for i, (w, _) in enumerate(top_nonstopwords):\n",
    "    embeddings[i] = model.get_word_vector(w)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 23:56:25.890421: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "embedding_var = tf.Variable(embeddings, name='fastText')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from tensorboard.plugins import projector\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(embedding=embedding_var)\n",
    "checkpoint.save(log_dir / 'embedding.ckpt')\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-774efd21e8d7a1b2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-774efd21e8d7a1b2\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 3. [5 баллов] Классификация текстов\n",
    "Задача классификации формулируется так: данный фрагмент фанфика описывают какую-то ситуацию, которая предшествует произнесению заклинания. Требуется по тексту предсказать, какое именно заклинание будет произнесено. Таким образом, заклинание - это фактически метка класса. Основная мера качества – macro $F_1$.\n",
    "Обучите несколько классификаторов и сравните их между собой. Оцените качество классификаторов на частых и редких классах. Какие классы чаще всего оказываются перепутаны? Связаны ли ошибки со смыслом заклинаний?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 fastText"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "ft_data_dir = data_dir / 'ft'\n",
    "\n",
    "ft_test_file = ft_data_dir / 'hpac_ft.test'\n",
    "\n",
    "models_dir = Path('models')\n",
    "ft_model = models_dir / 'ft.ftz'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "should_test_split_ft = True\n",
    "\n",
    "if ft_test_file.exists():\n",
    "    should_test_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "if should_test_split_ft:\n",
    "    test_df = pd.read_csv(split_data_dir / 'hpac_test_128.tsv',\n",
    "                           names=['target', 'text'],\n",
    "                           index_col=0,\n",
    "                           sep='\\t', header=None)\n",
    "    with open(ft_test_file, mode='a') as f:\n",
    "        for i, (target, text) in tqdm(test_df.iterrows(), desc='Processing test split for fastText'):\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "            f.write(f'__label__{target}\\t{text}\\n')\n",
    "    should_test_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model(str(ft_model))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "scores = model.test_label(str(ft_test_file))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 for fastText is 0.3122\n"
     ]
    }
   ],
   "source": [
    "macro_f1 = []\n",
    "\n",
    "for label, metrics in scores.items():\n",
    "    if np.isnan(metrics['f1score']):\n",
    "        continue\n",
    "    macro_f1 = metrics['f1score']\n",
    "\n",
    "macro_f1 = np.mean(macro_f1)\n",
    "print(f'Macro F1 for fastText is {macro_f1:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-hw1",
   "language": "python",
   "name": "nlp-hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
