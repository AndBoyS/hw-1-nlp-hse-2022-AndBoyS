{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "## Harry Potter and the Action Prediction Challenge from Natural Language\n",
    "\n",
    "*deadline*: 14 ноября 2022, 23:59\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусом Harry Potter and the Action Prediction Challenge. Корпус собран из фанфиков о Гарри Поттере и состоит из двух частей: 1) сырые тексты, 2) фрагменты текстов, описывающих ситуацию, в которой произнесено заклинание.\n",
    "\n",
    "Корпус описан в статье: https://arxiv.org/pdf/1905.11037.pdf\n",
    "\n",
    "David Vilares and Carlos Gómez-Rodríguez. Harry Potter and the Action Prediction Challenge from Natural Language. 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics. To appear.\n",
    "\n",
    "Код для сбора корпуса находится в репозитории: https://github.com/aghie/hpac . Корпус можно скачать по инструкции из этого репозитория, но для экономии времени авторы задания уже скачали и подготовили данные к работе. \n",
    "\n",
    "Ссылки на собранный корпус: \n",
    "* Сырые тексты:  https://www.dropbox.com/s/23xet9kvbqna1qs/hpac_raw.zip?dl=0\n",
    "* Токенизированные тексты в нижнем регистре: https://www.dropbox.com/s/gwfgmomdbetvdye/hpac_lower_tokenized.zip?dl=0\n",
    "* train-test-dev: https://www.dropbox.com/s/3vdz0mouvex8abd/hpac_splits.zip?dl=0\n",
    "\n",
    "Части 1, 2 задания должны быть выполнены на полных текстах (сырых или предобработанных -- на ваше усмотрение), Часть 3 – на разбиение на тестовое, отладочное и обучающее множества. Тестовое множество должно быть использовано исключительно для тестирования моделей, обучающее и отладочное – для выбора модели и параметров. \n",
    "\n",
    "В статье и репозитории вы найдете идеи, которые помогут вам выполнить домашнее задание. Их стоит воспринимать как руководство к действию, и не стоит их копировать и переиспользовать. Обученные модели использовать не нужно, код для их обучения можно использовать как подсказку. \n",
    "\n",
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 3-х человек.\n",
    "2. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо ipython-тетрадке. \n",
    "3. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "4. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "5. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "6. Плагиат и любое недобросоветсное цитирование приводит к обнуление оценки. \n",
    "\n",
    "\n",
    "## Часть 1. [2 балла] Эксплоративный анализ \n",
    "1. Найдите топ-1000 слов по частоте без учета стоп-слов.\n",
    "2. Найдите топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия. \n",
    "\n",
    "[бонус] Постройте тематическую модель по корпусу HPAC.\n",
    "\n",
    "[бонус] Найдите еще что-то интересное в корпусе (что-то специфичное для фанфиков или фентези-тематики)\n",
    "\n",
    "## Часть 2. [2 балла] Модели представления слов \n",
    "Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса HPAC.\n",
    "1. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели. \n",
    "2. Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io).\n",
    "\n",
    "## Часть 3. [5 баллов] Классификация текстов\n",
    "Задача классификации формулируется так: данный фрагмент фанфика описывают какую-то ситуацию, которая предшествует произнесению заклинания. Требуется по тексту предсказать, какое именно заклинание будет произнесено. Таким образом, заклинание - это фактически метка класса. Основная мера качества – macro $F_1$.\n",
    "Обучите несколько классификаторов и сравните их между собой. Оцените качество классификаторов на частых и редких классах. Какие классы чаще всего оказываются перепутаны? Связаны ли ошибки со смыслом заклинаний?\n",
    "\n",
    "Используйте фрагменты из множества train для обучения, из множества dev для отладки, из множества test – для тестирования и получения итоговых результатов. \n",
    "\n",
    "1. [1 балл] Используйте fastText в качестве baseline-классификатора.\n",
    "2. [2 балла] Используйте сверточные  или реккурентные сети в качестве более продвинутого классификатора. Поэкспериментируйте с количеством и размерностью фильтров, используйте разные размеры окон, попробуйте использовать $k$-max pooling. \n",
    "3. [2 балла] Попробуйте расширить обучающее множество за счет аугментации данных. Если вам понадобится словарь синонимов, можно использовать WordNet (ниже вы найдете примеры).\n",
    "\n",
    "[бонус] Используйте результат max pooling'а как эмбеддинг входного текста. Визуализируйте эмбеддинги 500-1000 предложений из обучающего множества и изучите свойства получившегося пространства.\n",
    "\n",
    "[бонус] Используйте ваш любимый классификатор и любые (честные) способы повышения качества классификации и получите macro $F_1$ больше 0.5.\n",
    "\n",
    "## Часть 4. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Читали ли вы сами Гарри Поттера или фанфики о нем и помогло ли вам знание предметной области в выполнении домашнего задания?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\r\n",
      "/Users/user/Main/Study/NLP/hw-1-nlp-hse-2022-AndBoyS/hw/data\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "%cd data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-07 20:59:19--  https://www.dropbox.com/s/23xet9kvbqna1qs/hpac_raw.zip\r\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18\r\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /s/raw/23xet9kvbqna1qs/hpac_raw.zip [following]\r\n",
      "--2022-11-07 20:59:23--  https://www.dropbox.com/s/raw/23xet9kvbqna1qs/hpac_raw.zip\r\n",
      "Reusing existing connection to www.dropbox.com:443.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com/cd/0/inline/BwX6_goqPJo1ECXTvh_cWpu92zklf6UlqQ6zzu9k6-c0lQFaFax-lxeRHu-R0Jy5mufEhXp3j717P-DzpLDcekkpXv6zTt7Jn3VRrE-0uX9lWrEE0mfNzpPpx9LFBiOEzs7MwKRgZ-eHacdOhTEY-b9KckcuKkYFfyXgMBfgrcwBTg/file# [following]\r\n",
      "--2022-11-07 20:59:24--  https://uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com/cd/0/inline/BwX6_goqPJo1ECXTvh_cWpu92zklf6UlqQ6zzu9k6-c0lQFaFax-lxeRHu-R0Jy5mufEhXp3j717P-DzpLDcekkpXv6zTt7Jn3VRrE-0uX9lWrEE0mfNzpPpx9LFBiOEzs7MwKRgZ-eHacdOhTEY-b9KckcuKkYFfyXgMBfgrcwBTg/file\r\n",
      "Resolving uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com (uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com)... 162.125.64.15\r\n",
      "Connecting to uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com (uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /cd/0/inline2/BwWbamQ57pATCA2QaNvrZk1FMExLPYT1Dj0dM1zACVuQ5YSEIkW_odvPGwXJ9IKE6eOlBlKfuroKno3nUlZ4wf-hTmNUefl7gEHHjpZClCKiOPudoRtY5dCRUGSdT2p6elsIV9IrmX_YuWTruVm0GrmpkpAkODsmGtgHYz6jAWYcM2rsmezf6CFoViPT9OwNz-7f6YSDaPnEBrxMQH0btSN3LZ882HmvfzO3PskG9iIYVv2Uw6kJ26vFePdI0KtsCYfCZl95iy0J9a16PkY-lalO3MnIqPlG_vQLQCXuEQeV-7aSp-W87XacZSnaK81RHiCG4oI6KZszgooMkRt2wwwn5KW4f_4IuNdX2nfxvxJuvva2zKpygniEiY8Q0PWrj_j3s2O0yeA2NVjcpZpetwbAWkIE2hCCjk1n6RY8n22W8Q/file [following]\r\n",
      "--2022-11-07 20:59:46--  https://uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com/cd/0/inline2/BwWbamQ57pATCA2QaNvrZk1FMExLPYT1Dj0dM1zACVuQ5YSEIkW_odvPGwXJ9IKE6eOlBlKfuroKno3nUlZ4wf-hTmNUefl7gEHHjpZClCKiOPudoRtY5dCRUGSdT2p6elsIV9IrmX_YuWTruVm0GrmpkpAkODsmGtgHYz6jAWYcM2rsmezf6CFoViPT9OwNz-7f6YSDaPnEBrxMQH0btSN3LZ882HmvfzO3PskG9iIYVv2Uw6kJ26vFePdI0KtsCYfCZl95iy0J9a16PkY-lalO3MnIqPlG_vQLQCXuEQeV-7aSp-W87XacZSnaK81RHiCG4oI6KZszgooMkRt2wwwn5KW4f_4IuNdX2nfxvxJuvva2zKpygniEiY8Q0PWrj_j3s2O0yeA2NVjcpZpetwbAWkIE2hCCjk1n6RY8n22W8Q/file\r\n",
      "Reusing existing connection to uc9a2656e9b64c11d44ee9de006a.dl.dropboxusercontent.com:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1018234025 (971M) [application/zip]\r\n",
      "Saving to: ‘hpac_raw.zip’\r\n",
      "\r\n",
      "hpac_raw.zip        100%[===================>] 971.06M  1.12MB/s    in 23m 10s \r\n",
      "\r\n",
      "2022-11-07 21:22:57 (715 KB/s) - ‘hpac_raw.zip’ saved [1018234025/1018234025]\r\n",
      "\r\n",
      "--2022-11-07 21:22:57--  https://www.dropbox.com/s/gwfgmomdbetvdye/hpac_lower_tokenized.zip\r\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18\r\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /s/raw/gwfgmomdbetvdye/hpac_lower_tokenized.zip [following]\r\n",
      "--2022-11-07 21:22:58--  https://www.dropbox.com/s/raw/gwfgmomdbetvdye/hpac_lower_tokenized.zip\r\n",
      "Reusing existing connection to www.dropbox.com:443.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com/cd/0/inline/BwWCmPm2dxyNSU-lnD9T5JpMVahm-SMWoBBJ9dWiHR0_GujfU1wORVgK9_Mun2-jFpC10JUCgZumzYePPZ3m0KwnDYWXRn5qW1qFe2bfI11rH8oARCFX6jVXFWRuzUMpaX51lg3f_8nfEtgZfv645KmRwypCoUlqfYYV1SrOFgZLug/file# [following]\r\n",
      "--2022-11-07 21:22:59--  https://uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com/cd/0/inline/BwWCmPm2dxyNSU-lnD9T5JpMVahm-SMWoBBJ9dWiHR0_GujfU1wORVgK9_Mun2-jFpC10JUCgZumzYePPZ3m0KwnDYWXRn5qW1qFe2bfI11rH8oARCFX6jVXFWRuzUMpaX51lg3f_8nfEtgZfv645KmRwypCoUlqfYYV1SrOFgZLug/file\r\n",
      "Resolving uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com (uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com)... 162.125.64.15\r\n",
      "Connecting to uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com (uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /cd/0/inline2/BwXA75GPhKHHfgshS-Q1YVUuYhneO0ndMIUNpVY4KQWtpIz-1sZuxcDrcOExRZHWTRCzAAdSH8SAlv8dvo3QA4dY7JwpCcMfEoKf2jB5Y5bdZ-oa5vIbBTMASi6aNAfBGUWPo2SsmU98I98oJwgc5dVwJaZ45Th-23WrdLDAcqSOFO6oaN70VTdgOLxEDwamdhkQ92d0yXmAY1g8G5SiTY8pYr_8SMKPWLnHUfvNOvuRxdYwsl_5FZ0pUyyeb6dj2MetLf48GLAqI62oqFJcmpel2j8WTWUosvaQyMrNIlcHksa8k0-h7jF_yC4Wl6tdsJrJs3u94S-2c9Rz-CseVq7CP-KRnNIHZJMx-9z17kf2pJnSVwnCjZyfr_jXX7s-BHVgJtL5HCXRYfgOrexS1_PTfu7-kHq08AN8em7LlJv9qw/file [following]\r\n",
      "--2022-11-07 21:23:00--  https://uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com/cd/0/inline2/BwXA75GPhKHHfgshS-Q1YVUuYhneO0ndMIUNpVY4KQWtpIz-1sZuxcDrcOExRZHWTRCzAAdSH8SAlv8dvo3QA4dY7JwpCcMfEoKf2jB5Y5bdZ-oa5vIbBTMASi6aNAfBGUWPo2SsmU98I98oJwgc5dVwJaZ45Th-23WrdLDAcqSOFO6oaN70VTdgOLxEDwamdhkQ92d0yXmAY1g8G5SiTY8pYr_8SMKPWLnHUfvNOvuRxdYwsl_5FZ0pUyyeb6dj2MetLf48GLAqI62oqFJcmpel2j8WTWUosvaQyMrNIlcHksa8k0-h7jF_yC4Wl6tdsJrJs3u94S-2c9Rz-CseVq7CP-KRnNIHZJMx-9z17kf2pJnSVwnCjZyfr_jXX7s-BHVgJtL5HCXRYfgOrexS1_PTfu7-kHq08AN8em7LlJv9qw/file\r\n",
      "Reusing existing connection to uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 996528740 (950M) [application/zip]\r\n",
      "Saving to: ‘hpac_lower_tokenized.zip’\r\n",
      "\r\n",
      "hpac_lower_tokenize  99%[==================> ] 947.75M   487KB/s    in 23m 25s \r\n",
      "\r\n",
      "2022-11-07 21:46:26 (691 KB/s) - Connection closed at byte 993787904. Retrying.\r\n",
      "\r\n",
      "--2022-11-07 21:46:27--  (try: 2)  https://uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com/cd/0/inline2/BwXA75GPhKHHfgshS-Q1YVUuYhneO0ndMIUNpVY4KQWtpIz-1sZuxcDrcOExRZHWTRCzAAdSH8SAlv8dvo3QA4dY7JwpCcMfEoKf2jB5Y5bdZ-oa5vIbBTMASi6aNAfBGUWPo2SsmU98I98oJwgc5dVwJaZ45Th-23WrdLDAcqSOFO6oaN70VTdgOLxEDwamdhkQ92d0yXmAY1g8G5SiTY8pYr_8SMKPWLnHUfvNOvuRxdYwsl_5FZ0pUyyeb6dj2MetLf48GLAqI62oqFJcmpel2j8WTWUosvaQyMrNIlcHksa8k0-h7jF_yC4Wl6tdsJrJs3u94S-2c9Rz-CseVq7CP-KRnNIHZJMx-9z17kf2pJnSVwnCjZyfr_jXX7s-BHVgJtL5HCXRYfgOrexS1_PTfu7-kHq08AN8em7LlJv9qw/file\r\n",
      "Connecting to uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com (uc4ca054c1de2b8c05cb388efa91.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 206 Partial Content\r\n",
      "Length: 996528740 (950M), 2740836 (2.6M) remaining [application/zip]\r\n",
      "Saving to: ‘hpac_lower_tokenized.zip’\r\n",
      "\r\n",
      "hpac_lower_tokenize 100%[+++++++++++++++++++>] 950.36M   903KB/s    in 3.0s    \r\n",
      "\r\n",
      "2022-11-07 21:46:32 (903 KB/s) - ‘hpac_lower_tokenized.zip’ saved [996528740/996528740]\r\n",
      "\r\n",
      "--2022-11-07 21:46:32--  https://www.dropbox.com/s/3vdz0mouvex8abd/hpac_splits.zip\r\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18\r\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /s/raw/3vdz0mouvex8abd/hpac_splits.zip [following]\r\n",
      "--2022-11-07 21:46:36--  https://www.dropbox.com/s/raw/3vdz0mouvex8abd/hpac_splits.zip\r\n",
      "Reusing existing connection to www.dropbox.com:443.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com/cd/0/inline/BwWUT3hrv_WgQPguHA7uNt5s3bOfAk6-p1mtO_0dRs9aNyjHGw919KuXeNc7oY_rrdQjhBLSv1CZpousig5U3y670N17zeWwkdzVi6KID75wd-1X-PivVVUbfxSjdJbudggTZQ5gdrVCxQlk_8BXTHSMqfwbiU4g1P5VBb08YoruCw/file# [following]\r\n",
      "--2022-11-07 21:46:36--  https://uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com/cd/0/inline/BwWUT3hrv_WgQPguHA7uNt5s3bOfAk6-p1mtO_0dRs9aNyjHGw919KuXeNc7oY_rrdQjhBLSv1CZpousig5U3y670N17zeWwkdzVi6KID75wd-1X-PivVVUbfxSjdJbudggTZQ5gdrVCxQlk_8BXTHSMqfwbiU4g1P5VBb08YoruCw/file\r\n",
      "Resolving uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com (uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com)... 162.125.64.15\r\n",
      "Connecting to uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com (uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /cd/0/inline2/BwX1RZANc7r_H2vfQ8TBZTMSoDcWrsgD8wcDxtnqWHBJdi8qajBddQD8EaA-dsfSflyoStkyM3KCYJrg1XCS67n5HttZrthzGEF2l2JbJWGbB2D-BwLPD_Jckmd8dM8hArz8tbu28EmyrKcTTF41d3JI9B3TQgOQXTd6XU_GC7j5WIxrVu2jP5Bd7Gn5H-Xs0vfmR1pc1AF6C6whb83Lw0lUWyRfzlj_yFW_mZDIaUvWWKxGqG4jWYmRqlA-yj1Gs-P61DFQjBYjwmg2eB9gUeuVpwfsZotQU5CX63-8oQLZQ1DpwVWi9sJKquwAlhQmlZSQaUwK_Twadmd7E7HY3CMeAaErL6rwpLcsNC_G_8KIB2nq3B1GT2KRY4F7wWG8LqTgqfavmE4Em6rYHtUDTSKWSioHJ8siRz6bbAi80kLwmw/file [following]\r\n",
      "--2022-11-07 21:46:44--  https://uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com/cd/0/inline2/BwX1RZANc7r_H2vfQ8TBZTMSoDcWrsgD8wcDxtnqWHBJdi8qajBddQD8EaA-dsfSflyoStkyM3KCYJrg1XCS67n5HttZrthzGEF2l2JbJWGbB2D-BwLPD_Jckmd8dM8hArz8tbu28EmyrKcTTF41d3JI9B3TQgOQXTd6XU_GC7j5WIxrVu2jP5Bd7Gn5H-Xs0vfmR1pc1AF6C6whb83Lw0lUWyRfzlj_yFW_mZDIaUvWWKxGqG4jWYmRqlA-yj1Gs-P61DFQjBYjwmg2eB9gUeuVpwfsZotQU5CX63-8oQLZQ1DpwVWi9sJKquwAlhQmlZSQaUwK_Twadmd7E7HY3CMeAaErL6rwpLcsNC_G_8KIB2nq3B1GT2KRY4F7wWG8LqTgqfavmE4Em6rYHtUDTSKWSioHJ8siRz6bbAi80kLwmw/file\r\n",
      "Reusing existing connection to uc11a57b9d130d6b1c8a7afed3bc.dl.dropboxusercontent.com:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 18284862 (17M) [application/zip]\r\n",
      "Saving to: ‘hpac_splits.zip’\r\n",
      "\r\n",
      "hpac_splits.zip     100%[===================>]  17.44M   806KB/s    in 32s     \r\n",
      "\r\n",
      "2022-11-07 21:47:16 (565 KB/s) - ‘hpac_splits.zip’ saved [18284862/18284862]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://www.dropbox.com/s/23xet9kvbqna1qs/hpac_raw.zip\n",
    "!wget -nc https://www.dropbox.com/s/gwfgmomdbetvdye/hpac_lower_tokenized.zip\n",
    "!wget -nc https://www.dropbox.com/s/3vdz0mouvex8abd/hpac_splits.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Импортируем базовые библиотеки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/user/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/user/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/user/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    "import re\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "# скачиваем модули для NLTK\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Данные\n",
    "\n",
    "Распакуем и переименуем данные для удобства"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Как папки будут называться в итоге\n",
    "raw_data_dir = Path('hpac_raw')\n",
    "tokenized_data_dir = Path('hpac_lower_tokenized')\n",
    "split_data_dir = Path('hpac_splits')\n",
    "\n",
    "if not raw_data_dir.exists():\n",
    "    !unzip hpac_raw\n",
    "if not tokenized_data_dir.exists():\n",
    "    !unzip hpac_lower_tokenized\n",
    "if not split_data_dir.exists():\n",
    "    !unzip hpac_splits\n",
    "shutil.rmtree('__MACOSX', ignore_errors=True)\n",
    "\n",
    "folder_mapping = {\n",
    "    'fanfiction_texts': raw_data_dir.name,\n",
    "    'hpac_source': tokenized_data_dir.name,\n",
    "    'hpac_corpus': split_data_dir.name,\n",
    "}\n",
    "\n",
    "for name, new_name in folder_mapping.items():\n",
    "    fp = Path(name)\n",
    "    if fp.exists():\n",
    "        fp.rename(new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36225\r\n"
     ]
    }
   ],
   "source": [
    "!ls hpac_lower_tokenized | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, test, dev файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(split_data_dir / 'hpac_training_128.tsv',\n",
    "                 names=['target', 'text'],\n",
    "                 index_col=0,\n",
    "                 sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                       target  \\\n7642954.0.676      RIDDIKULUS   \n10443333.0.5753    RIDDIKULUS   \n4703706.0.8690        STUPEFY   \n4593427.0.1815          ACCIO   \n4278446.0.2692   EXPELLIARMUS   \n\n                                                              text  \n7642954.0.676    were staring at her . she was up next to face ...  \n10443333.0.5753  that whole time . her first reaction , for whi...  \n4703706.0.8690   we watched his inglorious withdrawal together ...  \n4593427.0.1815   my wand , `` incendio . '' this wretched chill...  \n4278446.0.2692   already compared ours , they 're the same ever...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7642954.0.676</th>\n      <td>RIDDIKULUS</td>\n      <td>were staring at her . she was up next to face ...</td>\n    </tr>\n    <tr>\n      <th>10443333.0.5753</th>\n      <td>RIDDIKULUS</td>\n      <td>that whole time . her first reaction , for whi...</td>\n    </tr>\n    <tr>\n      <th>4703706.0.8690</th>\n      <td>STUPEFY</td>\n      <td>we watched his inglorious withdrawal together ...</td>\n    </tr>\n    <tr>\n      <th>4593427.0.1815</th>\n      <td>ACCIO</td>\n      <td>my wand , `` incendio . '' this wretched chill...</td>\n    </tr>\n    <tr>\n      <th>4278446.0.2692</th>\n      <td>EXPELLIARMUS</td>\n      <td>already compared ours , they 're the same ever...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "('RIDDIKULUS',\n \"were staring at her . she was up next to face the boggart in defense against the dark arts class . she was not scared , but what she was worried about was what had happened with lysander . she looked up at the boggart in front of her which had previously been a humongous spider . its eyes locked on her . before she could think of what frightened her , the spider transformed into lysander . he was dying . there were giggles coming from the male and female hufflepuff students . there was a smirk on lorcan 's face . `` lily help me '' i ca n't fail this class because of a secret love . lily lifted her wand and said , ``\")"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][0], df.iloc[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как использовать WordNet из nltk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[Synset('magic.n.01'), Synset('magic_trick.n.01'), Synset('charming.s.02')]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# слово -> множество синсетов (синонимов разных смыслов исходного слова)\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('magic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Lemma('magic_trick.n.01.magic_trick')"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим, что внутри одного синсета\n",
    "wn.synsets('magic')[1].lemmas()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'deception'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# возьмем лемму одного из слов из синсета\n",
    "wn.synsets('magic')[1].lemmas()[-1].name()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 1. [2 балла] Эксплоративный анализ\n",
    "1. Найдите топ-1000 слов по частоте без учета стоп-слов."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузим токенизированные тексты и уберем пунктуацию"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c4e0117961444f2aa3c218842a9bada"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Удаляем пунктуацию, не считая тире\n",
    "def read_text_no_punc(text_dir: Path, num_texts: Optional[int] = None):\n",
    "\n",
    "    fps = list(text_dir.glob('*'))\n",
    "\n",
    "    if num_texts:\n",
    "        fps = fps[:num_texts]\n",
    "\n",
    "    return [re.sub(r\"[^\\w\\s'-]\", '', fp.read_text())\n",
    "            for fp in tqdm(fps)]\n",
    "\n",
    "tokenized_texts = read_text_no_punc(raw_data_dir, 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/36225 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "234663a137fd495cb330d8189088c951"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "…'That wand's\n",
      "more trouble than it's worth,' said Harry, 'And quite\n",
      "honestly,' he turned away from the painted portraits, thinking now\n",
      "only of the four-poster bed lying waiting for him in Gryffindor\n",
      "tower, and wondering whether Kreacher might bring him a sandwich\n",
      "there, 'I've had enough trouble for a lifetime.' As soon as they left\n",
      "Dumbledore's office, the exertions of the past day caught up with\n",
      "him. It seemed impossible that only this morning he'd been at Shell\n",
      "Cottage… He was so tired he\n",
      "hardly knew how he got to Gryffindor tower. The fat lady was\n",
      "elsewhere, but the portrait hole was swinging open in any case. He\n",
      "wondered what had happened, and then decided that he was too tired to\n",
      "care. He parted company from Ron and Hermione (who had, for some\n",
      "impenetrable reason had elected to stay downstairs a while) and\n",
      "staggered up the spiral stairs, collapsing onto his bed at the top\n",
      "without undressing. He knew he'd been gone all year, but it was\n",
      "still his bed. He was still a Gryffindor, after all. Harry took off\n",
      "his glasses without bothering to open his eyes and placed them on his\n",
      "bedside table. Indistinct noises came up the stairs until he shut the\n",
      "door with his wand. There were some things he didn't want to know.\n",
      "After a while, Ron came up and also collapsed. 'Well,' Ron said.\n",
      "'We won.' 'Yeah,' said Harry,\n",
      "weariness washing over him. 'We won.' And as unconsciousness took\n",
      "him, the only emotion he felt was that of tired joy. The joy of\n",
      "success. Harry woke slowly –\n",
      "with small bits of his dream merging into reality. When he fully\n",
      "awoke, he saw that he'd been asleep for a long time: the shadows\n",
      "were short and the dormitory was deserted. It must be nearly noon. He\n",
      "got up and dressed on automatic, then walked down the stairs to the\n",
      "common room, which, as he had suspected, was almost empty. Hermione\n",
      "and Ron weren't there. He felt drained: not physically, but\n",
      "emotionally.  And when you think about it, it gets worse  he\n",
      "berated himself silently.   So don't think about it! But he couldn't stop\n",
      "thinking about it. He saw, through the medium of memory, Voldemort\n",
      "trying to kill him for the third time, using the killing curse for\n",
      "the third time, saw him fail, for the third time… he saw Voldemort\n",
      "watch as the green light, yet again turned on him… saw him fall\n",
      "under the terrible weight of it… And just as he was\n",
      "beginning to think he should throw himself out the window, and was\n",
      "staring at it, he suddenly found himself staring instead into a pair\n",
      "of beautiful, brown eyes. 'Wake up!' yelled a\n",
      "voice in his ear, and he turned from Ginny, the owner of the eyes,\n",
      "and saw Ron. 'You've been asleep\n",
      "for hours, now you're awake, and going comatose! Come on, you need\n",
      "food.' Harry almost agreed.\n",
      "Now he came to notice it, his stomach was growling so loudly he\n",
      "thought they could hear it down in the great hall. But Ginny was\n",
      "right here. 'I'll come down and\n",
      "meet you in a bit, ok?' Ron surveyed him,\n",
      "Hermione surveyed Ginny, and then both nodded. Harry and Ginny\n",
      "watched them leave. Harry looked back at\n",
      "Ginny. Ginny looked back at\n",
      "Harry. Harry cast around for\n",
      "something to say and hit on the events of last night. But now he came\n",
      "to it, there was only one thing he thought Ginny would want to\n",
      "discuss about it. 'I was there when\n",
      "Fred… you know…' He looked up at Ginny,\n",
      "and saw tears pouring down her cheeks. 'Yeah,' she\n",
      "whispered, 'I know.' 'Ah, Gin…' he\n",
      "really didn't like seeing her cry. He got up from his chair and\n",
      "held her until her tears subsided, then sat down again, pulling her\n",
      "down with him. 'Yeah,' she\n",
      "repeated. 'Percy went after the Rookwood, the guy who did it, you\n",
      "know.' 'Yeah, he did,'\n",
      "said Harry, remembering Percy's charge. 'Did he catch him?' Ginny smiled a bit.\n",
      "'Yes, he did. He got him. Stunned him, and he says he wished he'd\n",
      "done more, but he couldn't, because Macnair was after him. He got\n",
      "Macnair, too.' Harry smiled at this.\n",
      "Percy, the fussy, boring head boy interested in cauldron bottoms had\n",
      "floored at least two death eaters. 'Did he get any\n",
      "other's?' Harry wondered aloud. 'Yeah, he got\n",
      "everyone in that group.' 'Wow.' 'Yeah, wow. I don't\n",
      "even know where he learnt half the curses he used.' 'Huh. What were the\n",
      "effects?' 'Well, you saw hat\n",
      "one he used on the minister, right?' Ginny got up off his knee and\n",
      "sat on the arm of his chair. 'Yep.' 'Lucky you, I didn't.\n",
      "But he used another one on Macnair that made him stick his leg right\n",
      "up until it touched his ear, and another one that hung a guy upside\n",
      "down by his ankle…' 'Yeah, I know that\n",
      "one, levicorpus,' 'Ha, yes, Ron told me\n",
      "you used it on him once.' Harry was having fun,\n",
      "they were chatting easily, but… His stomach rumbled\n",
      "again, loud enough for Ginny to hear it. She looked at him in\n",
      "amusement. 'You're hungry'. Harry winced from the\n",
      "hunger pains. 'Yeah. But the Ministry'll be waiting for me down\n",
      "there, and I don't want to face them. So will the  Prophet .\n",
      "And a thousand other people. And I don't want to see any of them.'\n",
      "He looked at Ginny beseechingly. 'Reckon you could get enough for\n",
      "two and meet me back up here?' Ginny smiled again.\n",
      "'Sure.' Ten minutes later,\n",
      "Ginny came back up with a basketful of food. 'Ron and Hermione are\n",
      "sitting  very  close together' she said, grinning, as she set\n",
      "it down. 'And you were right –\n",
      "Kingsley was down there, and so were a couple of people from the\n",
      " Prophet , Luna's dad was there, McGonagall, the Malfoys, all\n",
      "my family… about half the wizarding world was waiting for you to\n",
      "show up.' After a superb lunch,\n",
      "Harry, Ron, Hermione and Ginny adjourned to the grounds. Someone had\n",
      "cleared the bodies away, and even the grass was green again… in the\n",
      "patches where it could still grow, there were many where it never\n",
      "would again. It was a beautiful\n",
      "sunny day, the sky was a clear blue and the heat was unrelenting, as\n",
      "if the day's weather were trying to make people forget what had\n",
      "happened last night. They all sat down next\n",
      "to the lake. Harry noticed that Hermione and Ron were sitting very\n",
      "close together. Ginny was looking at\n",
      "him. Out of the corner of\n",
      "his eye, he saw Ron take Hermione's hand, but he just kept looking\n",
      "at Ginny, drinking her in with his eyes. 'Oi, Harry, me and\n",
      "Hermione are going inside, ok?' called Ron, breaking into his\n",
      "thoughts.  Hermione must've whispered to him  thought Harry.\n",
      "Ron could never have been accused of being tactful.. 'Ok, bye!' he\n",
      "called to their retreating figures, and then it was just him and\n",
      "Ginny. They sat together,\n",
      "looking out over the lake. Harry tried to think of something to say,\n",
      "but still, ho could only settle on last night. So that's what they\n",
      "talked about. Harry recounted his story, and Ginny recounted hers.\n",
      "Tears were shed, when Harry reached Fred's death, when he\n",
      "remembered seeing Remus and Dora stretched out together, eternally at\n",
      "peace… 'And that means\n",
      "you're godfather now, doesn't it?' said Ginny. Harry started.\n",
      "He had forgotten. 'Yeah, I am! I'd\n",
      "forgotten he asked…' They concluded their\n",
      "stories, and sat in silence. Harry reached out for\n",
      "her hand, and found it. He held it tight. 'Ginny…' 'Yeah?' 'You missed me this\n",
      "year?' Ginny leant into him.\n",
      "'More than anything on God's good earth, Harry Potter.' Harry sighed with\n",
      "happiness. 'I love you, Gin,'\n",
      "he said, and kissed her. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fp in tqdm(list(raw_data_dir.glob('*'))):\n",
    "    print(fp.read_text())\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 75.3 ms, sys: 74.6 ms, total: 150 ms\n",
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import cpu_count, Pool\n",
    "import utils\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield n number of striped chunks from l.\"\"\"\n",
    "    for i in range(0, n):\n",
    "        yield l[i::n]\n",
    "\n",
    "def get_word_counters_mp(texts: List[str]):\n",
    "\n",
    "    num_processes = cpu_count() - 1\n",
    "    texts = list(chunks(texts, num_processes))\n",
    "\n",
    "    with Pool(num_processes) as p:\n",
    "        counters = p.map(utils.get_word_counters, texts)\n",
    "\n",
    "    # Объединяем результаты счетчиков\n",
    "    res_counter = counters[0]\n",
    "    for counter in counters:\n",
    "        for name, val in counter.items():\n",
    "            res_counter[name] += val\n",
    "\n",
    "    return res_counter\n",
    "\n",
    "%time word_counter = get_word_counters_mp(tokenized_texts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-1000 слов по встречаемости:\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('Harry', 9341),\n ('said', 6773),\n ('would', 5522),\n ('James', 4747),\n ('could', 4227),\n ('one', 3659),\n ('know', 3540),\n ('back', 3501),\n ('like', 3448),\n ('time', 2830),\n ('Hermione', 2649),\n ('eyes', 2476),\n ('Ron', 2460),\n ('asked', 2439),\n ('get', 2379),\n ('going', 2268),\n ('Draco', 2238),\n ('think', 2150),\n ('looked', 2002),\n ('see', 1923),\n ('head', 1846),\n ('around', 1845),\n ('Potter', 1824),\n ('even', 1786),\n ('go', 1785),\n ('room', 1744),\n ('want', 1727),\n ('way', 1706),\n ('Voldemort', 1704),\n ('much', 1679),\n ('still', 1660),\n ('man', 1631),\n ('thought', 1629),\n ('hand', 1585),\n ('never', 1567),\n ('Triss', 1555),\n ('Malfoy', 1536),\n ('say', 1527),\n ('right', 1526),\n ('first', 1502),\n ('something', 1495),\n ('face', 1443),\n ('knew', 1423),\n ('Snape', 1394),\n ('two', 1329),\n ('look', 1323),\n ('away', 1322),\n ('take', 1295),\n ('people', 1260),\n ('really', 1258),\n ('Dumbledore', 1241),\n ('make', 1228),\n ('wand', 1221),\n ('sure', 1218),\n ('father', 1217),\n ('Tom', 1205),\n ('took', 1201),\n ('well', 1199),\n ('Lord', 1198),\n ('Ginny', 1192),\n ('good', 1188),\n ('little', 1178),\n ('felt', 1165),\n ('nodded', 1158),\n ('Evans', 1154),\n ('us', 1135),\n ('got', 1129),\n ('made', 1117),\n ('Lily', 1086),\n ('though', 1084),\n ('Sirius', 1083),\n ('need', 1082),\n ('Dark', 1072),\n ('come', 1056),\n ('tell', 1038),\n ('left', 1036),\n ('let', 1031),\n ('door', 1020),\n ('anything', 1015),\n ('turned', 1009),\n ('told', 1004),\n ('thing', 1001),\n ('next', 987),\n ('went', 965),\n ('long', 963),\n ('last', 959),\n ('ca', 952),\n ('looking', 918),\n ('voice', 894),\n ('Hogwarts', 882),\n ('day', 881),\n ('put', 878),\n ('came', 871),\n ('saw', 868),\n ('always', 863),\n ('things', 860),\n ('year', 856),\n ('George', 856),\n ('help', 854),\n ('wanted', 851),\n ('feel', 836),\n ('another', 835),\n ('boy', 828),\n ('course', 819),\n ('bed', 806),\n ('mind', 805),\n ('moment', 801),\n ('better', 799),\n ('enough', 798),\n ('ever', 797),\n ('walked', 793),\n ('started', 790),\n ('life', 786),\n ('Severus', 776),\n ('nothing', 763),\n ('years', 762),\n ('find', 762),\n ('bit', 747),\n ('found', 741),\n ('Well', 741),\n ('night', 740),\n ('many', 739),\n ('Remus', 730),\n ('hands', 727),\n ('Albus', 725),\n ('might', 722),\n ('side', 721),\n ('trying', 708),\n ('behind', 705),\n ('hair', 704),\n ('stood', 697),\n ('everyone', 695),\n ('smile', 689),\n ('small', 687),\n ('later', 687),\n ('already', 681),\n ('sat', 677),\n ('Yes', 671),\n ('heard', 659),\n ('house', 657),\n ('dark', 650),\n ('happened', 648),\n ('Kingsley', 647),\n ('towards', 644),\n ('keep', 644),\n ('girl', 640),\n ('gave', 639),\n ('magic', 638),\n ('almost', 637),\n ('also', 633),\n ('best', 624),\n ('love', 614),\n ('done', 613),\n ('talk', 611),\n ('every', 610),\n ('smiled', 606),\n ('world', 604),\n ('else', 604),\n ('must', 603),\n ('friends', 600),\n ('seemed', 599),\n ('end', 597),\n ('Lucius', 596),\n ('floor', 593),\n ('place', 589),\n ('far', 586),\n ('table', 585),\n ('give', 583),\n ('name', 578),\n ('yet', 577),\n ('mean', 576),\n ('Slytherin', 572),\n ('without', 571),\n ('seen', 570),\n ('family', 566),\n ('school', 566),\n ('may', 565),\n ('Teddy', 558),\n ('quickly', 557),\n ('old', 556),\n ('able', 554),\n ('someone', 551),\n ('began', 551),\n ('since', 548),\n ('anyone', 548),\n ('three', 542),\n ('pulled', 539),\n ('try', 536),\n ('body', 535),\n ('death', 534),\n ('shook', 531),\n ('point', 531),\n ('leave', 530),\n ('Neville', 529),\n ('getting', 528),\n ('Oh', 527),\n ('rather', 524),\n ('Rita', 519),\n ('friend', 518),\n ('least', 517),\n ('spell', 516),\n ('front', 515),\n ('idea', 513),\n ('quite', 512),\n ('tried', 509),\n ('light', 505),\n ('power', 504),\n ('finally', 498),\n ('minutes', 492),\n ('open', 490),\n ('soon', 486),\n ('together', 485),\n ('everything', 485),\n ('young', 484),\n ('work', 481),\n ('words', 481),\n ('believe', 479),\n ('spoke', 475),\n ('great', 473),\n ('Cyrus', 472),\n ('sitting', 467),\n ('sighed', 466),\n ('mother', 465),\n ('second', 461),\n ('Fred', 460),\n ('Auror', 460),\n ('blood', 459),\n ('Professor', 457),\n ('making', 455),\n ('arms', 455),\n ('hear', 452),\n ('says', 451),\n ('understand', 450),\n ('coming', 449),\n ('arm', 448),\n ('taking', 445),\n ('stop', 444),\n ('wo', 443),\n ('feeling', 442),\n ('lot', 442),\n ('wrong', 442),\n ('slowly', 441),\n ('kill', 438),\n ('ask', 437),\n ('probably', 436),\n ('used', 435),\n ('hope', 434),\n ('Weasley', 434),\n ('son', 433),\n ('new', 432),\n ('hard', 432),\n ('held', 431),\n ('fact', 431),\n ('rest', 428),\n ('gone', 427),\n ('Luna', 425),\n ('across', 422),\n ('reason', 420),\n ('bad', 419),\n ('decided', 417),\n ('kind', 414),\n ('Leader', 414),\n ('lips', 410),\n ('close', 409),\n ('called', 408),\n ('parents', 407),\n ('question', 407),\n ('feet', 406),\n ('stopped', 405),\n ('matter', 403),\n ('past', 398),\n ('continued', 396),\n ('Mr', 396),\n ('slightly', 394),\n ('standing', 394),\n ('home', 393),\n ('Black', 392),\n ('care', 391),\n ('replied', 390),\n ('talking', 388),\n ('laughed', 386),\n ('students', 386),\n ('ready', 386),\n ('stay', 383),\n ('mouth', 381),\n ('Riddle', 381),\n ('opened', 377),\n ('dead', 377),\n ('others', 377),\n ('sorry', 375),\n ('suddenly', 374),\n ('days', 374),\n ('black', 374),\n ('morning', 372),\n ('use', 371),\n ('either', 370),\n ('Percy', 366),\n ('half', 365),\n ('part', 365),\n ('Kat', 365),\n ('forward', 364),\n ('heart', 364),\n ('word', 363),\n ('thinking', 362),\n ('immediately', 362),\n ('ground', 362),\n ('Gryffindor', 360),\n ('remember', 360),\n ('needed', 360),\n ('air', 359),\n ('breath', 358),\n ('sleep', 357),\n ('magical', 356),\n ('story', 354),\n ('shoulder', 354),\n ('taken', 354),\n ('ago', 353),\n ('turn', 353),\n ('person', 352),\n ('agreed', 351),\n ('large', 351),\n ('inside', 349),\n ('wall', 348),\n ('however', 346),\n ('Bellatrix', 345),\n ('less', 343),\n ('Rose', 343),\n ('fell', 342),\n ('Yeah', 340),\n ('alone', 340),\n ('walking', 339),\n ('surprised', 339),\n ('reached', 338),\n ('red', 338),\n ('different', 337),\n ('actually', 337),\n ('set', 335),\n ('ran', 335),\n ('start', 335),\n ('hall', 333),\n ('wizard', 333),\n ('whispered', 331),\n ('along', 329),\n ('saying', 327),\n ('pain', 327),\n ('times', 326),\n ('appeared', 325),\n ('Daphne', 323),\n ('tears', 322),\n ('book', 322),\n ('whole', 322),\n ('full', 322),\n ('powerful', 322),\n ('fight', 321),\n ('war', 321),\n ('onto', 320),\n ('looks', 320),\n ('Dray', 318),\n ('stared', 317),\n ('happen', 316),\n ('Death', 316),\n ('read', 316),\n ('watched', 315),\n ('move', 315),\n ('green', 314),\n ('known', 314),\n ('longer', 313),\n ('true', 313),\n ('deep', 312),\n ('Thanks', 310),\n ('please', 309),\n ('answered', 308),\n ('fine', 307),\n ('Good', 305),\n ('group', 303),\n ('killed', 303),\n ('maybe', 303),\n ('woman', 302),\n ('clearly', 302),\n ('Okay', 302),\n ('nearly', 301),\n ('curse', 300),\n ('plan', 300),\n ('eye', 299),\n ('fire', 299),\n ('hours', 298),\n ('hit', 296),\n ('lost', 296),\n ('pointed', 293),\n ('class', 293),\n ('speak', 292),\n ('chance', 292),\n ('running', 292),\n ('wizards', 291),\n ('guess', 289),\n ('chest', 289),\n ('kept', 288),\n ('hurt', 288),\n ('several', 288),\n ('exactly', 287),\n ('realized', 287),\n ('happy', 285),\n ('Aurors', 285),\n ('answer', 285),\n ('Susan', 285),\n ('moved', 284),\n ('knowing', 284),\n ('Regulus', 283),\n ('chair', 282),\n ('important', 282),\n ('closed', 282),\n ('neck', 282),\n ('common', 281),\n ('fingers', 281),\n ('followed', 279),\n ('outside', 279),\n ('call', 277),\n ('okay', 277),\n ('raised', 276),\n ('silence', 275),\n ('fear', 274),\n ('One', 273),\n ('given', 273),\n ('grinned', 273),\n ('Mel', 273),\n ('Ministry', 272),\n ('finished', 272),\n ('water', 272),\n ('sound', 271),\n ('sit', 271),\n ('noticed', 270),\n ('anyway', 270),\n ('become', 270),\n ('child', 269),\n ('pretty', 268),\n ('brother', 268),\n ('attention', 268),\n ('shrugged', 268),\n ('sense', 267),\n ('today', 266),\n ('waiting', 264),\n ('form', 263),\n ('seems', 262),\n ('knows', 262),\n ('staring', 261),\n ('walk', 261),\n ('surprise', 261),\n ('stand', 261),\n ('Scorpius', 261),\n ('top', 260),\n ('die', 260),\n ('Granger', 260),\n ('run', 259),\n ('near', 259),\n ('worry', 258),\n ('gently', 258),\n ('skin', 258),\n ('instead', 256),\n ('Henry', 256),\n ('Hugo', 256),\n ('minute', 255),\n ('change', 254),\n ('meant', 254),\n ('Lupin', 254),\n ('hold', 254),\n ('leaving', 253),\n ('glanced', 253),\n ('case', 252),\n ('wish', 252),\n ('caught', 251),\n ('kiss', 251),\n ('possible', 251),\n ('Thank', 248),\n ('seem', 246),\n ('wait', 246),\n ('holding', 243),\n ('problem', 243),\n ('short', 242),\n ('potion', 242),\n ('threw', 241),\n ('yelled', 240),\n ('responded', 240),\n ('seconds', 239),\n ('Maybe', 239),\n ('meet', 237),\n ('cold', 237),\n ('robes', 236),\n ('bring', 235),\n ('supposed', 234),\n ('met', 234),\n ('Tonks', 234),\n ('cut', 234),\n ('Raven', 234),\n ('expression', 233),\n ('completely', 233),\n ('watch', 232),\n ('food', 232),\n ('girls', 232),\n ('castle', 232),\n ('watching', 231),\n ('spells', 231),\n ('show', 230),\n ('added', 230),\n ('yes', 229),\n ('stepped', 229),\n ('information', 229),\n ('week', 228),\n ('Hagrid', 228),\n ('conversation', 227),\n ('hour', 226),\n ('perhaps', 226),\n ('died', 226),\n ('stairs', 223),\n ('Muggle', 223),\n ('Audrey', 223),\n ('Noah', 223),\n ('wizarding', 222),\n ('simply', 222),\n ('men', 222),\n ('clear', 221),\n ('situation', 221),\n ('hell', 221),\n ('corner', 220),\n ('Hana', 220),\n ('Let', 218),\n ('meeting', 218),\n ('control', 218),\n ('five', 218),\n ('white', 217),\n ('safe', 217),\n ('expected', 216),\n ('brought', 216),\n ('headmaster', 216),\n ('rolled', 215),\n ('shot', 215),\n ('turning', 214),\n ('children', 214),\n ('quietly', 213),\n ('big', 212),\n ('giving', 212),\n ('Please', 209),\n ('months', 209),\n ('likely', 209),\n ('barely', 208),\n ('boys', 208),\n ('pulling', 207),\n ('middle', 206),\n ('step', 205),\n ('closer', 205),\n ('telling', 205),\n ('tone', 205),\n ('four', 205),\n ('seeing', 204),\n ('age', 204),\n ('Even', 203),\n ('test', 203),\n ('older', 203),\n ('upon', 202),\n ('strong', 202),\n ('explained', 202),\n ('real', 202),\n ('sent', 202),\n ('passed', 201),\n ('Merlin', 201),\n ('trust', 201),\n ('chapter', 201),\n ('fall', 200),\n ('tonight', 200),\n ('professor', 200),\n ('quiet', 199),\n ('alright', 199),\n ('fast', 198),\n ('stomach', 197),\n ('blue', 197),\n ('live', 197),\n ('truth', 197),\n ('worse', 195),\n ('living', 195),\n ('returned', 195),\n ('makes', 195),\n ('charm', 194),\n ('muggle', 194),\n ('truly', 192),\n ('muttered', 192),\n ('Come', 191),\n ('cast', 191),\n ('empty', 190),\n ('anymore', 190),\n ('figure', 189),\n ('easy', 189),\n ('laugh', 188),\n ('late', 188),\n ('sight', 187),\n ('position', 187),\n ('certainly', 187),\n ('Eaters', 187),\n ('picked', 186),\n ('whatever', 186),\n ('softly', 186),\n ('changed', 186),\n ('sort', 186),\n ('wondered', 185),\n ('break', 185),\n ('silent', 185),\n ('followers', 185),\n ('ten', 184),\n ('managed', 184),\n ('reading', 183),\n ('office', 182),\n ('books', 182),\n ('line', 182),\n ('anger', 182),\n ('desk', 181),\n ('straight', 181),\n ('laughing', 181),\n ('Chapter', 181),\n ('cause', 180),\n ('battle', 180),\n ('aware', 180),\n ('couple', 179),\n ('save', 178),\n ('sir', 178),\n ('Bella', 178),\n ('McGonagall', 177),\n ('shaking', 177),\n ('seat', 177),\n ('lying', 176),\n ('whether', 176),\n ('broke', 176),\n ('working', 176),\n ('especially', 176),\n ('Narcissa', 176),\n ('exclaimed', 175),\n ('alive', 175),\n ('tea', 175),\n ('entered', 175),\n ('entire', 174),\n ('beautiful', 173),\n ('easily', 173),\n ('nice', 173),\n ('dropped', 173),\n ('Everyone', 173),\n ('starting', 173),\n ('Kurt', 173),\n ('placed', 172),\n ('shoulders', 172),\n ('ones', 172),\n ('However', 172),\n ('talked', 171),\n ('soul', 171),\n ('follow', 171),\n ('kissed', 170),\n ('questions', 170),\n ('game', 170),\n ('deal', 170),\n ('guys', 170),\n ('certain', 169),\n ('familiar', 169),\n ('evening', 169),\n ('smiling', 168),\n ('expect', 168),\n ('angry', 167),\n ('except', 167),\n ('future', 167),\n ('Dragon', 167),\n ('pushed', 166),\n ('fighting', 166),\n ('island', 166),\n ('spot', 165),\n ('touch', 165),\n ('train', 165),\n ('memory', 164),\n ('often', 164),\n ('grabbed', 164),\n ('afraid', 164),\n ('play', 164),\n ('human', 164),\n ('using', 163),\n ('window', 163),\n ('asking', 163),\n ('suppose', 163),\n ('broom', 163),\n ('arrived', 162),\n ('within', 162),\n ('became', 162),\n ('potions', 162),\n ('baby', 162),\n ('carefully', 161),\n ('Christmas', 161),\n ('circle', 161),\n ('main', 161),\n ('tomorrow', 161),\n ('thoughts', 160),\n ('lie', 160),\n ('gotten', 160),\n ('shut', 159),\n ('join', 159),\n ('weeks', 159),\n ('means', 158),\n ('warm', 158),\n ('Alice', 158),\n ('free', 158),\n ('Hey', 158),\n ('none', 158),\n ('elf', 158),\n ('Anika', 158),\n ('killing', 157),\n ('Prophet', 157),\n ('forehead', 157),\n ('worried', 157),\n ('cried', 157),\n ('leaned', 157),\n ('jumped', 157),\n ('society', 157),\n ('remembered', 156),\n ('throat', 156),\n ('paused', 156),\n ('hate', 156),\n ('stone', 156),\n ('Great', 156),\n ('training', 156),\n ('asleep', 155),\n ('eaters', 155),\n ('doubt', 155),\n ('sometimes', 155),\n ('putting', 155),\n ('sister', 155),\n ('tired', 154),\n ('grin', 154),\n ('dinner', 154),\n ('wake', 154),\n ('trouble', 153),\n ('moving', 153),\n ('kids', 153),\n ('continue', 153),\n ('student', 153),\n ('pull', 153),\n ('Sorry', 153),\n ('toward', 153),\n ('third', 152),\n ('notice', 152),\n ('stupid', 152),\n ('Bill', 152),\n ('order', 152),\n ('shock', 152),\n ('catch', 151),\n ('soft', 151),\n ('usual', 151),\n ('spent', 151),\n ('imagine', 150),\n ('goes', 150),\n ('Pansy', 150),\n ('gets', 149),\n ('lightly', 149),\n ('glad', 149),\n ('learn', 149),\n ('fun', 148),\n ('quick', 148),\n ('wrapped', 148),\n ('allowed', 148),\n ('promise', 148),\n ('loved', 148),\n ('beside', 147),\n ('glance', 147),\n ('glass', 147),\n ('choice', 147),\n ('growled', 147),\n ('ear', 146),\n ('loud', 146),\n ('sigh', 146),\n ('early', 146),\n ('wants', 146),\n ('Finally', 145),\n ('tent', 145),\n ('piece', 145),\n ('shirt', 145),\n ('Margaret', 145),\n ('respect', 145),\n ('wonder', 144),\n ('Master', 144),\n ('Uncle', 144),\n ('wards', 144),\n ('public', 144),\n ('hug', 143),\n ('lives', 143),\n ('bathroom', 143),\n ('hoped', 143),\n ('Crowe', 143),\n (\"I'm\", 142),\n ('gaze', 142),\n ('shouted', 142),\n ('summer', 142),\n ('decision', 142),\n ('difficult', 142),\n ('strange', 142),\n ('Hall', 142),\n ('high', 142),\n ('Like', 142),\n ('sick', 142),\n ('Jewel', 142),\n ('flew', 141),\n ('somehow', 141),\n ('Minerva', 141),\n ('thank', 141),\n ('Light', 141),\n ('hospital', 140),\n ('edge', 140),\n ('Quidditch', 140),\n ('comes', 140),\n ('perfect', 139),\n ('return', 139),\n ('cheek', 139),\n ('covered', 139),\n ('steps', 139),\n ('breakfast', 139),\n ('hoping', 139),\n ('sleeping', 139),\n ('legs', 139),\n ('hardly', 138),\n ('moments', 138),\n ('lead', 138),\n ('explain', 138),\n ('Greengrass', 138),\n ('muggles', 138),\n ('Blaise', 138),\n ('Gin', 137),\n ('realize', 137),\n ('dear', 137),\n ('showed', 137),\n ('obviously', 137),\n ('direction', 137),\n ('attack', 137),\n ('Minister', 137),\n ('England', 137),\n ('Blackstone', 137),\n ('serious', 136),\n ('wide', 136),\n ('broken', 136),\n ('kitchen', 136),\n ('helped', 135),\n ('needs', 135),\n ('mine', 135),\n ('keeping', 134),\n ('doors', 134),\n ('eyebrows', 134),\n ('tongue', 134),\n ('led', 134),\n ('merely', 134),\n ('beginning', 133),\n ('pair', 133),\n ('forced', 133),\n ('letter', 133),\n ('single', 133),\n ('eyebrow', 133),\n ('chuckled', 133),\n ('interesting', 133),\n ('stuff', 133),\n ('feels', 132),\n ('secret', 132),\n ('pointing', 132),\n ('area', 131),\n ('normal', 131),\n ('murmured', 131),\n ('crying', 131),\n ('begin', 131),\n ('hissed', 131),\n ('Cho', 131),\n ('clothes', 130),\n ('allow', 130),\n ('suggested', 130),\n ('filled', 130),\n ('considered', 130),\n ('write', 130),\n ('snake', 130),\n ('Potions', 129),\n ('nose', 129),\n ('mad', 129),\n ('daughter', 129),\n ('calm', 129),\n ('worth', 128),\n ('witch', 128),\n ('ghost', 128),\n ('knees', 128),\n ('slight', 128),\n ('speaking', 128),\n ('obvious', 128),\n ('understood', 128),\n ('believed', 128),\n ('walls', 127),\n ('lay', 127),\n ('act', 127),\n ('scared', 127),\n ('letting', 127),\n ('writing', 127),\n ('fault', 127),\n ('rose', 127),\n ('present', 127),\n ('news', 127),\n ('wearing', 126),\n ('ended', 126),\n ('hallway', 126),\n ('bloody', 125),\n ('lose', 125),\n ('flying', 125),\n ('library', 125),\n ('dress', 124),\n ('waited', 124),\n ('following', 123),\n ('causing', 123),\n ('risk', 123),\n ('drink', 123),\n ('force', 123),\n ('master', 123),\n ('usually', 122),\n ('birthday', 122),\n ('paper', 122),\n ('tightly', 122),\n ('screamed', 122),\n ('entrance', 122),\n ('ahead', 122),\n ('six', 122),\n ('forest', 122),\n ('wondering', 121),\n ('dad', 121),\n ('response', 121),\n ('field', 121),\n ('Slytherins', 121),\n ('hide', 121),\n ('Dom', 121),\n ('cry', 120),\n ('falling', 120),\n ('teacher', 120),\n ('bedroom', 120),\n ('younger', 120),\n ('Manor', 120),\n ('Cage', 120),\n ('cheeks', 119),\n ('tight', 119),\n ('proud', 119),\n ('torture', 119),\n ('listen', 119),\n ('takes', 119),\n ('Perhaps', 119),\n ('Mrs', 118),\n ('liked', 118),\n ('saved', 118),\n ('handed', 118),\n ('check', 118),\n ('concerned', 118),\n ('business', 118),\n ('agree', 118),\n ('stories', 117),\n ('presence', 117),\n ('gasped', 117),\n ('disappeared', 117),\n ('wife', 117),\n ('worked', 117),\n ('type', 117),\n ('headed', 117),\n ('funny', 117),\n ('view', 117),\n ('pale', 116),\n ('whose', 116),\n ('beyond', 116),\n ('ass', 116),\n ('cup', 116),\n ('interest', 116),\n ('caused', 116),\n ('number', 116),\n ('unless', 116),\n ('job', 116),\n ('low', 116),\n ('scream', 115),\n ('laughter', 115),\n ('prepared', 115),\n ('Bones', 115),\n ('forget', 114),\n ('evil', 114),\n ('instantly', 114),\n ('Slughorn', 114),\n ('Duane', 114),\n ('bright', 113),\n ('mention', 113),\n ('turns', 113),\n ('points', 113),\n ('history', 113),\n ('feelings', 113),\n ('teachers', 113),\n ('finish', 113),\n ('beat', 113),\n ('happens', 113),\n ('busy', 112),\n ('heavy', 112),\n ('reach', 112),\n ('owl', 112),\n ('Ravenclaw', 112),\n ('space', 111),\n ('sharp', 111),\n ('earlier', 111),\n ('spend', 111)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Топ-1000 слов по встречаемости:')\n",
    "sorted([(word, count) for word, count in word_counter.items()], key=lambda x: x[1], reverse=True)[:1000]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "2. Найдите топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/36225 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcd3c39b29ce4213a96390ca32a942cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4ac54e39d81477780109741b10315ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree('S', [(\"…'That\", 'WDT'), (\"wand's\", 'VBZ'), ('more', 'RBR'), ('trouble', 'NN'), ('than', 'IN'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('worth', 'JJ'), (',', ','), (\"'\", \"''\"), ('said', 'VBD'), Tree('PERSON', [('Harry', 'NNP')]), (',', ','), (\"'And\", 'NNP'), ('quite', 'RB'), ('honestly', 'RB'), (',', ','), (\"'\", \"''\"), ('he', 'PRP'), ('turned', 'VBD'), ('away', 'RB'), ('from', 'IN'), ('the', 'DT'), ('painted', 'JJ'), ('portraits', 'NNS'), (',', ','), ('thinking', 'VBG'), ('now', 'RB'), ('only', 'RB'), ('of', 'IN'), ('the', 'DT'), ('four-poster', 'JJ'), ('bed', 'NN'), ('lying', 'VBG'), ('waiting', 'VBG'), ('for', 'IN'), ('him', 'PRP'), ('in', 'IN'), Tree('GPE', [('Gryffindor', 'NNP')]), ('tower', 'NN'), (',', ','), ('and', 'CC'), ('wondering', 'VBG'), ('whether', 'IN'), Tree('PERSON', [('Kreacher', 'NNP')]), ('might', 'MD'), ('bring', 'VB'), ('him', 'PRP'), ('a', 'DT'), ('sandwich', 'NN'), ('there', 'RB'), (',', ','), (\"'\", \"''\"), ('I', 'PRP'), (\"'ve\", 'VBP'), ('had', 'VBD'), ('enough', 'JJ'), ('trouble', 'NN'), ('for', 'IN'), ('a', 'DT'), ('lifetime', 'NN'), ('.', '.'), (\"'\", \"''\"), ('As', 'RB'), ('soon', 'RB'), ('as', 'IN'), ('they', 'PRP'), ('left', 'VBD'), Tree('PERSON', [('Dumbledore', 'NNP')]), (\"'s\", 'POS'), ('office', 'NN'), (',', ','), ('the', 'DT'), ('exertions', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('past', 'JJ'), ('day', 'NN'), ('caught', 'VBD'), ('up', 'RP'), ('with', 'IN'), ('him', 'PRP'), ('.', '.'), ('It', 'PRP'), ('seemed', 'VBD'), ('impossible', 'JJ'), ('that', 'IN'), ('only', 'RB'), ('this', 'DT'), ('morning', 'NN'), ('he', 'PRP'), (\"'d\", 'MD'), ('been', 'VBN'), ('at', 'IN'), Tree('ORGANIZATION', [('Shell', 'NNP')]), ('Cottage…', 'NNP'), ('He', 'PRP'), ('was', 'VBD'), ('so', 'RB'), ('tired', 'JJ'), ('he', 'PRP'), ('hardly', 'RB'), ('knew', 'VBD'), ('how', 'WRB'), ('he', 'PRP'), ('got', 'VBD'), ('to', 'TO'), Tree('GPE', [('Gryffindor', 'NNP')]), ('tower', 'NN'), ('.', '.'), ('The', 'DT'), ('fat', 'JJ'), ('lady', 'NN'), ('was', 'VBD'), ('elsewhere', 'RB'), (',', ','), ('but', 'CC'), ('the', 'DT'), ('portrait', 'NN'), ('hole', 'NN'), ('was', 'VBD'), ('swinging', 'VBG'), ('open', 'JJ'), ('in', 'IN'), ('any', 'DT'), ('case', 'NN'), ('.', '.'), ('He', 'PRP'), ('wondered', 'VBD'), ('what', 'WP'), ('had', 'VBD'), ('happened', 'VBN'), (',', ','), ('and', 'CC'), ('then', 'RB'), ('decided', 'VBD'), ('that', 'IN'), ('he', 'PRP'), ('was', 'VBD'), ('too', 'RB'), ('tired', 'VBN'), ('to', 'TO'), ('care', 'VB'), ('.', '.'), ('He', 'PRP'), ('parted', 'VBD'), ('company', 'NN'), ('from', 'IN'), Tree('PERSON', [('Ron', 'NNP')]), ('and', 'CC'), Tree('GPE', [('Hermione', 'NNP')]), ('(', '('), ('who', 'WP'), ('had', 'VBD'), (',', ','), ('for', 'IN'), ('some', 'DT'), ('impenetrable', 'JJ'), ('reason', 'NN'), ('had', 'VBD'), ('elected', 'VBN'), ('to', 'TO'), ('stay', 'VB'), ('downstairs', 'NNS'), ('a', 'DT'), ('while', 'NN'), (')', ')'), ('and', 'CC'), ('staggered', 'VBD'), ('up', 'RP'), ('the', 'DT'), ('spiral', 'JJ'), ('stairs', 'NNS'), (',', ','), ('collapsing', 'VBG'), ('onto', 'IN'), ('his', 'PRP$'), ('bed', 'NN'), ('at', 'IN'), ('the', 'DT'), ('top', 'NN'), ('without', 'IN'), ('undressing', 'VBG'), ('.', '.'), ('He', 'PRP'), ('knew', 'VBD'), ('he', 'PRP'), (\"'d\", 'MD'), ('been', 'VBN'), ('gone', 'VBN'), ('all', 'DT'), ('year', 'NN'), (',', ','), ('but', 'CC'), ('it', 'PRP'), ('was', 'VBD'), ('still', 'RB'), ('his', 'PRP$'), ('bed', 'NN'), ('.', '.'), ('He', 'PRP'), ('was', 'VBD'), ('still', 'RB'), ('a', 'DT'), Tree('ORGANIZATION', [('Gryffindor', 'NNP')]), (',', ','), ('after', 'IN'), ('all', 'DT'), ('.', '.'), Tree('PERSON', [('Harry', 'NNP')]), ('took', 'VBD'), ('off', 'RP'), ('his', 'PRP$'), ('glasses', 'NNS'), ('without', 'IN'), ('bothering', 'VBG'), ('to', 'TO'), ('open', 'VB'), ('his', 'PRP$'), ('eyes', 'NNS'), ('and', 'CC'), ('placed', 'VBD'), ('them', 'PRP'), ('on', 'IN'), ('his', 'PRP$'), ('bedside', 'NN'), ('table', 'NN'), ('.', '.'), ('Indistinct', 'JJ'), ('noises', 'NNS'), ('came', 'VBD'), ('up', 'RP'), ('the', 'DT'), ('stairs', 'NNS'), ('until', 'IN'), ('he', 'PRP'), ('shut', 'VBD'), ('the', 'DT'), ('door', 'NN'), ('with', 'IN'), ('his', 'PRP$'), ('wand', 'NN'), ('.', '.'), ('There', 'EX'), ('were', 'VBD'), ('some', 'DT'), ('things', 'NNS'), ('he', 'PRP'), ('did', 'VBD'), (\"n't\", 'RB'), ('want', 'VB'), ('to', 'TO'), ('know', 'VB'), ('.', '.'), ('After', 'IN'), ('a', 'DT'), ('while', 'NN'), (',', ','), Tree('PERSON', [('Ron', 'NNP')]), ('came', 'VBD'), ('up', 'RB'), ('and', 'CC'), ('also', 'RB'), ('collapsed', 'VBD'), ('.', '.'), (\"'Well\", 'UH'), (',', ','), (\"'\", \"''\"), Tree('PERSON', [('Ron', 'NNP')]), ('said', 'VBD'), ('.', '.'), (\"'We\", \"''\"), ('won', 'VBD'), ('.', '.'), (\"'\", \"''\"), (\"'Yeah\", 'CD'), (',', ','), (\"'\", \"''\"), ('said', 'VBD'), Tree('PERSON', [('Harry', 'NNP')]), (',', ','), ('weariness', 'NN'), ('washing', 'NN'), ('over', 'IN'), ('him', 'PRP'), ('.', '.'), (\"'We\", \"''\"), ('won', 'VBD'), ('.', '.'), (\"'\", \"''\"), ('And', 'CC'), ('as', 'IN'), ('unconsciousness', 'JJ'), ('took', 'VBD'), ('him', 'PRP'), (',', ','), ('the', 'DT'), ('only', 'JJ'), ('emotion', 'NN'), ('he', 'PRP'), ('felt', 'VBD'), ('was', 'VBD'), ('that', 'IN'), ('of', 'IN'), ('tired', 'JJ'), ('joy', 'NN'), ('.', '.'), ('The', 'DT'), ('joy', 'NN'), ('of', 'IN'), ('success', 'NN'), ('.', '.'), Tree('PERSON', [('Harry', 'NNP')]), ('woke', 'VBD'), ('slowly', 'RB'), ('–', 'JJ'), ('with', 'IN'), ('small', 'JJ'), ('bits', 'NNS'), ('of', 'IN'), ('his', 'PRP$'), ('dream', 'NN'), ('merging', 'NN'), ('into', 'IN'), ('reality', 'NN'), ('.', '.'), ('When', 'WRB'), ('he', 'PRP'), ('fully', 'RB'), ('awoke', 'VBD'), (',', ','), ('he', 'PRP'), ('saw', 'VBD'), ('that', 'IN'), ('he', 'PRP'), (\"'d\", 'MD'), ('been', 'VBN'), ('asleep', 'RB'), ('for', 'IN'), ('a', 'DT'), ('long', 'JJ'), ('time', 'NN'), (':', ':'), ('the', 'DT'), ('shadows', 'NNS'), ('were', 'VBD'), ('short', 'JJ'), ('and', 'CC'), ('the', 'DT'), ('dormitory', 'NN'), ('was', 'VBD'), ('deserted', 'VBN'), ('.', '.'), ('It', 'PRP'), ('must', 'MD'), ('be', 'VB'), ('nearly', 'RB'), ('noon', 'RB'), ('.', '.'), ('He', 'PRP'), ('got', 'VBD'), ('up', 'RB'), ('and', 'CC'), ('dressed', 'VBN'), ('on', 'IN'), ('automatic', 'JJ'), (',', ','), ('then', 'RB'), ('walked', 'VBD'), ('down', 'IN'), ('the', 'DT'), ('stairs', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('common', 'JJ'), ('room', 'NN'), (',', ','), ('which', 'WDT'), (',', ','), ('as', 'IN'), ('he', 'PRP'), ('had', 'VBD'), ('suspected', 'VBN'), (',', ','), ('was', 'VBD'), ('almost', 'RB'), ('empty', 'JJ'), ('.', '.'), Tree('PERSON', [('Hermione', 'NN')]), ('and', 'CC'), Tree('PERSON', [('Ron', 'NNP')]), ('were', 'VBD'), (\"n't\", 'RB'), ('there', 'RB'), ('.', '.'), ('He', 'PRP'), ('felt', 'VBD'), ('drained', 'VBN'), (':', ':'), ('not', 'RB'), ('physically', 'RB'), (',', ','), ('but', 'CC'), ('emotionally', 'RB'), ('.', '.'), ('And', 'CC'), ('when', 'WRB'), ('you', 'PRP'), ('think', 'VBP'), ('about', 'IN'), ('it', 'PRP'), (',', ','), ('it', 'PRP'), ('gets', 'VBZ'), ('worse', 'JJR'), ('he', 'PRP'), ('berated', 'VBD'), ('himself', 'PRP'), ('silently', 'RB'), ('.', '.'), ('So', 'RB'), ('do', 'VBP'), (\"n't\", 'RB'), ('think', 'VB'), ('about', 'IN'), ('it', 'PRP'), ('!', '.'), ('But', 'CC'), ('he', 'PRP'), ('could', 'MD'), (\"n't\", 'RB'), ('stop', 'VB'), ('thinking', 'VBG'), ('about', 'IN'), ('it', 'PRP'), ('.', '.'), ('He', 'PRP'), ('saw', 'VBD'), (',', ','), ('through', 'IN'), ('the', 'DT'), ('medium', 'NN'), ('of', 'IN'), ('memory', 'NN'), (',', ','), Tree('PERSON', [('Voldemort', 'NNP')]), ('trying', 'VBG'), ('to', 'TO'), ('kill', 'VB'), ('him', 'PRP'), ('for', 'IN'), ('the', 'DT'), ('third', 'JJ'), ('time', 'NN'), (',', ','), ('using', 'VBG'), ('the', 'DT'), ('killing', 'VBG'), ('curse', 'NN'), ('for', 'IN'), ('the', 'DT'), ('third', 'JJ'), ('time', 'NN'), (',', ','), ('saw', 'VBD'), ('him', 'PRP'), ('fail', 'VB'), (',', ','), ('for', 'IN'), ('the', 'DT'), ('third', 'JJ'), ('time…', 'NN'), ('he', 'PRP'), ('saw', 'VBD'), Tree('PERSON', [('Voldemort', 'NNP')]), ('watch', 'NN'), ('as', 'IN'), ('the', 'DT'), ('green', 'JJ'), ('light', 'NN'), (',', ','), ('yet', 'RB'), ('again', 'RB'), ('turned', 'VBN'), ('on', 'IN'), ('him…', 'NN'), ('saw', 'VBD'), ('him', 'PRP'), ('fall', 'VB'), ('under', 'IN'), ('the', 'DT'), ('terrible', 'JJ'), ('weight', 'NN'), ('of', 'IN'), ('it…', 'NN'), ('And', 'CC'), ('just', 'RB'), ('as', 'IN'), ('he', 'PRP'), ('was', 'VBD'), ('beginning', 'VBG'), ('to', 'TO'), ('think', 'VB'), ('he', 'PRP'), ('should', 'MD'), ('throw', 'VB'), ('himself', 'PRP'), ('out', 'RP'), ('the', 'DT'), ('window', 'NN'), (',', ','), ('and', 'CC'), ('was', 'VBD'), ('staring', 'VBG'), ('at', 'IN'), ('it', 'PRP'), (',', ','), ('he', 'PRP'), ('suddenly', 'RB'), ('found', 'VBD'), ('himself', 'PRP'), ('staring', 'VBG'), ('instead', 'RB'), ('into', 'IN'), ('a', 'DT'), ('pair', 'NN'), ('of', 'IN'), ('beautiful', 'JJ'), (',', ','), ('brown', 'JJ'), ('eyes', 'NNS'), ('.', '.'), (\"'Wake\", 'VB'), ('up', 'RP'), ('!', '.'), (\"'\", \"''\"), ('yelled', 'VBD'), ('a', 'DT'), ('voice', 'NN'), ('in', 'IN'), ('his', 'PRP$'), ('ear', 'NN'), (',', ','), ('and', 'CC'), ('he', 'PRP'), ('turned', 'VBD'), ('from', 'IN'), Tree('GPE', [('Ginny', 'NNP')]), (',', ','), ('the', 'DT'), ('owner', 'NN'), ('of', 'IN'), ('the', 'DT'), ('eyes', 'NNS'), (',', ','), ('and', 'CC'), ('saw', 'VBD'), Tree('PERSON', [('Ron', 'NNP')]), ('.', '.'), (\"'You\", \"''\"), (\"'ve\", 'VBP'), ('been', 'VBN'), ('asleep', 'JJ'), ('for', 'IN'), ('hours', 'NNS'), (',', ','), ('now', 'RB'), ('you', 'PRP'), (\"'re\", 'VBP'), ('awake', 'VB'), (',', ','), ('and', 'CC'), ('going', 'VBG'), ('comatose', 'JJ'), ('!', '.'), ('Come', 'NNP'), ('on', 'IN'), (',', ','), ('you', 'PRP'), ('need', 'VBP'), ('food', 'NN'), ('.', '.'), (\"'\", \"''\"), Tree('PERSON', [('Harry', 'NNP')]), ('almost', 'RB'), ('agreed', 'VBD'), ('.', '.'), ('Now', 'RB'), ('he', 'PRP'), ('came', 'VBD'), ('to', 'TO'), ('notice', 'VB'), ('it', 'PRP'), (',', ','), ('his', 'PRP$'), ('stomach', 'NN'), ('was', 'VBD'), ('growling', 'VBG'), ('so', 'RB'), ('loudly', 'RB'), ('he', 'PRP'), ('thought', 'VBD'), ('they', 'PRP'), ('could', 'MD'), ('hear', 'VB'), ('it', 'PRP'), ('down', 'RP'), ('in', 'IN'), ('the', 'DT'), ('great', 'JJ'), ('hall', 'NN'), ('.', '.'), ('But', 'CC'), Tree('PERSON', [('Ginny', 'NNP')]), ('was', 'VBD'), ('right', 'RB'), ('here', 'RB'), ('.', '.'), (\"'\", \"''\"), ('I', 'PRP'), (\"'ll\", 'MD'), ('come', 'VB'), ('down', 'RB'), ('and', 'CC'), ('meet', 'VB'), ('you', 'PRP'), ('in', 'IN'), ('a', 'DT'), ('bit', 'NN'), (',', ','), ('ok', 'RB'), ('?', '.'), (\"'\", \"''\"), Tree('PERSON', [('Ron', 'NNP')]), ('surveyed', 'VBD'), ('him', 'PRP'), (',', ','), Tree('PERSON', [('Hermione', 'NNP')]), ('surveyed', 'VBD'), Tree('PERSON', [('Ginny', 'NNP')]), (',', ','), ('and', 'CC'), ('then', 'RB'), ('both', 'DT'), ('nodded', 'VBN'), ('.', '.'), Tree('PERSON', [('Harry', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Ginny', 'NNP')]), ('watched', 'VBD'), ('them', 'PRP'), ('leave', 'VBP'), ('.', '.'), Tree('PERSON', [('Harry', 'NNP')]), ('looked', 'VBD'), ('back', 'RB'), ('at', 'IN'), Tree('ORGANIZATION', [('Ginny', 'NNP')]), ('.', '.'), Tree('PERSON', [('Ginny', 'NNP')]), ('looked', 'VBD'), ('back', 'RB'), ('at', 'IN'), Tree('ORGANIZATION', [('Harry', 'NNP')]), ('.', '.'), Tree('PERSON', [('Harry', 'NNP')]), ('cast', 'VBD'), ('around', 'IN'), ('for', 'IN'), ('something', 'NN'), ('to', 'TO'), ('say', 'VB'), ('and', 'CC'), ('hit', 'VB'), ('on', 'IN'), ('the', 'DT'), ('events', 'NNS'), ('of', 'IN'), ('last', 'JJ'), ('night', 'NN'), ('.', '.'), ('But', 'CC'), ('now', 'RB'), ('he', 'PRP'), ('came', 'VBD'), ('to', 'TO'), ('it', 'PRP'), (',', ','), ('there', 'EX'), ('was', 'VBD'), ('only', 'RB'), ('one', 'CD'), ('thing', 'NN'), ('he', 'PRP'), ('thought', 'VBD'), Tree('PERSON', [('Ginny', 'NNP')]), ('would', 'MD'), ('want', 'VB'), ('to', 'TO'), ('discuss', 'VB'), ('about', 'IN'), ('it', 'PRP'), ('.', '.'), (\"'\", \"''\"), ('I', 'PRP'), ('was', 'VBD'), ('there', 'RB'), ('when', 'WRB'), ('Fred…', 'NNP'), ('you', 'PRP'), ('know…', 'VBP'), (\"'\", \"''\"), ('He', 'PRP'), ('looked', 'VBD'), ('up', 'RP'), ('at', 'IN'), Tree('ORGANIZATION', [('Ginny', 'NNP')]), (',', ','), ('and', 'CC'), ('saw', 'VBD'), ('tears', 'NNS'), ('pouring', 'VBG'), ('down', 'RP'), ('her', 'PRP$'), ('cheeks', 'NN'), ('.', '.'), (\"'Yeah\", 'UH'), (',', ','), (\"'\", \"''\"), ('she', 'PRP'), ('whispered', 'VBD'), (',', ','), (\"'\", \"''\"), ('I', 'PRP'), ('know', 'VBP'), ('.', '.'), (\"'\", \"''\"), (\"'Ah\", 'CD'), (',', ','), ('Gin…', 'NNP'), (\"'\", 'POS'), ('he', 'PRP'), ('really', 'RB'), ('did', 'VBD'), (\"n't\", 'RB'), ('like', 'VB'), ('seeing', 'VBG'), ('her', 'PRP$'), ('cry', 'NN'), ('.', '.'), ('He', 'PRP'), ('got', 'VBD'), ('up', 'RP'), ('from', 'IN'), ('his', 'PRP$'), ('chair', 'NN'), ('and', 'CC'), ('held', 'VBD'), ('her', 'PRP$'), ('until', 'IN'), ('her', 'PRP$'), ('tears', 'NNS'), ('subsided', 'VBD'), (',', ','), ('then', 'RB'), ('sat', 'VBD'), ('down', 'RB'), ('again', 'RB'), (',', ','), ('pulling', 'VBG'), ('her', 'PRP$'), ('down', 'NN'), ('with', 'IN'), ('him', 'PRP'), ('.', '.'), (\"'Yeah\", \"''\"), (',', ','), (\"'\", \"''\"), ('she', 'PRP'), ('repeated', 'VBD'), ('.', '.'), (\"'Percy\", 'CD'), ('went', 'VBD'), ('after', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('Rookwood', 'NNP')]), (',', ','), ('the', 'DT'), ('guy', 'NN'), ('who', 'WP'), ('did', 'VBD'), ('it', 'PRP'), (',', ','), ('you', 'PRP'), ('know', 'VBP'), ('.', '.'), (\"'\", \"''\"), (\"'Yeah\", 'UH'), (',', ','), ('he', 'PRP'), ('did', 'VBD'), (',', ','), (\"'\", \"''\"), ('said', 'VBD'), Tree('PERSON', [('Harry', 'NNP')]), (',', ','), ('remembering', 'VBG'), Tree('PERSON', [('Percy', 'NNP')]), (\"'s\", 'POS'), ('charge', 'NN'), ('.', '.'), (\"'Did\", 'CC'), ('he', 'PRP'), ('catch', 'VB'), ('him', 'PRP'), ('?', '.'), (\"'\", \"''\"), Tree('PERSON', [('Ginny', 'NNP')]), ('smiled', 'VBD'), ('a', 'DT'), ('bit', 'NN'), ('.', '.'), (\"'Yes\", 'UH'), (',', ','), ('he', 'PRP'), ('did', 'VBD'), ('.', '.'), ('He', 'PRP'), ('got', 'VBD'), ('him', 'PRP'), ('.', '.'), ('Stunned', 'VBD'), ('him', 'PRP'), (',', ','), ('and', 'CC'), ('he', 'PRP'), ('says', 'VBZ'), ('he', 'PRP'), ('wished', 'VBD'), (\"he'd\", 'PRP'), ('done', 'VBN'), ('more', 'RBR'), (',', ','), ('but', 'CC'), ('he', 'PRP'), ('could', 'MD'), (\"n't\", 'RB'), (',', ','), ('because', 'IN'), Tree('PERSON', [('Macnair', 'NNP')]), ('was', 'VBD'), ('after', 'IN'), ('him', 'PRP'), ('.', '.'), ('He', 'PRP'), ('got', 'VBD'), Tree('PERSON', [('Macnair', 'NNP')]), (',', ','), ('too', 'RB'), ('.', '.'), (\"'\", \"''\"), Tree('PERSON', [('Harry', 'NNP')]), ('smiled', 'VBD'), ('at', 'IN'), ('this', 'DT'), ('.', '.'), Tree('PERSON', [('Percy', 'NNP')]), (',', ','), ('the', 'DT'), ('fussy', 'NN'), (',', ','), ('boring', 'VBG'), ('head', 'NN'), ('boy', 'NN'), ('interested', 'JJ'), ('in', 'IN'), ('cauldron', 'NN'), ('bottoms', 'NNS'), ('had', 'VBD'), ('floored', 'VBN'), ('at', 'IN'), ('least', 'JJS'), ('two', 'CD'), ('death', 'NN'), ('eaters', 'NNS'), ('.', '.'), (\"'Did\", 'CC'), ('he', 'PRP'), ('get', 'VB'), ('any', 'DT'), ('other', 'JJ'), (\"'s\", 'POS'), ('?', '.'), (\"'\", \"''\"), Tree('PERSON', [('Harry', 'NNP')]), ('wondered', 'VBD'), ('aloud', 'JJ'), ('.', '.'), (\"'Yeah\", 'UH'), (',', ','), ('he', 'PRP'), ('got', 'VBD'), ('everyone', 'NN'), ('in', 'IN'), ('that', 'DT'), ('group', 'NN'), ('.', '.'), (\"'\", \"''\"), (\"'Wow\", 'POS'), ('.', '.'), (\"'\", \"''\"), (\"'Yeah\", 'CD'), (',', ','), ('wow', 'NN'), ('.', '.'), ('I', 'PRP'), (\"don't\", 'VBD'), ('even', 'RB'), ('know', 'VB'), ('where', 'WRB'), ('he', 'PRP'), ('learnt', 'VBZ'), ('half', 'PDT'), ('the', 'DT'), ('curses', 'NNS'), ('he', 'PRP'), ('used', 'VBD'), ('.', '.'), (\"'\", \"''\"), (\"'Huh\", 'POS'), ('.', '.'), ('What', 'WP'), ('were', 'VBD'), ('the', 'DT'), ('effects', 'NNS'), ('?', '.'), (\"'\", \"''\"), (\"'Well\", 'UH'), (',', ','), ('you', 'PRP'), ('saw', 'VBD'), ('hat', 'WP'), ('one', 'CD'), ('he', 'PRP'), ('used', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('minister', 'NN'), (',', ','), ('right', 'RB'), ('?', '.'), (\"'\", \"''\"), Tree('PERSON', [('Ginny', 'NNP')]), ('got', 'VBD'), ('up', 'RP'), ('off', 'IN'), ('his', 'PRP$'), ('knee', 'NN'), ('and', 'CC'), ('sat', 'NN'), ('on', 'IN'), ('the', 'DT'), ('arm', 'NN'), ('of', 'IN'), ('his', 'PRP$'), ('chair', 'NN'), ('.', '.'), (\"'Yep\", \"''\"), ('.', '.'), (\"'\", \"''\"), (\"'Lucky\", 'JJ'), ('you', 'PRP'), (',', ','), ('I', 'PRP'), ('did', 'VBD'), (\"n't\", 'RB'), ('.', '.'), ('But', 'CC'), ('he', 'PRP'), ('used', 'VBD'), ('another', 'DT'), ('one', 'NN'), ('on', 'IN'), Tree('PERSON', [('Macnair', 'NNP')]), ('that', 'IN'), ('made', 'VBD'), ('him', 'PRP'), ('stick', 'VB'), ('his', 'PRP$'), ('leg', 'NN'), ('right', 'VBD'), ('up', 'RB'), ('until', 'IN'), ('it', 'PRP'), ('touched', 'VBD'), ('his', 'PRP$'), ('ear', 'NN'), (',', ','), ('and', 'CC'), ('another', 'DT'), ('one', 'NN'), ('that', 'WDT'), ('hung', 'VBZ'), ('a', 'DT'), ('guy', 'NN'), ('upside', 'RB'), ('down', 'RB'), ('by', 'IN'), ('his', 'PRP$'), ('ankle…', 'NN'), (\"'\", \"''\"), (\"'Yeah\", 'CD'), (',', ','), ('I', 'PRP'), ('know', 'VBP'), ('that', 'IN'), ('one', 'CD'), (',', ','), ('levicorpus', 'NN'), (',', ','), (\"'\", \"''\"), (\"'Ha\", 'CD'), (',', ','), ('yes', 'UH'), (',', ','), Tree('PERSON', [('Ron', 'NNP')]), ('told', 'VBD'), ('me', 'PRP'), ('you', 'PRP'), ('used', 'VBD'), ('it', 'PRP'), ('on', 'IN'), ('him', 'PRP'), ('once', 'RB'), ('.', '.'), (\"'\", \"''\"), Tree('PERSON', [('Harry', 'NNP')]), ('was', 'VBD'), ('having', 'VBG'), ('fun', 'NN'), (',', ','), ('they', 'PRP'), ('were', 'VBD'), ('chatting', 'VBG'), ('easily', 'RB'), (',', ','), ('but…', 'VB'), ('His', 'PRP$'), ('stomach', 'NN'), ('rumbled', 'VBD'), ('again', 'RB'), (',', ','), ('loud', 'JJ'), ('enough', 'RB'), ('for', 'IN'), Tree('PERSON', [('Ginny', 'NNP')]), ('to', 'TO'), ('hear', 'VB'), ('it', 'PRP'), ('.', '.'), ('She', 'PRP'), ('looked', 'VBD'), ('at', 'IN'), ('him', 'PRP'), ('in', 'IN'), ('amusement', 'NN'), ('.', '.'), (\"'You\", 'CC'), (\"'re\", 'VBP'), ('hungry', 'JJ'), (\"'\", 'POS'), ('.', '.'), Tree('PERSON', [('Harry', 'NNP')]), ('winced', 'VBD'), ('from', 'IN'), ('the', 'DT'), ('hunger', 'NN'), ('pains', 'VBZ'), ('.', '.'), (\"'Yeah\", \"''\"), ('.', '.'), ('But', 'CC'), ('the', 'DT'), Tree('ORGANIZATION', [('Ministry', 'NNP')]), (\"'ll\", 'MD'), ('be', 'VB'), ('waiting', 'VBG'), ('for', 'IN'), ('me', 'PRP'), ('down', 'IN'), ('there', 'RB'), (',', ','), ('and', 'CC'), ('I', 'PRP'), ('do', 'VBP'), (\"n't\", 'RB'), ('want', 'VB'), ('to', 'TO'), ('face', 'VB'), ('them', 'PRP'), ('.', '.'), ('So', 'RB'), ('will', 'MD'), ('the', 'DT'), ('Prophet', 'NNP'), ('.', '.'), ('And', 'CC'), ('a', 'DT'), ('thousand', 'CD'), ('other', 'JJ'), ('people', 'NNS'), ('.', '.'), ('And', 'CC'), ('I', 'PRP'), ('do', 'VBP'), (\"n't\", 'RB'), ('want', 'VB'), ('to', 'TO'), ('see', 'VB'), ('any', 'DT'), ('of', 'IN'), ('them', 'PRP'), ('.', '.'), (\"'\", \"''\"), ('He', 'PRP'), ('looked', 'VBD'), ('at', 'IN'), Tree('ORGANIZATION', [('Ginny', 'NNP')]), ('beseechingly', 'RB'), ('.', '.'), (\"'Reckon\", 'CC'), ('you', 'PRP'), ('could', 'MD'), ('get', 'VB'), ('enough', 'RB'), ('for', 'IN'), ('two', 'CD'), ('and', 'CC'), ('meet', 'VB'), ('me', 'PRP'), ('back', 'RP'), ('up', 'IN'), ('here', 'RB'), ('?', '.'), (\"'\", \"''\"), Tree('PERSON', [('Ginny', 'NNP')]), ('smiled', 'VBD'), ('again', 'RB'), ('.', '.'), (\"'Sure\", 'NN'), ('.', '.'), (\"'\", \"''\"), ('Ten', 'CD'), ('minutes', 'NNS'), ('later', 'RB'), (',', ','), Tree('PERSON', [('Ginny', 'NNP')]), ('came', 'VBD'), ('back', 'RP'), ('up', 'RP'), ('with', 'IN'), ('a', 'DT'), ('basketful', 'NN'), ('of', 'IN'), ('food', 'NN'), ('.', '.'), (\"'Ron\", 'CD'), ('and', 'CC'), ('Hermione', 'NNP'), ('are', 'VBP'), ('sitting', 'VBG'), ('very', 'RB'), ('close', 'RB'), ('together', 'NN'), (\"'\", \"''\"), ('she', 'PRP'), ('said', 'VBD'), (',', ','), ('grinning', 'VBG'), (',', ','), ('as', 'IN'), ('she', 'PRP'), ('set', 'VBD'), ('it', 'PRP'), ('down', 'RP'), ('.', '.'), (\"'And\", 'IN'), ('you', 'PRP'), ('were', 'VBD'), ('right', 'JJ'), ('–', 'NNP'), Tree('PERSON', [('Kingsley', 'NNP')]), ('was', 'VBD'), ('down', 'RB'), ('there', 'RB'), (',', ','), ('and', 'CC'), ('so', 'RB'), ('were', 'VBD'), ('a', 'DT'), ('couple', 'NN'), ('of', 'IN'), ('people', 'NNS'), ('from', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('Prophet', 'NNP')]), (',', ','), Tree('PERSON', [('Luna', 'NNP')]), (\"'s\", 'POS'), ('dad', 'NN'), ('was', 'VBD'), ('there', 'RB'), (',', ','), Tree('ORGANIZATION', [('McGonagall', 'NNP')]), (',', ','), ('the', 'DT'), Tree('GPE', [('Malfoys', 'NNP')]), (',', ','), ('all', 'DT'), ('my', 'PRP$'), ('family…', 'NN'), ('about', 'IN'), ('half', 'PDT'), ('the', 'DT'), ('wizarding', 'JJ'), ('world', 'NN'), ('was', 'VBD'), ('waiting', 'VBG'), ('for', 'IN'), ('you', 'PRP'), ('to', 'TO'), ('show', 'VB'), ('up', 'RP'), ('.', '.'), (\"'\", \"''\"), ('After', 'IN'), ('a', 'DT'), ('superb', 'NN'), ('lunch', 'NN'), (',', ','), Tree('PERSON', [('Harry', 'NNP')]), (',', ','), Tree('PERSON', [('Ron', 'NNP')]), (',', ','), Tree('PERSON', [('Hermione', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Ginny', 'NNP')]), ('adjourned', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('grounds', 'NNS'), ('.', '.'), Tree('PERSON', [('Someone', 'NN')]), ('had', 'VBD'), ('cleared', 'VBN'), ('the', 'DT'), ('bodies', 'NNS'), ('away', 'RB'), (',', ','), ('and', 'CC'), ('even', 'RB'), ('the', 'DT'), ('grass', 'NN'), ('was', 'VBD'), ('green', 'JJ'), ('again…', 'NN'), ('in', 'IN'), ('the', 'DT'), ('patches', 'NNS'), ('where', 'WRB'), ('it', 'PRP'), ('could', 'MD'), ('still', 'RB'), ('grow', 'VB'), (',', ','), ('there', 'EX'), ('were', 'VBD'), ('many', 'JJ'), ('where', 'WRB'), ('it', 'PRP'), ('never', 'RB'), ('would', 'MD'), ('again', 'RB'), ('.', '.'), ('It', 'PRP'), ('was', 'VBD'), ('a', 'DT'), ('beautiful', 'JJ'), ('sunny', 'JJ'), ('day', 'NN'), (',', ','), ('the', 'DT'), ('sky', 'NN'), ('was', 'VBD'), ('a', 'DT'), ('clear', 'JJ'), ('blue', 'NN'), ('and', 'CC'), ('the', 'DT'), ('heat', 'NN'), ('was', 'VBD'), ('unrelenting', 'JJ'), (',', ','), ('as', 'IN'), ('if', 'IN'), ('the', 'DT'), ('day', 'NN'), (\"'s\", 'POS'), ('weather', 'NN'), ('were', 'VBD'), ('trying', 'VBG'), ('to', 'TO'), ('make', 'VB'), ('people', 'NNS'), ('forget', 'VB'), ('what', 'WP'), ('had', 'VBD'), ('happened', 'VBN'), ('last', 'JJ'), ('night', 'NN'), ('.', '.'), ('They', 'PRP'), ('all', 'DT'), ('sat', 'VBD'), ('down', 'RP'), ('next', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('lake', 'NN'), ('.', '.'), Tree('PERSON', [('Harry', 'NNP')]), ('noticed', 'VBD'), ('that', 'IN'), Tree('PERSON', [('Hermione', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Ron', 'NNP')]), ('were', 'VBD'), ('sitting', 'VBG'), ('very', 'RB'), ('close', 'RB'), ('together', 'RB'), ('.', '.'), Tree('PERSON', [('Ginny', 'NNP')]), ('was', 'VBD'), ('looking', 'VBG'), ('at', 'IN'), ('him', 'PRP'), ('.', '.'), ('Out', 'IN'), ('of', 'IN'), ('the', 'DT'), ('corner', 'NN'), ('of', 'IN'), ('his', 'PRP$'), ('eye', 'NN'), (',', ','), ('he', 'PRP'), ('saw', 'VBD'), Tree('PERSON', [('Ron', 'NNP')]), ('take', 'VB'), Tree('PERSON', [('Hermione', 'NNP')]), (\"'s\", 'POS'), ('hand', 'NN'), (',', ','), ('but', 'CC'), ('he', 'PRP'), ('just', 'RB'), ('kept', 'VBD'), ('looking', 'VBG'), ('at', 'IN'), Tree('ORGANIZATION', [('Ginny', 'NNP')]), (',', ','), ('drinking', 'VBG'), ('her', 'PRP$'), ('in', 'IN'), ('with', 'IN'), ('his', 'PRP$'), ('eyes', 'NNS'), ('.', '.'), (\"'Oi\", 'CD'), (',', ','), Tree('PERSON', [('Harry', 'NNP')]), (',', ','), ('me', 'PRP'), ('and', 'CC'), ('Hermione', 'NNP'), ('are', 'VBP'), ('going', 'VBG'), ('inside', 'IN'), (',', ','), ('ok', 'FW'), ('?', '.'), (\"'\", \"''\"), ('called', 'VBN'), Tree('PERSON', [('Ron', 'NNP')]), (',', ','), ('breaking', 'VBG'), ('into', 'IN'), ('his', 'PRP$'), ('thoughts', 'NNS'), ('.', '.'), Tree('PERSON', [('Hermione', 'NNP')]), ('must', 'MD'), (\"'ve\", 'VBP'), ('whispered', 'VBN'), ('to', 'TO'), ('him', 'PRP'), ('thought', 'JJ'), Tree('PERSON', [('Harry', 'NNP')]), ('.', '.'), Tree('PERSON', [('Ron', 'NNP')]), ('could', 'MD'), ('never', 'RB'), ('have', 'VB'), ('been', 'VBN'), ('accused', 'VBN'), ('of', 'IN'), ('being', 'VBG'), ('tactful', 'JJ'), ('..', 'NN'), (\"'Ok\", 'CD'), (',', ','), ('bye', 'NN'), ('!', '.'), (\"'\", \"''\"), ('he', 'PRP'), ('called', 'VBD'), ('to', 'TO'), ('their', 'PRP$'), ('retreating', 'NN'), ('figures', 'NNS'), (',', ','), ('and', 'CC'), ('then', 'RB'), ('it', 'PRP'), ('was', 'VBD'), ('just', 'RB'), ('him', 'PRP'), ('and', 'CC'), Tree('PERSON', [('Ginny', 'NNP')]), ('.', '.'), ('They', 'PRP'), ('sat', 'VBD'), ('together', 'RB'), (',', ','), ('looking', 'VBG'), ('out', 'RP'), ('over', 'IN'), ('the', 'DT'), ('lake', 'NN'), ('.', '.'), Tree('PERSON', [('Harry', 'NNP')]), ('tried', 'VBD'), ('to', 'TO'), ('think', 'VB'), ('of', 'IN'), ('something', 'NN'), ('to', 'TO'), ('say', 'VB'), (',', ','), ('but', 'CC'), ('still', 'RB'), (',', ','), ('ho', 'NN'), ('could', 'MD'), ('only', 'RB'), ('settle', 'VB'), ('on', 'IN'), ('last', 'JJ'), ('night', 'NN'), ('.', '.'), ('So', 'IN'), ('that', 'DT'), (\"'s\", 'VBZ'), ('what', 'WP'), ('they', 'PRP'), ('talked', 'VBD'), ('about', 'IN'), ('.', '.'), Tree('PERSON', [('Harry', 'NNP')]), ('recounted', 'VBD'), ('his', 'PRP$'), ('story', 'NN'), (',', ','), ('and', 'CC'), Tree('PERSON', [('Ginny', 'NNP')]), ('recounted', 'VBD'), ('hers', 'NNS'), ('.', '.'), ('Tears', 'NNS'), ('were', 'VBD'), ('shed', 'VBN'), (',', ','), ('when', 'WRB'), Tree('PERSON', [('Harry', 'NNP')]), ('reached', 'VBD'), Tree('PERSON', [('Fred', 'NNP')]), (\"'s\", 'POS'), ('death', 'NN'), (',', ','), ('when', 'WRB'), ('he', 'PRP'), ('remembered', 'VBD'), ('seeing', 'VBG'), Tree('PERSON', [('Remus', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Dora', 'NNP')]), ('stretched', 'VBD'), ('out', 'RP'), ('together', 'RB'), (',', ','), ('eternally', 'RB'), ('at', 'IN'), ('peace…', 'NN'), (\"'And\", 'POS'), ('that', 'IN'), ('means', 'VBZ'), ('you', 'PRP'), (\"'re\", 'VBP'), ('godfather', 'RB'), ('now', 'RB'), (',', ','), ('does', 'VBZ'), (\"n't\", 'RB'), ('it', 'PRP'), ('?', '.'), (\"'\", \"''\"), ('said', 'VBD'), Tree('PERSON', [('Ginny', 'NNP')]), ('.', '.'), Tree('PERSON', [('Harry', 'NNP')]), ('started', 'VBD'), ('.', '.'), ('He', 'PRP'), ('had', 'VBD'), ('forgotten', 'VBN'), ('.', '.'), (\"'Yeah\", 'CD'), (',', ','), ('I', 'PRP'), ('am', 'VBP'), ('!', '.'), (\"I'd\", 'NNP'), ('forgotten', 'VBD'), ('he', 'PRP'), ('asked…', 'MD'), (\"'\", \"''\"), ('They', 'PRP'), ('concluded', 'VBD'), ('their', 'PRP$'), ('stories', 'NNS'), (',', ','), ('and', 'CC'), ('sat', 'VBD'), ('in', 'IN'), ('silence', 'NN'), ('.', '.'), Tree('PERSON', [('Harry', 'NNP')]), ('reached', 'VBD'), ('out', 'RP'), ('for', 'IN'), ('her', 'PRP$'), ('hand', 'NN'), (',', ','), ('and', 'CC'), ('found', 'VBD'), ('it', 'PRP'), ('.', '.'), ('He', 'PRP'), ('held', 'VBD'), ('it', 'PRP'), ('tight', 'JJ'), ('.', '.'), (\"'Ginny…\", 'CC'), (\"'\", \"''\"), (\"'Yeah\", \"''\"), ('?', '.'), (\"'\", \"''\"), (\"'You\", 'POS'), ('missed', 'VBD'), ('me', 'PRP'), ('this', 'DT'), ('year', 'NN'), ('?', '.'), (\"'\", \"''\"), Tree('PERSON', [('Ginny', 'NNP')]), ('leant', 'VBP'), ('into', 'IN'), ('him', 'PRP'), ('.', '.'), (\"'More\", \"''\"), ('than', 'IN'), ('anything', 'NN'), ('on', 'IN'), ('God', 'NNP'), (\"'s\", 'POS'), ('good', 'JJ'), ('earth', 'NN'), (',', ','), Tree('PERSON', [('Harry', 'NNP'), ('Potter', 'NNP')]), ('.', '.'), (\"'\", \"''\"), Tree('PERSON', [('Harry', 'NNP')]), ('sighed', 'VBD'), ('with', 'IN'), ('happiness', 'NN'), ('.', '.'), (\"'\", \"''\"), ('I', 'PRP'), ('love', 'VBP'), ('you', 'PRP'), (',', ','), Tree('PERSON', [('Gin', 'NNP')]), (',', ','), (\"'\", \"''\"), ('he', 'PRP'), ('said', 'VBD'), (',', ','), ('and', 'CC'), ('kissed', 'VBD'), ('her', 'PRP'), ('.', '.')])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [39], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m pos_tags \u001B[38;5;241m=\u001B[39m nltk\u001B[38;5;241m.\u001B[39mpos_tag(tokens)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mrepr\u001B[39m(nltk\u001B[38;5;241m.\u001B[39mne_chunk(pos_tags)))\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, ner_tag \u001B[38;5;129;01min\u001B[39;00m nltk\u001B[38;5;241m.\u001B[39mne_chunk(pos_tags):\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;66;03m#print(name, ner_tag)\u001B[39;00m\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ner_tag \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# TODO\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "name_counter = defaultdict(lambda: 0)\n",
    "\n",
    "for fp in tqdm(list(raw_data_dir.glob('*'))):\n",
    "    texts = [fp.read_text()]\n",
    "    break\n",
    "\n",
    "for text in tqdm(texts):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    print(repr(nltk.ne_chunk(pos_tags)))\n",
    "    for name, ner_tag in nltk.ne_chunk(pos_tags):\n",
    "        #print(name, ner_tag)\n",
    "        if ner_tag == '':\n",
    "            pass  # TODO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "[бонус] Найдите еще что-то интересное в корпусе (что-то специфичное для фанфиков или фентези-тематики)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "[('that', 'DT'),\n ('wand', 'VBP'),\n ('s', 'VBZ'),\n ('more', 'RBR'),\n ('trouble', 'NN'),\n ('than', 'IN'),\n ('it', 'PRP'),\n ('s', 'VBD'),\n ('worth', 'NN'),\n ('said', 'VBD'),\n ('harry', 'NN'),\n ('and', 'CC'),\n ('quite', 'RB'),\n ('honestly', 'RB'),\n ('he', 'PRP'),\n ('turned', 'VBD'),\n ('away', 'RB'),\n ('from', 'IN'),\n ('the', 'DT'),\n ('painted', 'VBN'),\n ('portraits', 'NNS'),\n ('thinking', 'VBG'),\n ('now', 'RB'),\n ('only', 'RB'),\n ('of', 'IN'),\n ('the', 'DT'),\n ('four-poster', 'JJ'),\n ('bed', 'NN'),\n ('lying', 'VBG'),\n ('waiting', 'VBG'),\n ('for', 'IN'),\n ('him', 'PRP'),\n ('in', 'IN'),\n ('gryffindor', 'NN'),\n ('tower', 'NN'),\n ('and', 'CC'),\n ('wondering', 'VBG'),\n ('whether', 'IN'),\n ('kreacher', 'NN'),\n ('might', 'MD'),\n ('bring', 'VB'),\n ('him', 'PRP'),\n ('a', 'DT'),\n ('sandwich', 'NN'),\n ('there', 'EX'),\n ('i', 'JJ'),\n ('ve', 'NN'),\n ('had', 'VBD'),\n ('enough', 'JJ'),\n ('trouble', 'NN'),\n ('for', 'IN'),\n ('a', 'DT'),\n ('lifetime', 'NN'),\n ('as', 'RB'),\n ('soon', 'RB'),\n ('as', 'IN'),\n ('they', 'PRP'),\n ('left', 'VBD'),\n ('dumbledore', 'NN'),\n ('s', 'NN'),\n ('office', 'NN'),\n ('the', 'DT'),\n ('exertions', 'NNS'),\n ('of', 'IN'),\n ('the', 'DT'),\n ('past', 'JJ'),\n ('day', 'NN'),\n ('caught', 'VBD'),\n ('up', 'RP'),\n ('with', 'IN'),\n ('him', 'PRP'),\n ('it', 'PRP'),\n ('seemed', 'VBD'),\n ('impossible', 'JJ'),\n ('that', 'IN'),\n ('only', 'RB'),\n ('this', 'DT'),\n ('morning', 'NN'),\n ('he', 'PRP'),\n ('d', 'VBZ'),\n ('been', 'VBN'),\n ('at', 'IN'),\n ('shell', 'NN'),\n ('cottage', 'NN'),\n ('he', 'PRP'),\n ('was', 'VBD'),\n ('so', 'RB'),\n ('tired', 'JJ'),\n ('he', 'PRP'),\n ('hardly', 'RB'),\n ('knew', 'VBD'),\n ('how', 'WRB'),\n ('he', 'PRP'),\n ('got', 'VBD'),\n ('to', 'TO'),\n ('gryffindor', 'VB'),\n ('tower', 'VB'),\n ('the', 'DT'),\n ('fat', 'JJ'),\n ('lady', 'NN'),\n ('was', 'VBD'),\n ('elsewhere', 'RB'),\n ('but', 'CC'),\n ('the', 'DT'),\n ('portrait', 'NN'),\n ('hole', 'NN'),\n ('was', 'VBD'),\n ('swinging', 'VBG'),\n ('open', 'JJ'),\n ('in', 'IN'),\n ('any', 'DT'),\n ('case', 'NN'),\n ('he', 'PRP'),\n ('wondered', 'VBD'),\n ('what', 'WP'),\n ('had', 'VBD'),\n ('happened', 'VBN'),\n ('and', 'CC'),\n ('then', 'RB'),\n ('decided', 'VBD'),\n ('that', 'IN'),\n ('he', 'PRP'),\n ('was', 'VBD'),\n ('too', 'RB'),\n ('tired', 'VBN'),\n ('to', 'TO'),\n ('care', 'VB'),\n ('he', 'PRP'),\n ('parted', 'VBD'),\n ('company', 'NN'),\n ('from', 'IN'),\n ('ron', 'NN'),\n ('and', 'CC'),\n ('hermione', 'NN'),\n ('-LRB-', 'NN'),\n ('who', 'WP'),\n ('had', 'VBD'),\n ('for', 'IN'),\n ('some', 'DT'),\n ('impenetrable', 'JJ'),\n ('reason', 'NN'),\n ('had', 'VBD'),\n ('elected', 'VBN'),\n ('to', 'TO'),\n ('stay', 'VB'),\n ('downstairs', 'NNS'),\n ('a', 'DT'),\n ('while', 'NN'),\n ('-RRB-', 'NN'),\n ('and', 'CC'),\n ('staggered', 'VBD'),\n ('up', 'RP'),\n ('the', 'DT'),\n ('spiral', 'JJ'),\n ('stairs', 'NNS'),\n ('collapsing', 'VBG'),\n ('onto', 'IN'),\n ('his', 'PRP$'),\n ('bed', 'NN'),\n ('at', 'IN'),\n ('the', 'DT'),\n ('top', 'NN'),\n ('without', 'IN'),\n ('undressing', 'VBG'),\n ('he', 'PRP'),\n ('knew', 'VBD'),\n ('he', 'PRP'),\n ('d', 'VBZ'),\n ('been', 'VBN'),\n ('gone', 'VBN'),\n ('all', 'DT'),\n ('year', 'NN'),\n ('but', 'CC'),\n ('it', 'PRP'),\n ('was', 'VBD'),\n ('still', 'RB'),\n ('his', 'PRP$'),\n ('bed', 'NN'),\n ('he', 'PRP'),\n ('was', 'VBD'),\n ('still', 'RB'),\n ('a', 'DT'),\n ('gryffindor', 'NN'),\n ('after', 'IN'),\n ('all', 'DT'),\n ('harry', 'NN'),\n ('took', 'VBD'),\n ('off', 'RP'),\n ('his', 'PRP$'),\n ('glasses', 'NNS'),\n ('without', 'IN'),\n ('bothering', 'VBG'),\n ('to', 'TO'),\n ('open', 'VB'),\n ('his', 'PRP$'),\n ('eyes', 'NNS'),\n ('and', 'CC'),\n ('placed', 'VBD'),\n ('them', 'PRP'),\n ('on', 'IN'),\n ('his', 'PRP$'),\n ('bedside', 'NN'),\n ('table', 'NN'),\n ('indistinct', 'JJ'),\n ('noises', 'NNS'),\n ('came', 'VBD'),\n ('up', 'RP'),\n ('the', 'DT'),\n ('stairs', 'NNS'),\n ('until', 'IN'),\n ('he', 'PRP'),\n ('shut', 'VBD'),\n ('the', 'DT'),\n ('door', 'NN'),\n ('with', 'IN'),\n ('his', 'PRP$'),\n ('wand', 'NN'),\n ('there', 'EX'),\n ('were', 'VBD'),\n ('some', 'DT'),\n ('things', 'NNS'),\n ('he', 'PRP'),\n ('did', 'VBD'),\n ('nt', 'RB'),\n ('want', 'VB'),\n ('to', 'TO'),\n ('know', 'VB'),\n ('after', 'IN'),\n ('a', 'DT'),\n ('while', 'NN'),\n ('ron', 'NN'),\n ('came', 'VBD'),\n ('up', 'RB'),\n ('and', 'CC'),\n ('also', 'RB'),\n ('collapsed', 'VBN'),\n ('well', 'RB'),\n ('ron', 'RB'),\n ('said', 'VBD'),\n ('we', 'PRP'),\n ('won', 'VBD'),\n ('yeah', 'NNS'),\n ('said', 'VBD'),\n ('harry', 'JJ'),\n ('weariness', 'NN'),\n ('washing', 'VBG'),\n ('over', 'IN'),\n ('him', 'PRP'),\n ('we', 'PRP'),\n ('won', 'VBD'),\n ('and', 'CC'),\n ('as', 'IN'),\n ('unconsciousness', 'JJ'),\n ('took', 'VBD'),\n ('him', 'PRP'),\n ('the', 'DT'),\n ('only', 'JJ'),\n ('emotion', 'NN'),\n ('he', 'PRP'),\n ('felt', 'VBD'),\n ('was', 'VBD'),\n ('that', 'IN'),\n ('of', 'IN'),\n ('tired', 'JJ'),\n ('joy', 'NN'),\n ('the', 'DT'),\n ('joy', 'NN'),\n ('of', 'IN'),\n ('success', 'NN'),\n ('harry', 'NN'),\n ('woke', 'VBD'),\n ('slowly', 'RB'),\n ('--', ':'),\n ('with', 'IN'),\n ('small', 'JJ'),\n ('bits', 'NNS'),\n ('of', 'IN'),\n ('his', 'PRP$'),\n ('dream', 'NN'),\n ('merging', 'NN'),\n ('into', 'IN'),\n ('reality', 'NN'),\n ('when', 'WRB'),\n ('he', 'PRP'),\n ('fully', 'RB'),\n ('awoke', 'VBD'),\n ('he', 'PRP'),\n ('saw', 'VBD'),\n ('that', 'IN'),\n ('he', 'PRP'),\n ('d', 'VBZ'),\n ('been', 'VBN'),\n ('asleep', 'RB'),\n ('for', 'IN'),\n ('a', 'DT'),\n ('long', 'JJ'),\n ('time', 'NN'),\n ('the', 'DT'),\n ('shadows', 'NNS'),\n ('were', 'VBD'),\n ('short', 'JJ'),\n ('and', 'CC'),\n ('the', 'DT'),\n ('dormitory', 'NN'),\n ('was', 'VBD'),\n ('deserted', 'VBN'),\n ('it', 'PRP'),\n ('must', 'MD'),\n ('be', 'VB'),\n ('nearly', 'RB'),\n ('noon', 'RB'),\n ('he', 'PRP'),\n ('got', 'VBD'),\n ('up', 'RB'),\n ('and', 'CC'),\n ('dressed', 'VBN'),\n ('on', 'IN'),\n ('automatic', 'JJ'),\n ('then', 'RB'),\n ('walked', 'VBD'),\n ('down', 'IN'),\n ('the', 'DT'),\n ('stairs', 'NNS'),\n ('to', 'TO'),\n ('the', 'DT'),\n ('common', 'JJ'),\n ('room', 'NN'),\n ('which', 'WDT'),\n ('as', 'IN'),\n ('he', 'PRP'),\n ('had', 'VBD'),\n ('suspected', 'VBN'),\n ('was', 'VBD'),\n ('almost', 'RB'),\n ('empty', 'JJ'),\n ('hermione', 'NN'),\n ('and', 'CC'),\n ('ron', 'NN'),\n ('were', 'VBD'),\n ('nt', 'RB'),\n ('there', 'EX'),\n ('he', 'PRP'),\n ('felt', 'VBD'),\n ('drained', 'VBN'),\n ('not', 'RB'),\n ('physically', 'RB'),\n ('but', 'CC'),\n ('emotionally', 'RB'),\n ('and', 'CC'),\n ('when', 'WRB'),\n ('you', 'PRP'),\n ('think', 'VBP'),\n ('about', 'IN'),\n ('it', 'PRP'),\n ('it', 'PRP'),\n ('gets', 'VBZ'),\n ('worse', 'JJR'),\n ('he', 'PRP'),\n ('berated', 'VBD'),\n ('himself', 'PRP'),\n ('silently', 'RB'),\n ('so', 'RB'),\n ('do', 'JJ'),\n ('nt', 'RB'),\n ('think', 'VB'),\n ('about', 'IN'),\n ('it', 'PRP'),\n ('but', 'CC'),\n ('he', 'PRP'),\n ('could', 'MD'),\n ('nt', 'VB'),\n ('stop', 'VB'),\n ('thinking', 'VBG'),\n ('about', 'IN'),\n ('it', 'PRP'),\n ('he', 'PRP'),\n ('saw', 'VBD'),\n ('through', 'IN'),\n ('the', 'DT'),\n ('medium', 'NN'),\n ('of', 'IN'),\n ('memory', 'NN'),\n ('voldemort', 'NN'),\n ('trying', 'VBG'),\n ('to', 'TO'),\n ('kill', 'VB'),\n ('him', 'PRP'),\n ('for', 'IN'),\n ('the', 'DT'),\n ('third', 'JJ'),\n ('time', 'NN'),\n ('using', 'VBG'),\n ('the', 'DT'),\n ('killing', 'VBG'),\n ('curse', 'NN'),\n ('for', 'IN'),\n ('the', 'DT'),\n ('third', 'JJ'),\n ('time', 'NN'),\n ('saw', 'VBD'),\n ('him', 'PRP'),\n ('fail', 'VB'),\n ('for', 'IN'),\n ('the', 'DT'),\n ('third', 'JJ'),\n ('time', 'NN'),\n ('he', 'PRP'),\n ('saw', 'VBD'),\n ('voldemort', 'RB'),\n ('watch', 'NN'),\n ('as', 'IN'),\n ('the', 'DT'),\n ('green', 'JJ'),\n ('light', 'NN'),\n ('yet', 'RB'),\n ('again', 'RB'),\n ('turned', 'VBN'),\n ('on', 'IN'),\n ('him', 'PRP'),\n ('saw', 'VBD'),\n ('him', 'PRP'),\n ('fall', 'VB'),\n ('under', 'IN'),\n ('the', 'DT'),\n ('terrible', 'JJ'),\n ('weight', 'NN'),\n ('of', 'IN'),\n ('it', 'PRP'),\n ('and', 'CC'),\n ('just', 'RB'),\n ('as', 'IN'),\n ('he', 'PRP'),\n ('was', 'VBD'),\n ('beginning', 'VBG'),\n ('to', 'TO'),\n ('think', 'VB'),\n ('he', 'PRP'),\n ('should', 'MD'),\n ('throw', 'VB'),\n ('himself', 'PRP'),\n ('out', 'RP'),\n ('the', 'DT'),\n ('window', 'NN'),\n ('and', 'CC'),\n ('was', 'VBD'),\n ('staring', 'VBG'),\n ('at', 'IN'),\n ('it', 'PRP'),\n ('he', 'PRP'),\n ('suddenly', 'RB'),\n ('found', 'VBD'),\n ('himself', 'PRP'),\n ('staring', 'VBG'),\n ('instead', 'RB'),\n ('into', 'IN'),\n ('a', 'DT'),\n ('pair', 'NN'),\n ('of', 'IN'),\n ('beautiful', 'JJ'),\n ('brown', 'JJ'),\n ('eyes', 'NNS'),\n ('wake', 'VBP'),\n ('up', 'RP'),\n ('yelled', 'VBD'),\n ('a', 'DT'),\n ('voice', 'NN'),\n ('in', 'IN'),\n ('his', 'PRP$'),\n ('ear', 'NN'),\n ('and', 'CC'),\n ('he', 'PRP'),\n ('turned', 'VBD'),\n ('from', 'IN'),\n ('ginny', 'NN'),\n ('the', 'DT'),\n ('owner', 'NN'),\n ('of', 'IN'),\n ('the', 'DT'),\n ('eyes', 'NNS'),\n ('and', 'CC'),\n ('saw', 'VBD'),\n ('ron', 'NN'),\n ('you', 'PRP'),\n ('ve', 'VBP'),\n ('been', 'VBN'),\n ('asleep', 'RB'),\n ('for', 'IN'),\n ('hours', 'NNS'),\n ('now', 'RB'),\n ('you', 'PRP'),\n ('re', 'VBP'),\n ('awake', 'VB'),\n ('and', 'CC'),\n ('going', 'VBG'),\n ('comatose', 'JJ'),\n ('come', 'VBN'),\n ('on', 'IN'),\n ('you', 'PRP'),\n ('need', 'VBP'),\n ('food', 'NN'),\n ('harry', 'NN'),\n ('almost', 'RB'),\n ('agreed', 'VBD'),\n ('now', 'RB'),\n ('he', 'PRP'),\n ('came', 'VBD'),\n ('to', 'TO'),\n ('notice', 'VB'),\n ('it', 'PRP'),\n ('his', 'PRP$'),\n ('stomach', 'NN'),\n ('was', 'VBD'),\n ('growling', 'VBG'),\n ('so', 'RB'),\n ('loudly', 'RB'),\n ('he', 'PRP'),\n ('thought', 'VBD'),\n ('they', 'PRP'),\n ('could', 'MD'),\n ('hear', 'VB'),\n ('it', 'PRP'),\n ('down', 'RP'),\n ('in', 'IN'),\n ('the', 'DT'),\n ('great', 'JJ'),\n ('hall', 'NN'),\n ('but', 'CC'),\n ('ginny', 'NN'),\n ('was', 'VBD'),\n ('right', 'RB'),\n ('here', 'RB'),\n ('i', 'JJ'),\n ('ll', 'VBP'),\n ('come', 'VBP'),\n ('down', 'RB'),\n ('and', 'CC'),\n ('meet', 'VB'),\n ('you', 'PRP'),\n ('in', 'IN'),\n ('a', 'DT'),\n ('bit', 'NN'),\n ('ok', 'JJ'),\n ('ron', 'NN'),\n ('surveyed', 'VBD'),\n ('him', 'PRP'),\n ('hermione', 'VB'),\n ('surveyed', 'VBN'),\n ('ginny', 'NN'),\n ('and', 'CC'),\n ('then', 'RB'),\n ('both', 'DT'),\n ('nodded', 'VBN'),\n ('harry', 'NN'),\n ('and', 'CC'),\n ('ginny', 'NN'),\n ('watched', 'VBD'),\n ('them', 'PRP'),\n ('leave', 'VBP'),\n ('harry', 'NN'),\n ('looked', 'VBD'),\n ('back', 'RB'),\n ('at', 'IN'),\n ('ginny', 'NN'),\n ('ginny', 'NN'),\n ('looked', 'VBD'),\n ('back', 'RB'),\n ('at', 'IN'),\n ('harry', 'NN'),\n ('harry', 'NN'),\n ('cast', 'VBP'),\n ('around', 'IN'),\n ('for', 'IN'),\n ('something', 'NN'),\n ('to', 'TO'),\n ('say', 'VB'),\n ('and', 'CC'),\n ('hit', 'VB'),\n ('on', 'IN'),\n ('the', 'DT'),\n ('events', 'NNS'),\n ('of', 'IN'),\n ('last', 'JJ'),\n ('night', 'NN'),\n ('but', 'CC'),\n ('now', 'RB'),\n ('he', 'PRP'),\n ('came', 'VBD'),\n ('to', 'TO'),\n ('it', 'PRP'),\n ('there', 'EX'),\n ('was', 'VBD'),\n ('only', 'RB'),\n ('one', 'CD'),\n ('thing', 'NN'),\n ('he', 'PRP'),\n ('thought', 'VBD'),\n ('ginny', 'RB'),\n ('would', 'MD'),\n ('want', 'VB'),\n ('to', 'TO'),\n ('discuss', 'VB'),\n ('about', 'IN'),\n ('it', 'PRP'),\n ('i', 'NN'),\n ('was', 'VBD'),\n ('there', 'RB'),\n ('when', 'WRB'),\n ('fred', 'VBN'),\n ('you', 'PRP'),\n ('know', 'VBP'),\n ('he', 'PRP'),\n ('looked', 'VBD'),\n ('up', 'RP'),\n ('at', 'IN'),\n ('ginny', 'NN'),\n ('and', 'CC'),\n ('saw', 'VBD'),\n ('tears', 'NNS'),\n ('pouring', 'VBG'),\n ('down', 'RP'),\n ('her', 'PRP$'),\n ('cheeks', 'NN'),\n ('yeah', 'NN'),\n ('she', 'PRP'),\n ('whispered', 'VBD'),\n ('i', 'NNS'),\n ('know', 'VBP'),\n ('ah', 'RB'),\n ('gin', 'NN'),\n ('he', 'PRP'),\n ('really', 'RB'),\n ('did', 'VBD'),\n ('nt', 'NNS'),\n ('like', 'IN'),\n ('seeing', 'VBG'),\n ('her', 'PRP$'),\n ('cry', 'NN'),\n ('he', 'PRP'),\n ('got', 'VBD'),\n ('up', 'RP'),\n ('from', 'IN'),\n ('his', 'PRP$'),\n ('chair', 'NN'),\n ('and', 'CC'),\n ('held', 'VBD'),\n ('her', 'PRP$'),\n ('until', 'IN'),\n ('her', 'PRP$'),\n ('tears', 'NNS'),\n ('subsided', 'VBD'),\n ('then', 'RB'),\n ('sat', 'VBD'),\n ('down', 'RB'),\n ('again', 'RB'),\n ('pulling', 'VBG'),\n ('her', 'PRP$'),\n ('down', 'NN'),\n ('with', 'IN'),\n ('him', 'PRP'),\n ('yeah', 'VB'),\n ('she', 'PRP'),\n ('repeated', 'VBD'),\n ('percy', 'JJ'),\n ('went', 'VBD'),\n ('after', 'IN'),\n ('the', 'DT'),\n ('rookwood', 'NN'),\n ('the', 'DT'),\n ('guy', 'NN'),\n ('who', 'WP'),\n ('did', 'VBD'),\n ('it', 'PRP'),\n ('you', 'PRP'),\n ('know', 'VBP'),\n ('yeah', 'RB'),\n ('he', 'PRP'),\n ('did', 'VBD'),\n ('said', 'VBD'),\n ('harry', 'NN'),\n ('remembering', 'VBG'),\n ('percy', 'JJ'),\n ('s', 'JJ'),\n ('charge', 'NN'),\n ('did', 'VBD'),\n ('he', 'PRP'),\n ('catch', 'VB'),\n ('him', 'PRP'),\n ('ginny', 'VB'),\n ('smiled', 'VBD'),\n ('a', 'DT'),\n ('bit', 'NN'),\n ('yes', 'RB'),\n ('he', 'PRP'),\n ('did', 'VBD'),\n ('he', 'PRP'),\n ('got', 'VBD'),\n ('him', 'PRP'),\n ('stunned', 'VBD'),\n ('him', 'PRP'),\n ('and', 'CC'),\n ('he', 'PRP'),\n ('says', 'VBZ'),\n ('he', 'PRP'),\n ('wished', 'VBD'),\n ('he', 'PRP'),\n ('d', 'VB'),\n ('done', 'VBN'),\n ('more', 'RBR'),\n ('but', 'CC'),\n ('he', 'PRP'),\n ('could', 'MD'),\n ('nt', 'VB'),\n ('because', 'IN'),\n ('macnair', 'NN'),\n ('was', 'VBD'),\n ('after', 'IN'),\n ('him', 'PRP'),\n ('he', 'PRP'),\n ('got', 'VBD'),\n ('macnair', 'RB'),\n ('too', 'RB'),\n ('harry', 'JJ'),\n ('smiled', 'VBN'),\n ('at', 'IN'),\n ('this', 'DT'),\n ('percy', 'VBZ'),\n ('the', 'DT'),\n ('fussy', 'JJ'),\n ('boring', 'JJ'),\n ('head', 'NN'),\n ('boy', 'NN'),\n ('interested', 'JJ'),\n ('in', 'IN'),\n ('cauldron', 'NN'),\n ('bottoms', 'NNS'),\n ('had', 'VBD'),\n ('floored', 'VBN'),\n ('at', 'IN'),\n ('least', 'JJS'),\n ('two', 'CD'),\n ('death', 'NN'),\n ('eaters', 'NNS'),\n ('did', 'VBD'),\n ('he', 'PRP'),\n ('get', 'VB'),\n ('any', 'DT'),\n ('other', 'JJ'),\n ('s', 'NN'),\n ('harry', 'NN'),\n ('wondered', 'VBD'),\n ('aloud', 'JJ'),\n ('yeah', 'NN'),\n ('he', 'PRP'),\n ('got', 'VBD'),\n ('everyone', 'NN'),\n ('in', 'IN'),\n ('that', 'DT'),\n ('group', 'NN'),\n ('wow', 'VBD'),\n ('yeah', 'UH'),\n ('wow', 'NN'),\n ('i', 'NN'),\n ('do', 'VBP'),\n ('nt', 'RB'),\n ('even', 'RB'),\n ('know', 'VB'),\n ('where', 'WRB'),\n ('he', 'PRP'),\n ('learnt', 'VBZ'),\n ('half', 'PDT'),\n ('the', 'DT'),\n ('curses', 'NNS'),\n ('he', 'PRP'),\n ('used', 'VBD'),\n ('huh', 'VB'),\n ('what', 'WP'),\n ('were', 'VBD'),\n ('the', 'DT'),\n ('effects', 'NNS'),\n ('well', 'RB'),\n ('you', 'PRP'),\n ('saw', 'VBD'),\n ('hat', 'WP'),\n ('one', 'CD'),\n ('he', 'PRP'),\n ('used', 'VBD'),\n ('on', 'IN'),\n ('the', 'DT'),\n ('minister', 'NN'),\n ('right', 'RB'),\n ('ginny', 'NN'),\n ('got', 'VBD'),\n ('up', 'RP'),\n ('off', 'IN'),\n ('his', 'PRP$'),\n ('knee', 'NN'),\n ('and', 'CC'),\n ('sat', 'NN'),\n ('on', 'IN'),\n ('the', 'DT'),\n ('arm', 'NN'),\n ('of', 'IN'),\n ('his', 'PRP$'),\n ('chair', 'NN'),\n ('yep', 'NN'),\n ('lucky', 'IN'),\n ('you', 'PRP'),\n ('i', 'VBP'),\n ('did', 'VBD'),\n ('nt', 'RB'),\n ('but', 'CC'),\n ('he', 'PRP'),\n ('used', 'VBD'),\n ('another', 'DT'),\n ('one', 'NN'),\n ('on', 'IN'),\n ('macnair', 'NN'),\n ('that', 'IN'),\n ('made', 'VBD'),\n ('him', 'PRP'),\n ('stick', 'VB'),\n ('his', 'PRP$'),\n ('leg', 'NN'),\n ('right', 'VBD'),\n ('up', 'RB'),\n ('until', 'IN'),\n ('it', 'PRP'),\n ('touched', 'VBD'),\n ('his', 'PRP$'),\n ('ear', 'NN'),\n ('and', 'CC'),\n ('another', 'DT'),\n ('one', 'NN'),\n ('that', 'WDT'),\n ('hung', 'VBZ'),\n ('a', 'DT'),\n ('guy', 'NN'),\n ('upside', 'RB'),\n ('down', 'RB'),\n ('by', 'IN'),\n ('his', 'PRP$'),\n ('ankle', 'NN'),\n ('yeah', 'NN'),\n ('i', 'NN'),\n ('know', 'VBP'),\n ('that', 'IN'),\n ('one', 'CD'),\n ('levicorpus', 'NN'),\n ('ha', 'NN'),\n ('yes', 'UH'),\n ('ron', 'NN'),\n ('told', 'VBD'),\n ('me', 'PRP'),\n ('you', 'PRP'),\n ('used', 'VBD'),\n ('it', 'PRP'),\n ('on', 'IN'),\n ('him', 'PRP'),\n ('once', 'RB'),\n ('harry', 'NN'),\n ('was', 'VBD'),\n ('having', 'VBG'),\n ('fun', 'NN'),\n ('they', 'PRP'),\n ('were', 'VBD'),\n ('chatting', 'VBG'),\n ('easily', 'RB'),\n ('but', 'CC'),\n ('his', 'PRP$'),\n ('stomach', 'NN'),\n ('rumbled', 'VBD'),\n ('again', 'RB'),\n ('loud', 'JJ'),\n ('enough', 'RB'),\n ('for', 'IN'),\n ('ginny', 'NN'),\n ('to', 'TO'),\n ('hear', 'VB'),\n ('it', 'PRP'),\n ('she', 'PRP'),\n ('looked', 'VBD'),\n ('at', 'IN'),\n ('him', 'PRP'),\n ('in', 'IN'),\n ('amusement', 'NN'),\n ('you', 'PRP'),\n ('re', 'VBP'),\n ('hungry', 'JJ'),\n ('harry', 'NN'),\n ('winced', 'VBD'),\n ('from', 'IN'),\n ('the', 'DT'),\n ('hunger', 'NN'),\n ('pains', 'VBZ'),\n ('yeah', 'UH'),\n ('but', 'CC'),\n ('the', 'DT'),\n ('ministry', 'NN'),\n ('ll', 'NN'),\n ('be', 'VB'),\n ('waiting', 'VBG'),\n ('for', 'IN'),\n ('me', 'PRP'),\n ('down', 'IN'),\n ('there', 'RB'),\n ('and', 'CC'),\n ('i', 'VB'),\n ('do', 'VBP'),\n ('nt', 'DT'),\n ('want', 'VB'),\n ('to', 'TO'),\n ('face', 'VB'),\n ('them', 'PRP'),\n ('so', 'RB'),\n ('will', 'MD'),\n ('the', 'DT'),\n ('prophet', 'NN'),\n ('and', 'CC'),\n ('a', 'DT'),\n ('thousand', 'CD'),\n ('other', 'JJ'),\n ('people', 'NNS'),\n ('and', 'CC'),\n ('i', 'VB'),\n ('do', 'VBP'),\n ('nt', 'DT'),\n ('want', 'VB'),\n ('to', 'TO'),\n ('see', 'VB'),\n ('any', 'DT'),\n ('of', 'IN'),\n ('them', 'PRP'),\n ('he', 'PRP'),\n ('looked', 'VBD'),\n ('at', 'IN'),\n ('ginny', 'JJ'),\n ('beseechingly', 'RB'),\n ('reckon', 'VBP'),\n ('you', 'PRP'),\n ('could', 'MD'),\n ('get', 'VB'),\n ('enough', 'RB'),\n ('for', 'IN'),\n ('two', 'CD'),\n ('and', 'CC'),\n ('meet', 'VB'),\n ('me', 'PRP'),\n ('back', 'RP'),\n ('up', 'RP'),\n ('here', 'RB'),\n ('ginny', 'RB'),\n ('smiled', 'VBN'),\n ('again', 'RB'),\n ('sure', 'JJ'),\n ('ten', 'VBN'),\n ('minutes', 'NNS'),\n ('later', 'RBR'),\n ('ginny', 'NN'),\n ('came', 'VBD'),\n ('back', 'RB'),\n ('up', 'RP'),\n ('with', 'IN'),\n ('a', 'DT'),\n ('basketful', 'NN'),\n ('of', 'IN'),\n ('food', 'NN'),\n ('ron', 'NN'),\n ('and', 'CC'),\n ('hermione', 'NN'),\n ('are', 'VBP'),\n ('sitting', 'VBG'),\n ('very', 'RB'),\n ('close', 'RB'),\n ('together', 'IN'),\n ('she', 'PRP'),\n ('said', 'VBD'),\n ('grinning', 'NN'),\n ('as', 'IN'),\n ('she', 'PRP'),\n ('set', 'VBD'),\n ('it', 'PRP'),\n ('down', 'RP'),\n ('and', 'CC'),\n ('you', 'PRP'),\n ('were', 'VBD'),\n ('right', 'RB'),\n ('--', ':'),\n ('kingsley', 'NN'),\n ('was', 'VBD'),\n ('down', 'RB'),\n ('there', 'RB'),\n ('and', 'CC'),\n ('so', 'RB'),\n ('were', 'VBD'),\n ('a', 'DT'),\n ('couple', 'NN'),\n ('of', 'IN'),\n ('people', 'NNS'),\n ('from', 'IN'),\n ('the', 'DT'),\n ...]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [33], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m a \u001B[38;5;241m=\u001B[39m nltk\u001B[38;5;241m.\u001B[39mne_chunk(pos_tags)\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubtrees\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a = nltk.ne_chunk(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 2. [2 балла] Модели представления слов\n",
    "Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса HPAC."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/germanarutunov/DataspellProjects/hw-1-nlp-hse-2022-AndBoyS/hw\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "data_dir = Path('data')\n",
    "split_data_dir = data_dir / 'hpac_splits'\n",
    "\n",
    "ft_data_dir = data_dir / 'ft'\n",
    "ft_data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "ft_train_file = ft_data_dir / 'hpac_ft.train'\n",
    "ft_dev_file = ft_data_dir / 'hpac_ft.dev'\n",
    "\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "ft_model = models_dir / 'ft.ftz'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "should_train_ft = True\n",
    "should_train_split_ft = True\n",
    "should_dev_split_ft = True\n",
    "\n",
    "if ft_train_file.exists():\n",
    "    should_train_split_ft = False\n",
    "\n",
    "if ft_dev_file.exists():\n",
    "    should_dev_split_ft = False\n",
    "\n",
    "if ft_model.exists():\n",
    "    should_train_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "if should_train_split_ft:\n",
    "    train_df = pd.read_csv(split_data_dir / 'hpac_training_128.tsv',\n",
    "                           names=['target', 'text'],\n",
    "                           index_col=0,\n",
    "                           sep='\\t', header=None)\n",
    "    with open(ft_train_file, mode='a') as f:\n",
    "        for i, (target, text) in tqdm(train_df.iterrows(), desc='Processing train split for fastText'):\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "            f.write(f'__label__{target}\\t{text}\\n')\n",
    "    should_train_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Processing dev split for fastText: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aed506615af24295aac487ceb36279eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if should_dev_split_ft:\n",
    "    dev_df = pd.read_csv(split_data_dir / 'hpac_dev_128.tsv',\n",
    "                         names=['target', 'text'],\n",
    "                         index_col=0,\n",
    "                         sep='\\t', header=None)\n",
    "    with open(ft_dev_file, mode='a') as f:\n",
    "        for i, (target, text) in tqdm(dev_df.iterrows(), desc='Processing dev split for fastText'):\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "            f.write(f'__label__{target}\\t{text}\\n')\n",
    "    should_dev_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import fasttext"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:    3 Best score:  0.260092 ETA:   0h 0m 0s 95.3% Trials:    3 Best score:  0.260092 ETA:   0h 0m56s\n",
      "Training again with best arguments\n",
      "Read 7M words\n",
      "Number of words:  58022\n",
      "Number of labels: 85\n",
      "Progress: 100.0% words/sec/thread:  427044 lr:  0.000000 avg.loss:  3.599567 ETA:   0h 0m 0s 58.2% words/sec/thread:  383426 lr:  0.320569 avg.loss:  3.709370 ETA:   0h 0m 2s\n",
      "Progress: 100.0% words/sec/thread:  459367 lr:  0.000000 avg.loss:  3.411367 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "if should_train_ft:\n",
    "    model = fasttext.train_supervised(\n",
    "        input=str(ft_train_file),\n",
    "        autotuneValidationFile=str(ft_dev_file),\n",
    "        autotuneModelSize='5M',\n",
    "        autotuneDuration=1200\n",
    "    )\n",
    "    model.save_model(str(ft_model))\n",
    "    should_train_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.1 Синонимы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.8944582343101501, 'rescue'),\n (0.888363242149353, 'ridiculously'),\n (0.8825259208679199, 'jeremiah'),\n (0.8562796115875244, 'witnessed'),\n (0.8521283864974976, 'hounding'),\n (0.8432715535163879, 'none'),\n (0.8367645740509033, 'hints'),\n (0.8300632834434509, 'weaved'),\n (0.82944256067276, 'sacred'),\n (0.8291577100753784, 'betas')]"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors('wizard')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.2 Ассоциации"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.9383688569068909, 'combats'),\n (0.9187878966331482, 'mocked'),\n (0.9064145088195801, 'ooooo'),\n (0.9061028361320496, 'force'),\n (0.903786301612854, 'roared'),\n (0.9032526612281799, 'jezlyn'),\n (0.8954090476036072, 'wheezley'),\n (0.8932932019233704, 'abstract'),\n (0.8926324844360352, 'fenir'),\n (0.8868676424026489, 'caged')]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_analogies('zombie', 'monster', 'beast')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.3 Лишние слова"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Не знаю, как это тут сделать"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Нужны предыдущие пункты"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 3. [5 баллов] Классификация текстов\n",
    "Задача классификации формулируется так: данный фрагмент фанфика описывают какую-то ситуацию, которая предшествует произнесению заклинания. Требуется по тексту предсказать, какое именно заклинание будет произнесено. Таким образом, заклинание - это фактически метка класса. Основная мера качества – macro $F_1$.\n",
    "Обучите несколько классификаторов и сравните их между собой. Оцените качество классификаторов на частых и редких классах. Какие классы чаще всего оказываются перепутаны? Связаны ли ошибки со смыслом заклинаний?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 fastText"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "ft_data_dir = data_dir / 'ft'\n",
    "\n",
    "ft_test_file = ft_data_dir / 'hpac_ft.test'\n",
    "\n",
    "models_dir = Path('models')\n",
    "ft_model = models_dir / 'ft.ftz'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "should_test_split_ft = True\n",
    "\n",
    "if ft_test_file.exists():\n",
    "    should_test_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "if should_test_split_ft:\n",
    "    test_df = pd.read_csv(split_data_dir / 'hpac_test_128.tsv',\n",
    "                           names=['target', 'text'],\n",
    "                           index_col=0,\n",
    "                           sep='\\t', header=None)\n",
    "    with open(ft_test_file, mode='a') as f:\n",
    "        for i, (target, text) in tqdm(test_df.iterrows(), desc='Processing test split for fastText'):\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "            f.write(f'__label__{target}\\t{text}\\n')\n",
    "    should_test_split_ft = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model(str(ft_model))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "scores = model.test_label(str(ft_test_file))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 for fastText is 0.3122\n"
     ]
    }
   ],
   "source": [
    "macro_f1 = []\n",
    "\n",
    "for label, metrics in scores.items():\n",
    "    if np.isnan(metrics['f1score']):\n",
    "        continue\n",
    "    macro_f1 = metrics['f1score']\n",
    "\n",
    "macro_f1 = np.mean(macro_f1)\n",
    "print(f'Macro F1 for fastText is {macro_f1:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
